{
    "checksum": "71050277375ae7f615b4a8d743d2bcc1636db99024617ed2d3534b3247118657",
    "data": {
    "id": "f65619ed-df12-4b0b-bc75-a999c1315b92",
    "createdAt": 1745335117575,
    "updatedAt": 1745335135869,
    "title": "Go io/ioutil Replacement Guide",
    "messages": [
        {
            "id": "c285ebe5-6cac-4fbc-b104-ba2afed801c2",
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "Replace deprecated io/ioutil with os package helpers"
                },
                {
                    "type": "text",
                    "text": "io/ioutil is deprecated since Go 1.19. Use os.ReadFile / os.WriteFile."
                },
                {
                    "type": "codeSnippet",
                    "text": "-import (\n-\t\"context\"\n-\t\"encoding/json\"\n-\t\"flag\"\n-\t\"fmt\"\n-\t\"io/ioutil\"\n+import (\n+\t\"context\"\n+\t\"encoding/json\"\n+\t\"flag\"\n+\t\"fmt\"\n \t// …\n )\n …\n-\terr = ioutil.WriteFile(outputFile, jsonData, 0644)\n+\terr = os.WriteFile(outputFile, jsonData, 0o644)\n …\n-\tdata, err := ioutil.ReadFile(existingFile)\n+\tdata, err := os.ReadFile(existingFile)"
                },
                {
                    "type": "text",
                    "text": "Also applies to: 146-149, 509-512"
                }
            ],
            "context": {
                "currentFile": {
                    "path": "cmd\\find-junit5-prs\\main.go",
                    "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                    "sources": [
                        "opened_tab"
                    ],
                    "content": "package main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"math\"\n\t\"math/rand\"\n\t\"os\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/shurcooL/githubv4\"\n\t\"golang.org/x/oauth2\"\n)\n\n// JUnit5PR represents a GitHub pull request related to JUnit 5 migration\ntype JUnit5PR struct {\n\tTitle      string   `json:\"title\"`\n\tURL        string   `json:\"url\"`\n\tRepository string   `json:\"repository\"`\n\tState      string   `json:\"state\"`\n\tAuthor     string   `json:\"author\"`\n\tLabels     []string `json:\"labels\"`\n\tBody       string   `json:\"body\"`\n\tCreatedAt  string   `json:\"createdAt\"`\n}\n\n// SearchResult holds the PRs found in the search\ntype SearchResult struct {\n\tPRs []JUnit5PR `json:\"prs\"`\n}\n\n// GraphQL query structure for searching pull requests\ntype searchQuery struct {\n\tSearch struct {\n\t\tPageInfo struct {\n\t\t\tHasNextPage bool\n\t\t\tEndCursor   githubv4.String\n\t\t}\n\t\tNodes []struct {\n\t\t\tPullRequest struct {\n\t\t\t\tTitle     githubv4.String\n\t\t\t\tURL       githubv4.String\n\t\t\t\tState     githubv4.String\n\t\t\t\tCreatedAt githubv4.DateTime\n\t\t\t\tAuthor    struct {\n\t\t\t\t\tLogin githubv4.String\n\t\t\t\t}\n\t\t\t\tRepository struct {\n\t\t\t\t\tNameWithOwner githubv4.String\n\t\t\t\t}\n\t\t\t\tLabels struct {\n\t\t\t\t\tNodes []struct {\n\t\t\t\t\t\tName githubv4.String\n\t\t\t\t\t}\n\t\t\t\t} `graphql:\"labels(first: 10)\"`\n\t\t\t\tBodyText githubv4.String\n\t\t\t} `graphql:\"... on PullRequest\"`\n\t\t}\n\t} `graphql:\"search(query: $query, type: ISSUE, first: $first, after: $after)\"`\n}\n\nfunc main() {\n\t// Parse command line flags\n\toutputDir := flag.String(\"output-dir\", \"data/junit5\", \"Directory to store output files\")\n\tcandidateFile := flag.String(\"candidate-file\", \"junit5_candidate_prs.txt\", \"File to store candidate PR URLs\")\n\texistingFile := flag.String(\"existing-file\", \"junit5_pr_urls.txt\", \"File containing existing PR URLs\")\n\tstartDate := flag.String(\"start-date\", \"2024-07-01\", \"Start date for PR search (YYYY-MM-DD)\")\n\tflag.Parse()\n\n\t// Get GitHub token from environment\n\ttoken := os.Getenv(\"GITHUB_TOKEN\")\n\tif token == \"\" {\n\t\tfmt.Println(\"GITHUB_TOKEN environment variable is required\")\n\t\tos.Exit(1)\n\t}\n\n\t// Parse start date\n\tstartDateTime, err := time.Parse(\"2006-01-02\", *startDate)\n\tif err != nil {\n\t\tfmt.Printf(\"Error parsing start date: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tfmt.Printf(\"Searching for PRs created on or after: %s\\n\", startDateTime.Format(\"2006-01-02\"))\n\n\t// Create output directory if it doesn't exist\n\tos.MkdirAll(*outputDir, 0755)\n\n\t// Create GitHub client\n\tsrc := oauth2.StaticTokenSource(\n\t\t&oauth2.Token{AccessToken: token},\n\t)\n\thttpClient := oauth2.NewClient(context.Background(), src)\n\tclient := githubv4.NewClient(httpClient)\n\n\t// Define search terms\n\tsearchTerms := []string{\n\t\t\"junit5\",\n\t\t\"junit 5\",\n\t\t\"migrate tests to junit\",\n\t\t\"junit jupiter\",\n\t\t\"openrewrite junit\",\n\t}\n\n\t// Initialize result\n\tresult := SearchResult{\n\t\tPRs: []JUnit5PR{},\n\t}\n\n\t// Search for each term\n\tfor _, term := range searchTerms {\n\t\tfmt.Printf(\"Searching for: %s\\n\", term)\n\n\t\t// Search in title\n\t\ttitleQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:title %s\", term)\n\t\tprs := searchPRs(client, titleQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\n\t\t// Search in body\n\t\tbodyQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:body %s\", term)\n\t\tprs = searchPRs(client, bodyQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\t}\n\n\t// Search for PRs by specific authors known for JUnit 5 migrations\n\tfmt.Println(\"Searching for PRs by known JUnit 5 migration authors...\")\n\tauthorQuery := \"org:jenkinsci is:pr author:strangelookingnerd\"\n\tprs := searchPRs(client, authorQuery, startDateTime)\n\tresult.PRs = append(result.PRs, prs...)\n\n\t// Remove duplicates\n\tresult.PRs = removeDuplicates(result.PRs)\n\n\t// Save results to JSON file\n\tjsonData, err := json.MarshalIndent(result, \"\", \"  \")\n\tif err != nil {\n\t\tfmt.Printf(\"Error marshaling JSON: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\toutputFile := fmt.Sprintf(\"%s/junit5_candidates.json\", *outputDir)\n\terr = ioutil.WriteFile(outputFile, jsonData, 0644)\n\tif err != nil {\n\t\tfmt.Printf(\"Error writing JSON file: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Generate text file with URLs for easy addition to junit5_pr_urls.txt\n\tgenerateCandidateURLsFile(result.PRs, *candidateFile)\n\n\t// Compare with existing PRs in junit5_pr_urls.txt\n\tcompareWithExistingPRs(result.PRs, *existingFile)\n\n\tfmt.Printf(\"Found %d potential JUnit 5 migration PR candidates\\n\", len(result.PRs))\n\tfmt.Printf(\"Results saved to %s and %s\\n\", outputFile, *candidateFile)\n}\n\n// searchPRs performs a GitHub search and returns PRs matching the query\nfunc searchPRs(client *githubv4.Client, query string, startDate time.Time) []JUnit5PR {\n\tvar q searchQuery\n\tvariables := map[string]interface{}{\n\t\t\"query\": githubv4.String(query),\n\t\t\"first\": githubv4.Int(10), // Reduced from 25 to 10 to make queries even less complex\n\t\t\"after\": (*githubv4.String)(nil),\n\t}\n\n\tvar allPRs []JUnit5PR\n\tmaxRetries := 10 // Increased from 5 to 10\n\tinitialBackoff := 2 * time.Second\n\tmaxBackoff := 60 * time.Second\n\n\t// Log the query being executed\n\tfmt.Printf(\"Executing GitHub GraphQL query: %s\\n\", query)\n\tfmt.Printf(\"Start date: %s\\n\", startDate.Format(time.RFC3339))\n\n\tpageCount := 0\n\ttotalAttempts := 0\n\tmaxPages := 100 // Set a maximum page limit to prevent infinite loops\n\n\tfor pageCount < maxPages {\n\t\t// Add a small delay between requests to respect rate limits\n\t\ttime.Sleep(1 * time.Second)\n\n\t\t// Create a context with timeout\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n\n\t\tvar err error\n\t\tsuccess := false\n\n\t\t// Implement retry with exponential backoff\n\t\tfor attempt := 0; attempt < maxRetries && !success; attempt++ {\n\t\t\ttotalAttempts++\n\n\t\t\t// Get current rate limit information before making the request\n\t\t\tvar rateLimit struct {\n\t\t\t\tRateLimit struct {\n\t\t\t\t\tLimit     githubv4.Int\n\t\t\t\t\tRemaining githubv4.Int\n\t\t\t\t\tResetAt   githubv4.DateTime\n\t\t\t\t} `graphql:\"rateLimit\"`\n\t\t\t}\n\n\t\t\trateLimitErr := client.Query(context.Background(), &rateLimit, nil)\n\t\t\tif rateLimitErr == nil {\n\t\t\t\tfmt.Printf(\"GitHub API rate limit: %d/%d remaining, resets at %s\\n\",\n\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\trateLimit.RateLimit.Limit,\n\t\t\t\t\trateLimit.RateLimit.ResetAt.Format(time.RFC3339))\n\n\t\t\t\t// Check if we're close to hitting the rate limit\n\t\t\t\tif rateLimit.RateLimit.Remaining < 100 {\n\t\t\t\t\tresetTime := time.Until(rateLimit.RateLimit.ResetAt.Time)\n\t\t\t\t\tfmt.Printf(\"WARNING: Rate limit is low (%d remaining). Limit resets in %s\\n\",\n\t\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\t\tresetTime.Round(time.Second))\n\n\t\t\t\t\tif rateLimit.RateLimit.Remaining < 10 {\n\t\t\t\t\t\tfmt.Println(\"Rate limit critically low, waiting until reset...\")\n\t\t\t\t\t\twaitTime := time.Until(rateLimit.RateLimit.ResetAt.Time) + 10*time.Second\n\t\t\t\t\t\ttime.Sleep(waitTime)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfmt.Printf(\"Could not fetch rate limit info: %v\\n\", rateLimitErr)\n\t\t\t}\n\n\t\t\t// Execute the actual query\n\t\t\tstartTime := time.Now()\n\t\t\terr = client.Query(ctx, &q, variables)\n\t\t\tqueryDuration := time.Since(startTime)\n\n\t\t\tif err == nil {\n\t\t\t\tsuccess = true\n\t\t\t\tfmt.Printf(\"Query succeeded in %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t\t// Log the number of results received\n\t\t\t\tresultCount := len(q.Search.Nodes)\n\t\t\t\tfmt.Printf(\"Received %d results for page %d\\n\", resultCount, pageCount+1)\n\n\t\t\t\t// Process the results\n\t\t\t\tfor _, node := range q.Search.Nodes {\n\t\t\t\t\tpr := node.PullRequest\n\n\t\t\t\t\t// Extract labels\n\t\t\t\t\tvar labels []string\n\t\t\t\t\tfor _, label := range pr.Labels.Nodes {\n\t\t\t\t\t\tlabels = append(labels, string(label.Name))\n\t\t\t\t\t}\n\n\t\t\t\t\t// Create PR object\n\t\t\t\t\tnewPR := JUnit5PR{\n\t\t\t\t\t\tTitle:      string(pr.Title),\n\t\t\t\t\t\tURL:        string(pr.URL),\n\t\t\t\t\t\tRepository: string(pr.Repository.NameWithOwner),\n\t\t\t\t\t\tState:      string(pr.State),\n\t\t\t\t\t\tAuthor:     string(pr.Author.Login),\n\t\t\t\t\t\tLabels:     labels,\n\t\t\t\t\t\tBody:       string(pr.BodyText),\n\t\t\t\t\t\tCreatedAt:  pr.CreatedAt.Format(time.RFC3339),\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs created on or after the start date\n\t\t\t\t\tif pr.CreatedAt.Before(startDate) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs that are likely related to JUnit 5 migration\n\t\t\t\t\tif isJUnit5MigrationPR(newPR) {\n\t\t\t\t\t\tallPRs = append(allPRs, newPR)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Log progress\n\t\t\t\tfmt.Printf(\"Processed page %d, found %d matching PRs so far\\n\", pageCount+1, len(allPRs))\n\n\t\t\t\t// Check if there are more pages\n\t\t\t\tif !q.Search.PageInfo.HasNextPage {\n\t\t\t\t\tfmt.Printf(\"No more pages available, completed after %d pages\\n\", pageCount+1)\n\t\t\t\t\tcancel()      // Cancel the context before returning\n\t\t\t\t\treturn allPRs // Exit the function when no more pages\n\t\t\t\t}\n\n\t\t\t\t// Move to next page\n\t\t\t\tfmt.Printf(\"Moving to next page with cursor: %s\\n\", q.Search.PageInfo.EndCursor)\n\t\t\t\tvariables[\"after\"] = githubv4.NewString(q.Search.PageInfo.EndCursor)\n\n\t\t\t\t// Increment page count\n\t\t\t\tpageCount++\n\n\t\t\t\t// Add a small delay before the next page to avoid overwhelming GitHub\n\t\t\t\ttime.Sleep(1 * time.Second)\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Log detailed error information\n\t\t\tfmt.Printf(\"GitHub API error on attempt %d/%d (total %d): %v\\n\",\n\t\t\t\tattempt+1, maxRetries, totalAttempts, err)\n\t\t\tfmt.Printf(\"Query duration before error: %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t// Try to parse and log more details from the error\n\t\t\tvar errorDetails struct {\n\t\t\t\tData   interface{}              `json:\"data\"`\n\t\t\t\tErrors []map[string]interface{} `json:\"errors\"`\n\t\t\t}\n\n\t\t\tif strings.Contains(err.Error(), \"{\") {\n\t\t\t\terrorJSON := err.Error()[strings.Index(err.Error(), \"{\"):]\n\t\t\t\tif jsonErr := json.Unmarshal([]byte(errorJSON), &errorDetails); jsonErr == nil {\n\t\t\t\t\tif errorDetails.Errors != nil && len(errorDetails.Errors) > 0 {\n\t\t\t\t\t\tfmt.Println(\"Detailed error information:\")\n\t\t\t\t\t\tfor i, errDetail := range errorDetails.Errors {\n\t\t\t\t\t\t\tfmt.Printf(\"  Error %d:\\n\", i+1)\n\t\t\t\t\t\t\tfor k, v := range errDetail {\n\t\t\t\t\t\t\t\tfmt.Printf(\"    %s: %v\\n\", k, v)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Check if this is a retryable error (like 502)\n\t\t\tif strings.Contains(err.Error(), \"502\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"timeout\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"Something went wrong\") {\n\n\t\t\t\t// Calculate backoff duration with exponential increase and jitter\n\t\t\t\tbackoffTime := float64(initialBackoff) * math.Pow(2, float64(attempt))\n\t\t\t\tif backoffTime > float64(maxBackoff) {\n\t\t\t\t\tbackoffTime = float64(maxBackoff)\n\t\t\t\t}\n\n\t\t\t\t// Add jitter (±20%)\n\t\t\t\tjitter := (rand.Float64() * 0.4) - 0.2 // -20% to +20%\n\t\t\t\tbackoffTime = backoffTime * (1 + jitter)\n\n\t\t\t\tsleepDuration := time.Duration(backoffTime)\n\t\t\t\tfmt.Printf(\"Retrying in %v...\\n\", sleepDuration)\n\t\t\t\ttime.Sleep(sleepDuration)\n\t\t\t} else {\n\t\t\t\t// Non-retryable error, break out\n\t\t\t\tfmt.Println(\"Non-retryable error encountered, stopping retry attempts\")\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !success {\n\t\t\tfmt.Printf(\"Failed after %d attempts: %v\\n\", maxRetries, err)\n\t\t\tfmt.Println(\"Continuing with results collected so far...\")\n\t\t\tcancel() // Cancel the context before returning\n\t\t\treturn allPRs\n\t\t}\n\n\t\t// Cancel the context after we're done with it\n\t\tcancel()\n\t}\n\n\t// If we've reached the maximum number of pages, log a message\n\tfmt.Printf(\"Reached maximum page limit (%d). Stopping to prevent excessive API usage.\\n\", maxPages)\n\treturn allPRs\n}\n\n// isJUnit5MigrationPR checks if a PR is likely related to JUnit 5 migration\nfunc isJUnit5MigrationPR(pr JUnit5PR) bool {\n\t// Exclude dependency bumps\n\tif strings.HasPrefix(pr.Title, \"Bump\") || strings.HasPrefix(pr.Title, \"bump\") {\n\t\treturn false\n\t}\n\n\t// Exclude PRs with specific JIRA ticket prefixes that are known not to be JUnit 5 related\n\t// These are examples of tickets that were incorrectly included\n\texcludePatterns := []string{\n\t\t`(?i)JENKINS-70560`,         // Improve test coverage\n\t\t`(?i)JENKINS-75447`,         // Fix Snippetizer rendering\n\t\t`(?i)JENKINS-\\d+.*fix`,      // General fixes\n\t\t`(?i)fix`,                   // General fixes\n\t\t`(?i)improve test coverage`, // Test coverage improvements not related to JUnit 5\n\t}\n\n\tfor _, pattern := range excludePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Define more specific patterns for JUnit 5 migration PRs\n\ttitlePatterns := []string{\n\t\t`(?i)migrate tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t}\n\n\tbodyPatterns := []string{\n\t\t`(?i)migrate (all )?tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t\t`(?i)org\\.junit\\.jupiter`,\n\t\t`(?i)junit-jupiter`,\n\t}\n\n\tlabelPatterns := []string{\n\t\t`(?i)\\bjunit ?5\\b`,\n\t\t`(?i)junit-5`,\n\t\t`(?i)junit-migration`,\n\t}\n\n\tauthorPatterns := []string{\n\t\t`strangelookingnerd`,\n\t}\n\n\t// Check title with more specific matching\n\tfor _, pattern := range titlePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn true\n\t\t}\n\t}\n\n\t// For body matches, require stronger evidence\n\t// Count how many patterns match in the body\n\tbodyMatchCount := 0\n\tfor _, pattern := range bodyPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Body)\n\t\tif matched {\n\t\t\tbodyMatchCount++\n\t\t}\n\t}\n\n\t// Require at least 2 body pattern matches for a positive identification\n\t// This helps avoid false positives from PRs that mention JUnit in passing\n\tif bodyMatchCount >= 2 {\n\t\treturn true\n\t}\n\n\t// Check labels\n\tfor _, label := range pr.Labels {\n\t\tfor _, pattern := range labelPatterns {\n\t\t\tmatched, _ := regexp.MatchString(pattern, label)\n\t\t\tif matched {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check author - but only if there's at least some mention of JUnit in the body\n\t// This avoids including all PRs from certain authors\n\tfor _, pattern := range authorPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Author)\n\t\tif matched {\n\t\t\t// Check if there's at least some mention of JUnit in the body\n\t\t\tjunitmatch, _ := regexp.MatchString(`(?i)junit`, pr.Body)\n\t\t\tif junitmatch {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\treturn false\n}\n\n// removeDuplicates removes duplicate PRs from the slice\nfunc removeDuplicates(prs []JUnit5PR) []JUnit5PR {\n\tseen := make(map[string]bool)\n\tvar result []JUnit5PR\n\n\tfor _, pr := range prs {\n\t\tif !seen[pr.URL] {\n\t\t\tseen[pr.URL] = true\n\t\t\tresult = append(result, pr)\n\t\t}\n\t}\n\n\treturn result\n}\n\n// generateCandidateURLsFile creates a text file with PR URLs for easy addition to junit5_pr_urls.txt\nfunc generateCandidateURLsFile(prs []JUnit5PR, outputFile string) {\n\tfile, err := os.Create(outputFile)\n\tif err != nil {\n\t\tfmt.Printf(\"Error creating file: %v\\n\", err)\n\t\treturn\n\t}\n\tdefer file.Close()\n\n\tfile.WriteString(fmt.Sprintf(\"# JUnit 5 migration PR candidates found on %s\\n\", time.Now().Format(\"2006-01-02 15:04:05\")))\n\tfile.WriteString(\"# Add relevant URLs to junit5_pr_urls.txt after verification\\n\\n\")\n\n\tfor _, pr := range prs {\n\t\tfile.WriteString(fmt.Sprintf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State))\n\t\tfile.WriteString(fmt.Sprintf(\"%s\\n\\n\", pr.URL))\n\t}\n}\n\n// compareWithExistingPRs compares found PRs with those already in junit5_pr_urls.txt\nfunc compareWithExistingPRs(prs []JUnit5PR, existingFile string) {\n\t// Read existing PR URLs\n\texistingURLs := make(map[string]bool)\n\n\tdata, err := ioutil.ReadFile(existingFile)\n\tif err == nil {\n\t\tlines := strings.Split(string(data), \"\\n\")\n\t\tfor _, line := range lines {\n\t\t\tline = strings.TrimSpace(line)\n\t\t\tif strings.HasPrefix(line, \"https://\") {\n\t\t\t\texistingURLs[line] = true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Find new PRs\n\tvar newPRs []JUnit5PR\n\tfor _, pr := range prs {\n\t\tif !existingURLs[pr.URL] {\n\t\t\tnewPRs = append(newPRs, pr)\n\t\t}\n\t}\n\n\tfmt.Printf(\"Found %d new PR candidates not already in %s\\n\", len(newPRs), existingFile)\n\n\tif len(newPRs) > 0 {\n\t\tfmt.Println(\"New PR candidates:\")\n\t\tfor _, pr := range newPRs {\n\t\t\tfmt.Printf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State)\n\t\t\tfmt.Printf(\"%s\\n\\n\", pr.URL)\n\t\t}\n\t}\n}\n"
                },
                "codebaseEnabled": true,
                "ragFiles": [
                    {
                        "path": "cmd/find-junit5-prs/main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google_auth_oauthlib/flow.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google_auth_oauthlib\\flow.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pyparsing/__init__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pyparsing\\__init__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pyparsing/common.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pyparsing\\common.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "jenkins-pr-collector.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\jenkins-pr-collector.go",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/req/req_install.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\req\\req_install.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/packaging/licenses/_spdx.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\packaging\\licenses\\_spdx.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/models/wheel.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\models\\wheel.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/models/link.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\models\\link.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/metadata/importlib/_envs.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\metadata\\importlib\\_envs.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/locations/__init__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\locations\\__init__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/typing_extensions.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\typing_extensions.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/cli/base_command.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\cli\\base_command.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/utils/deprecation.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\utils\\deprecation.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/six.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\six.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/logging.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\logging.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/default_styles.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\default_styles.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/progress_bar.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\progress_bar.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/urllib3/packages/six.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\urllib3\\packages\\six.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/pygments/formatters/html.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\pygments\\formatters\\html.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "go.sum",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\go.sum",
                        "sources": []
                    },
                    {
                        "path": "cmd\\find-junit5-prs\\go.sum",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\go.sum",
                        "sources": []
                    },
                    {
                        "path": "cmd\\find-junit5-prs\\go.mod",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\go.mod",
                        "sources": []
                    },
                    {
                        "path": "go.mod",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\go.mod",
                        "sources": []
                    },
                    {
                        "path": "cmd\\find-junit5-prs\\main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": []
                    },
                    {
                        "path": "analyze-junit5-prs.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\analyze-junit5-prs.sh",
                        "sources": []
                    },
                    {
                        "path": "data\\consolidated\\failing_prs.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\failing_prs.json",
                        "sources": []
                    },
                    {
                        "path": "grouped_prs_filtered_prs_2025_02.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\grouped_prs_filtered_prs_2025_02.json",
                        "sources": []
                    },
                    {
                        "path": "filtered_prs_filtered_prs_2025_03.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\filtered_prs_filtered_prs_2025_03.json",
                        "sources": []
                    },
                    {
                        "path": "data\\monthly\\prs_2025_03.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\monthly\\prs_2025_03.json",
                        "sources": []
                    },
                    {
                        "path": "data\\monthly\\filtered_prs_2025_03.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\monthly\\filtered_prs_2025_03.json",
                        "sources": []
                    },
                    {
                        "path": "data\\monthly\\filtered_prs_2025_02.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\monthly\\filtered_prs_2025_02.json",
                        "sources": []
                    },
                    {
                        "path": "junit5_candidate_prs.txt",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\junit5_candidate_prs.txt",
                        "sources": []
                    },
                    {
                        "path": "process_prs.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\process_prs.sh",
                        "sources": []
                    },
                    {
                        "path": "junit5-migration-prs.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\junit5-migration-prs.sh",
                        "sources": []
                    },
                    {
                        "path": "README.md",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\README.md",
                        "sources": []
                    },
                    {
                        "path": "data/consolidated/failed_builds.csv",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\failed_builds.csv",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "data/consolidated/successful_builds.csv",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\successful_builds.csv",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "data/consolidated/test_results.csv",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\test_results.csv",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "update-daily.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\update-daily.sh",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "upload_to_sheets.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\upload_to_sheets.py",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "data/junit5/junit5_migration_prs.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\junit5\\junit5_migration_prs.json",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "cmd/find-junit5-prs/main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": [
                            "opened_tab"
                        ]
                    }
                ],
                "rerankedFiles": [
                    {
                        "path": "cmd\\find-junit5-prs\\main.go",
                        "fsPath": "cmd\\find-junit5-prs\\main.go"
                    }
                ],
                "usedFilePaths": [
                    {
                        "path": "cmd\\find-junit5-prs\\main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": [
                            "opened_tab"
                        ],
                        "content": "package main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"math\"\n\t\"math/rand\"\n\t\"os\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/shurcooL/githubv4\"\n\t\"golang.org/x/oauth2\"\n)\n\n// JUnit5PR represents a GitHub pull request related to JUnit 5 migration\ntype JUnit5PR struct {\n\tTitle      string   `json:\"title\"`\n\tURL        string   `json:\"url\"`\n\tRepository string   `json:\"repository\"`\n\tState      string   `json:\"state\"`\n\tAuthor     string   `json:\"author\"`\n\tLabels     []string `json:\"labels\"`\n\tBody       string   `json:\"body\"`\n\tCreatedAt  string   `json:\"createdAt\"`\n}\n\n// SearchResult holds the PRs found in the search\ntype SearchResult struct {\n\tPRs []JUnit5PR `json:\"prs\"`\n}\n\n// GraphQL query structure for searching pull requests\ntype searchQuery struct {\n\tSearch struct {\n\t\tPageInfo struct {\n\t\t\tHasNextPage bool\n\t\t\tEndCursor   githubv4.String\n\t\t}\n\t\tNodes []struct {\n\t\t\tPullRequest struct {\n\t\t\t\tTitle     githubv4.String\n\t\t\t\tURL       githubv4.String\n\t\t\t\tState     githubv4.String\n\t\t\t\tCreatedAt githubv4.DateTime\n\t\t\t\tAuthor    struct {\n\t\t\t\t\tLogin githubv4.String\n\t\t\t\t}\n\t\t\t\tRepository struct {\n\t\t\t\t\tNameWithOwner githubv4.String\n\t\t\t\t}\n\t\t\t\tLabels struct {\n\t\t\t\t\tNodes []struct {\n\t\t\t\t\t\tName githubv4.String\n\t\t\t\t\t}\n\t\t\t\t} `graphql:\"labels(first: 10)\"`\n\t\t\t\tBodyText githubv4.String\n\t\t\t} `graphql:\"... on PullRequest\"`\n\t\t}\n\t} `graphql:\"search(query: $query, type: ISSUE, first: $first, after: $after)\"`\n}\n\nfunc main() {\n\t// Parse command line flags\n\toutputDir := flag.String(\"output-dir\", \"data/junit5\", \"Directory to store output files\")\n\tcandidateFile := flag.String(\"candidate-file\", \"junit5_candidate_prs.txt\", \"File to store candidate PR URLs\")\n\texistingFile := flag.String(\"existing-file\", \"junit5_pr_urls.txt\", \"File containing existing PR URLs\")\n\tstartDate := flag.String(\"start-date\", \"2024-07-01\", \"Start date for PR search (YYYY-MM-DD)\")\n\tflag.Parse()\n\n\t// Get GitHub token from environment\n\ttoken := os.Getenv(\"GITHUB_TOKEN\")\n\tif token == \"\" {\n\t\tfmt.Println(\"GITHUB_TOKEN environment variable is required\")\n\t\tos.Exit(1)\n\t}\n\n\t// Parse start date\n\tstartDateTime, err := time.Parse(\"2006-01-02\", *startDate)\n\tif err != nil {\n\t\tfmt.Printf(\"Error parsing start date: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tfmt.Printf(\"Searching for PRs created on or after: %s\\n\", startDateTime.Format(\"2006-01-02\"))\n\n\t// Create output directory if it doesn't exist\n\tos.MkdirAll(*outputDir, 0755)\n\n\t// Create GitHub client\n\tsrc := oauth2.StaticTokenSource(\n\t\t&oauth2.Token{AccessToken: token},\n\t)\n\thttpClient := oauth2.NewClient(context.Background(), src)\n\tclient := githubv4.NewClient(httpClient)\n\n\t// Define search terms\n\tsearchTerms := []string{\n\t\t\"junit5\",\n\t\t\"junit 5\",\n\t\t\"migrate tests to junit\",\n\t\t\"junit jupiter\",\n\t\t\"openrewrite junit\",\n\t}\n\n\t// Initialize result\n\tresult := SearchResult{\n\t\tPRs: []JUnit5PR{},\n\t}\n\n\t// Search for each term\n\tfor _, term := range searchTerms {\n\t\tfmt.Printf(\"Searching for: %s\\n\", term)\n\n\t\t// Search in title\n\t\ttitleQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:title %s\", term)\n\t\tprs := searchPRs(client, titleQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\n\t\t// Search in body\n\t\tbodyQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:body %s\", term)\n\t\tprs = searchPRs(client, bodyQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\t}\n\n\t// Search for PRs by specific authors known for JUnit 5 migrations\n\tfmt.Println(\"Searching for PRs by known JUnit 5 migration authors...\")\n\tauthorQuery := \"org:jenkinsci is:pr author:strangelookingnerd\"\n\tprs := searchPRs(client, authorQuery, startDateTime)\n\tresult.PRs = append(result.PRs, prs...)\n\n\t// Remove duplicates\n\tresult.PRs = removeDuplicates(result.PRs)\n\n\t// Save results to JSON file\n\tjsonData, err := json.MarshalIndent(result, \"\", \"  \")\n\tif err != nil {\n\t\tfmt.Printf(\"Error marshaling JSON: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\toutputFile := fmt.Sprintf(\"%s/junit5_candidates.json\", *outputDir)\n\terr = ioutil.WriteFile(outputFile, jsonData, 0644)\n\tif err != nil {\n\t\tfmt.Printf(\"Error writing JSON file: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Generate text file with URLs for easy addition to junit5_pr_urls.txt\n\tgenerateCandidateURLsFile(result.PRs, *candidateFile)\n\n\t// Compare with existing PRs in junit5_pr_urls.txt\n\tcompareWithExistingPRs(result.PRs, *existingFile)\n\n\tfmt.Printf(\"Found %d potential JUnit 5 migration PR candidates\\n\", len(result.PRs))\n\tfmt.Printf(\"Results saved to %s and %s\\n\", outputFile, *candidateFile)\n}\n\n// searchPRs performs a GitHub search and returns PRs matching the query\nfunc searchPRs(client *githubv4.Client, query string, startDate time.Time) []JUnit5PR {\n\tvar q searchQuery\n\tvariables := map[string]interface{}{\n\t\t\"query\": githubv4.String(query),\n\t\t\"first\": githubv4.Int(10), // Reduced from 25 to 10 to make queries even less complex\n\t\t\"after\": (*githubv4.String)(nil),\n\t}\n\n\tvar allPRs []JUnit5PR\n\tmaxRetries := 10 // Increased from 5 to 10\n\tinitialBackoff := 2 * time.Second\n\tmaxBackoff := 60 * time.Second\n\n\t// Log the query being executed\n\tfmt.Printf(\"Executing GitHub GraphQL query: %s\\n\", query)\n\tfmt.Printf(\"Start date: %s\\n\", startDate.Format(time.RFC3339))\n\n\tpageCount := 0\n\ttotalAttempts := 0\n\tmaxPages := 100 // Set a maximum page limit to prevent infinite loops\n\n\tfor pageCount < maxPages {\n\t\t// Add a small delay between requests to respect rate limits\n\t\ttime.Sleep(1 * time.Second)\n\n\t\t// Create a context with timeout\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n\n\t\tvar err error\n\t\tsuccess := false\n\n\t\t// Implement retry with exponential backoff\n\t\tfor attempt := 0; attempt < maxRetries && !success; attempt++ {\n\t\t\ttotalAttempts++\n\n\t\t\t// Get current rate limit information before making the request\n\t\t\tvar rateLimit struct {\n\t\t\t\tRateLimit struct {\n\t\t\t\t\tLimit     githubv4.Int\n\t\t\t\t\tRemaining githubv4.Int\n\t\t\t\t\tResetAt   githubv4.DateTime\n\t\t\t\t} `graphql:\"rateLimit\"`\n\t\t\t}\n\n\t\t\trateLimitErr := client.Query(context.Background(), &rateLimit, nil)\n\t\t\tif rateLimitErr == nil {\n\t\t\t\tfmt.Printf(\"GitHub API rate limit: %d/%d remaining, resets at %s\\n\",\n\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\trateLimit.RateLimit.Limit,\n\t\t\t\t\trateLimit.RateLimit.ResetAt.Format(time.RFC3339))\n\n\t\t\t\t// Check if we're close to hitting the rate limit\n\t\t\t\tif rateLimit.RateLimit.Remaining < 100 {\n\t\t\t\t\tresetTime := time.Until(rateLimit.RateLimit.ResetAt.Time)\n\t\t\t\t\tfmt.Printf(\"WARNING: Rate limit is low (%d remaining). Limit resets in %s\\n\",\n\t\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\t\tresetTime.Round(time.Second))\n\n\t\t\t\t\tif rateLimit.RateLimit.Remaining < 10 {\n\t\t\t\t\t\tfmt.Println(\"Rate limit critically low, waiting until reset...\")\n\t\t\t\t\t\twaitTime := time.Until(rateLimit.RateLimit.ResetAt.Time) + 10*time.Second\n\t\t\t\t\t\ttime.Sleep(waitTime)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfmt.Printf(\"Could not fetch rate limit info: %v\\n\", rateLimitErr)\n\t\t\t}\n\n\t\t\t// Execute the actual query\n\t\t\tstartTime := time.Now()\n\t\t\terr = client.Query(ctx, &q, variables)\n\t\t\tqueryDuration := time.Since(startTime)\n\n\t\t\tif err == nil {\n\t\t\t\tsuccess = true\n\t\t\t\tfmt.Printf(\"Query succeeded in %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t\t// Log the number of results received\n\t\t\t\tresultCount := len(q.Search.Nodes)\n\t\t\t\tfmt.Printf(\"Received %d results for page %d\\n\", resultCount, pageCount+1)\n\n\t\t\t\t// Process the results\n\t\t\t\tfor _, node := range q.Search.Nodes {\n\t\t\t\t\tpr := node.PullRequest\n\n\t\t\t\t\t// Extract labels\n\t\t\t\t\tvar labels []string\n\t\t\t\t\tfor _, label := range pr.Labels.Nodes {\n\t\t\t\t\t\tlabels = append(labels, string(label.Name))\n\t\t\t\t\t}\n\n\t\t\t\t\t// Create PR object\n\t\t\t\t\tnewPR := JUnit5PR{\n\t\t\t\t\t\tTitle:      string(pr.Title),\n\t\t\t\t\t\tURL:        string(pr.URL),\n\t\t\t\t\t\tRepository: string(pr.Repository.NameWithOwner),\n\t\t\t\t\t\tState:      string(pr.State),\n\t\t\t\t\t\tAuthor:     string(pr.Author.Login),\n\t\t\t\t\t\tLabels:     labels,\n\t\t\t\t\t\tBody:       string(pr.BodyText),\n\t\t\t\t\t\tCreatedAt:  pr.CreatedAt.Format(time.RFC3339),\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs created on or after the start date\n\t\t\t\t\tif pr.CreatedAt.Before(startDate) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs that are likely related to JUnit 5 migration\n\t\t\t\t\tif isJUnit5MigrationPR(newPR) {\n\t\t\t\t\t\tallPRs = append(allPRs, newPR)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Log progress\n\t\t\t\tfmt.Printf(\"Processed page %d, found %d matching PRs so far\\n\", pageCount+1, len(allPRs))\n\n\t\t\t\t// Check if there are more pages\n\t\t\t\tif !q.Search.PageInfo.HasNextPage {\n\t\t\t\t\tfmt.Printf(\"No more pages available, completed after %d pages\\n\", pageCount+1)\n\t\t\t\t\tcancel()      // Cancel the context before returning\n\t\t\t\t\treturn allPRs // Exit the function when no more pages\n\t\t\t\t}\n\n\t\t\t\t// Move to next page\n\t\t\t\tfmt.Printf(\"Moving to next page with cursor: %s\\n\", q.Search.PageInfo.EndCursor)\n\t\t\t\tvariables[\"after\"] = githubv4.NewString(q.Search.PageInfo.EndCursor)\n\n\t\t\t\t// Increment page count\n\t\t\t\tpageCount++\n\n\t\t\t\t// Add a small delay before the next page to avoid overwhelming GitHub\n\t\t\t\ttime.Sleep(1 * time.Second)\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Log detailed error information\n\t\t\tfmt.Printf(\"GitHub API error on attempt %d/%d (total %d): %v\\n\",\n\t\t\t\tattempt+1, maxRetries, totalAttempts, err)\n\t\t\tfmt.Printf(\"Query duration before error: %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t// Try to parse and log more details from the error\n\t\t\tvar errorDetails struct {\n\t\t\t\tData   interface{}              `json:\"data\"`\n\t\t\t\tErrors []map[string]interface{} `json:\"errors\"`\n\t\t\t}\n\n\t\t\tif strings.Contains(err.Error(), \"{\") {\n\t\t\t\terrorJSON := err.Error()[strings.Index(err.Error(), \"{\"):]\n\t\t\t\tif jsonErr := json.Unmarshal([]byte(errorJSON), &errorDetails); jsonErr == nil {\n\t\t\t\t\tif errorDetails.Errors != nil && len(errorDetails.Errors) > 0 {\n\t\t\t\t\t\tfmt.Println(\"Detailed error information:\")\n\t\t\t\t\t\tfor i, errDetail := range errorDetails.Errors {\n\t\t\t\t\t\t\tfmt.Printf(\"  Error %d:\\n\", i+1)\n\t\t\t\t\t\t\tfor k, v := range errDetail {\n\t\t\t\t\t\t\t\tfmt.Printf(\"    %s: %v\\n\", k, v)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Check if this is a retryable error (like 502)\n\t\t\tif strings.Contains(err.Error(), \"502\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"timeout\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"Something went wrong\") {\n\n\t\t\t\t// Calculate backoff duration with exponential increase and jitter\n\t\t\t\tbackoffTime := float64(initialBackoff) * math.Pow(2, float64(attempt))\n\t\t\t\tif backoffTime > float64(maxBackoff) {\n\t\t\t\t\tbackoffTime = float64(maxBackoff)\n\t\t\t\t}\n\n\t\t\t\t// Add jitter (±20%)\n\t\t\t\tjitter := (rand.Float64() * 0.4) - 0.2 // -20% to +20%\n\t\t\t\tbackoffTime = backoffTime * (1 + jitter)\n\n\t\t\t\tsleepDuration := time.Duration(backoffTime)\n\t\t\t\tfmt.Printf(\"Retrying in %v...\\n\", sleepDuration)\n\t\t\t\ttime.Sleep(sleepDuration)\n\t\t\t} else {\n\t\t\t\t// Non-retryable error, break out\n\t\t\t\tfmt.Println(\"Non-retryable error encountered, stopping retry attempts\")\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !success {\n\t\t\tfmt.Printf(\"Failed after %d attempts: %v\\n\", maxRetries, err)\n\t\t\tfmt.Println(\"Continuing with results collected so far...\")\n\t\t\tcancel() // Cancel the context before returning\n\t\t\treturn allPRs\n\t\t}\n\n\t\t// Cancel the context after we're done with it\n\t\tcancel()\n\t}\n\n\t// If we've reached the maximum number of pages, log a message\n\tfmt.Printf(\"Reached maximum page limit (%d). Stopping to prevent excessive API usage.\\n\", maxPages)\n\treturn allPRs\n}\n\n// isJUnit5MigrationPR checks if a PR is likely related to JUnit 5 migration\nfunc isJUnit5MigrationPR(pr JUnit5PR) bool {\n\t// Exclude dependency bumps\n\tif strings.HasPrefix(pr.Title, \"Bump\") || strings.HasPrefix(pr.Title, \"bump\") {\n\t\treturn false\n\t}\n\n\t// Exclude PRs with specific JIRA ticket prefixes that are known not to be JUnit 5 related\n\t// These are examples of tickets that were incorrectly included\n\texcludePatterns := []string{\n\t\t`(?i)JENKINS-70560`,         // Improve test coverage\n\t\t`(?i)JENKINS-75447`,         // Fix Snippetizer rendering\n\t\t`(?i)JENKINS-\\d+.*fix`,      // General fixes\n\t\t`(?i)fix`,                   // General fixes\n\t\t`(?i)improve test coverage`, // Test coverage improvements not related to JUnit 5\n\t}\n\n\tfor _, pattern := range excludePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Define more specific patterns for JUnit 5 migration PRs\n\ttitlePatterns := []string{\n\t\t`(?i)migrate tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t}\n\n\tbodyPatterns := []string{\n\t\t`(?i)migrate (all )?tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t\t`(?i)org\\.junit\\.jupiter`,\n\t\t`(?i)junit-jupiter`,\n\t}\n\n\tlabelPatterns := []string{\n\t\t`(?i)\\bjunit ?5\\b`,\n\t\t`(?i)junit-5`,\n\t\t`(?i)junit-migration`,\n\t}\n\n\tauthorPatterns := []string{\n\t\t`strangelookingnerd`,\n\t}\n\n\t// Check title with more specific matching\n\tfor _, pattern := range titlePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn true\n\t\t}\n\t}\n\n\t// For body matches, require stronger evidence\n\t// Count how many patterns match in the body\n\tbodyMatchCount := 0\n\tfor _, pattern := range bodyPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Body)\n\t\tif matched {\n\t\t\tbodyMatchCount++\n\t\t}\n\t}\n\n\t// Require at least 2 body pattern matches for a positive identification\n\t// This helps avoid false positives from PRs that mention JUnit in passing\n\tif bodyMatchCount >= 2 {\n\t\treturn true\n\t}\n\n\t// Check labels\n\tfor _, label := range pr.Labels {\n\t\tfor _, pattern := range labelPatterns {\n\t\t\tmatched, _ := regexp.MatchString(pattern, label)\n\t\t\tif matched {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check author - but only if there's at least some mention of JUnit in the body\n\t// This avoids including all PRs from certain authors\n\tfor _, pattern := range authorPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Author)\n\t\tif matched {\n\t\t\t// Check if there's at least some mention of JUnit in the body\n\t\t\tjunitmatch, _ := regexp.MatchString(`(?i)junit`, pr.Body)\n\t\t\tif junitmatch {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\treturn false\n}\n\n// removeDuplicates removes duplicate PRs from the slice\nfunc removeDuplicates(prs []JUnit5PR) []JUnit5PR {\n\tseen := make(map[string]bool)\n\tvar result []JUnit5PR\n\n\tfor _, pr := range prs {\n\t\tif !seen[pr.URL] {\n\t\t\tseen[pr.URL] = true\n\t\t\tresult = append(result, pr)\n\t\t}\n\t}\n\n\treturn result\n}\n\n// generateCandidateURLsFile creates a text file with PR URLs for easy addition to junit5_pr_urls.txt\nfunc generateCandidateURLsFile(prs []JUnit5PR, outputFile string) {\n\tfile, err := os.Create(outputFile)\n\tif err != nil {\n\t\tfmt.Printf(\"Error creating file: %v\\n\", err)\n\t\treturn\n\t}\n\tdefer file.Close()\n\n\tfile.WriteString(fmt.Sprintf(\"# JUnit 5 migration PR candidates found on %s\\n\", time.Now().Format(\"2006-01-02 15:04:05\")))\n\tfile.WriteString(\"# Add relevant URLs to junit5_pr_urls.txt after verification\\n\\n\")\n\n\tfor _, pr := range prs {\n\t\tfile.WriteString(fmt.Sprintf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State))\n\t\tfile.WriteString(fmt.Sprintf(\"%s\\n\\n\", pr.URL))\n\t}\n}\n\n// compareWithExistingPRs compares found PRs with those already in junit5_pr_urls.txt\nfunc compareWithExistingPRs(prs []JUnit5PR, existingFile string) {\n\t// Read existing PR URLs\n\texistingURLs := make(map[string]bool)\n\n\tdata, err := ioutil.ReadFile(existingFile)\n\tif err == nil {\n\t\tlines := strings.Split(string(data), \"\\n\")\n\t\tfor _, line := range lines {\n\t\t\tline = strings.TrimSpace(line)\n\t\t\tif strings.HasPrefix(line, \"https://\") {\n\t\t\t\texistingURLs[line] = true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Find new PRs\n\tvar newPRs []JUnit5PR\n\tfor _, pr := range prs {\n\t\tif !existingURLs[pr.URL] {\n\t\t\tnewPRs = append(newPRs, pr)\n\t\t}\n\t}\n\n\tfmt.Printf(\"Found %d new PR candidates not already in %s\\n\", len(newPRs), existingFile)\n\n\tif len(newPRs) > 0 {\n\t\tfmt.Println(\"New PR candidates:\")\n\t\tfor _, pr := range newPRs {\n\t\t\tfmt.Printf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State)\n\t\t\tfmt.Printf(\"%s\\n\\n\", pr.URL)\n\t\t}\n\t}\n}\n"
                    }
                ]
            },
            "createdAt": 1745335117576,
            "isInternal": false,
            "rawContent": {
                "type": "doc",
                "content": [
                    {
                        "type": "paragraph",
                        "content": [
                            {
                                "type": "text",
                                "text": "Replace deprecated io/ioutil with os package helpers"
                            }
                        ]
                    },
                    {
                        "type": "paragraph",
                        "content": [
                            {
                                "type": "text",
                                "text": "io/ioutil is deprecated since Go 1.19. Use os.ReadFile / os.WriteFile."
                            }
                        ]
                    },
                    {
                        "type": "codeBlock",
                        "attrs": {
                            "language": null
                        },
                        "content": [
                            {
                                "type": "text",
                                "text": "-import (\n-\t\"context\"\n-\t\"encoding/json\"\n-\t\"flag\"\n-\t\"fmt\"\n-\t\"io/ioutil\"\n+import (\n+\t\"context\"\n+\t\"encoding/json\"\n+\t\"flag\"\n+\t\"fmt\"\n \t// …\n )\n …\n-\terr = ioutil.WriteFile(outputFile, jsonData, 0644)\n+\terr = os.WriteFile(outputFile, jsonData, 0o644)\n …\n-\tdata, err := ioutil.ReadFile(existingFile)\n+\tdata, err := os.ReadFile(existingFile)"
                            }
                        ]
                    },
                    {
                        "type": "paragraph",
                        "content": [
                            {
                                "type": "text",
                                "text": "Also applies to: 146-149, 509-512"
                            }
                        ]
                    }
                ]
            }
        },
        {
            "id": "8504c27a-bedb-437b-98d4-92a79dd07851",
            "role": "assistant",
            "content": [
                {
                    "type": "text",
                    "text": "To replace the deprecated `io/ioutil` package with the `os` package helpers in your Go code, you need to make the following changes:\n\n1. **Import the `os` package**: Ensure that the `os` package is imported in your file. You can remove the `io/ioutil` import since it's no longer needed.\n\n2. **Replace `ioutil.ReadFile` with `os.ReadFile`**: This function reads the content of a file and returns the data as a byte slice.\n\n3. **Replace `ioutil.WriteFile` with `os.WriteFile`**: This function writes data to a file, creating the file if it does not exist.\n\nHere's how you can update your code:\n\n```go\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"flag\"\n\t\"fmt\"\n\t\"os\"\n\t// other imports...\n)\n\n// ... rest of your code ...\n\nfunc main() {\n\t// ... existing code ...\n\n\t// Save results to JSON file\n\tjsonData, err := json.MarshalIndent(result, \"\", \"  \")\n\tif err != nil {\n\t\tfmt.Printf(\"Error marshaling JSON: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\toutputFile := fmt.Sprintf(\"%s/junit5_candidates.json\", *outputDir)\n\terr = os.WriteFile(outputFile, jsonData, 0o644)\n\tif err != nil {\n\t\tfmt.Printf(\"Error writing JSON file: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Generate text file with URLs for easy addition to junit5_pr_urls.txt\n\tgenerateCandidateURLsFile(result.PRs, *candidateFile)\n\n\t// Compare with existing PRs in junit5_pr_urls.txt\n\tcompareWithExistingPRs(result.PRs, *existingFile)\n\n\tfmt.Printf(\"Found %d potential JUnit 5 migration PR candidates\\n\", len(result.PRs))\n\tfmt.Printf(\"Results saved to %s and %s\\n\", outputFile, *candidateFile)\n}\n\n// compareWithExistingPRs compares found PRs with those already in junit5_pr_urls.txt\nfunc compareWithExistingPRs(prs []JUnit5PR, existingFile string) {\n\t// Read existing PR URLs\n\texistingURLs := make(map[string]bool)\n\n\tdata, err := os.ReadFile(existingFile)\n\tif err == nil {\n\t\tlines := strings.Split(string(data), \"\\n\")\n\t\tfor _, line := range lines {\n\t\t\tline = strings.TrimSpace(line)\n\t\t\tif strings.HasPrefix(line, \"https://\") {\n\t\t\t\texistingURLs[line] = true\n\t\t\t}\n\t\t}\n\t}\n\n\t// ... rest of the function ...\n}\n```\n\n### Key Changes:\n- **`os.WriteFile`**: Used for writing JSON data to a file.\n- **`os.ReadFile`**: Used for reading existing PR URLs from a file.\n\nThese changes ensure that your code is up-to-date with the latest Go standards and avoids using deprecated packages."
                }
            ],
            "context": {
                "currentFile": {
                    "path": "cmd\\find-junit5-prs\\main.go",
                    "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                    "sources": [
                        "opened_tab"
                    ],
                    "content": "package main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"math\"\n\t\"math/rand\"\n\t\"os\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/shurcooL/githubv4\"\n\t\"golang.org/x/oauth2\"\n)\n\n// JUnit5PR represents a GitHub pull request related to JUnit 5 migration\ntype JUnit5PR struct {\n\tTitle      string   `json:\"title\"`\n\tURL        string   `json:\"url\"`\n\tRepository string   `json:\"repository\"`\n\tState      string   `json:\"state\"`\n\tAuthor     string   `json:\"author\"`\n\tLabels     []string `json:\"labels\"`\n\tBody       string   `json:\"body\"`\n\tCreatedAt  string   `json:\"createdAt\"`\n}\n\n// SearchResult holds the PRs found in the search\ntype SearchResult struct {\n\tPRs []JUnit5PR `json:\"prs\"`\n}\n\n// GraphQL query structure for searching pull requests\ntype searchQuery struct {\n\tSearch struct {\n\t\tPageInfo struct {\n\t\t\tHasNextPage bool\n\t\t\tEndCursor   githubv4.String\n\t\t}\n\t\tNodes []struct {\n\t\t\tPullRequest struct {\n\t\t\t\tTitle     githubv4.String\n\t\t\t\tURL       githubv4.String\n\t\t\t\tState     githubv4.String\n\t\t\t\tCreatedAt githubv4.DateTime\n\t\t\t\tAuthor    struct {\n\t\t\t\t\tLogin githubv4.String\n\t\t\t\t}\n\t\t\t\tRepository struct {\n\t\t\t\t\tNameWithOwner githubv4.String\n\t\t\t\t}\n\t\t\t\tLabels struct {\n\t\t\t\t\tNodes []struct {\n\t\t\t\t\t\tName githubv4.String\n\t\t\t\t\t}\n\t\t\t\t} `graphql:\"labels(first: 10)\"`\n\t\t\t\tBodyText githubv4.String\n\t\t\t} `graphql:\"... on PullRequest\"`\n\t\t}\n\t} `graphql:\"search(query: $query, type: ISSUE, first: $first, after: $after)\"`\n}\n\nfunc main() {\n\t// Parse command line flags\n\toutputDir := flag.String(\"output-dir\", \"data/junit5\", \"Directory to store output files\")\n\tcandidateFile := flag.String(\"candidate-file\", \"junit5_candidate_prs.txt\", \"File to store candidate PR URLs\")\n\texistingFile := flag.String(\"existing-file\", \"junit5_pr_urls.txt\", \"File containing existing PR URLs\")\n\tstartDate := flag.String(\"start-date\", \"2024-07-01\", \"Start date for PR search (YYYY-MM-DD)\")\n\tflag.Parse()\n\n\t// Get GitHub token from environment\n\ttoken := os.Getenv(\"GITHUB_TOKEN\")\n\tif token == \"\" {\n\t\tfmt.Println(\"GITHUB_TOKEN environment variable is required\")\n\t\tos.Exit(1)\n\t}\n\n\t// Parse start date\n\tstartDateTime, err := time.Parse(\"2006-01-02\", *startDate)\n\tif err != nil {\n\t\tfmt.Printf(\"Error parsing start date: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tfmt.Printf(\"Searching for PRs created on or after: %s\\n\", startDateTime.Format(\"2006-01-02\"))\n\n\t// Create output directory if it doesn't exist\n\tos.MkdirAll(*outputDir, 0755)\n\n\t// Create GitHub client\n\tsrc := oauth2.StaticTokenSource(\n\t\t&oauth2.Token{AccessToken: token},\n\t)\n\thttpClient := oauth2.NewClient(context.Background(), src)\n\tclient := githubv4.NewClient(httpClient)\n\n\t// Define search terms\n\tsearchTerms := []string{\n\t\t\"junit5\",\n\t\t\"junit 5\",\n\t\t\"migrate tests to junit\",\n\t\t\"junit jupiter\",\n\t\t\"openrewrite junit\",\n\t}\n\n\t// Initialize result\n\tresult := SearchResult{\n\t\tPRs: []JUnit5PR{},\n\t}\n\n\t// Search for each term\n\tfor _, term := range searchTerms {\n\t\tfmt.Printf(\"Searching for: %s\\n\", term)\n\n\t\t// Search in title\n\t\ttitleQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:title %s\", term)\n\t\tprs := searchPRs(client, titleQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\n\t\t// Search in body\n\t\tbodyQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:body %s\", term)\n\t\tprs = searchPRs(client, bodyQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\t}\n\n\t// Search for PRs by specific authors known for JUnit 5 migrations\n\tfmt.Println(\"Searching for PRs by known JUnit 5 migration authors...\")\n\tauthorQuery := \"org:jenkinsci is:pr author:strangelookingnerd\"\n\tprs := searchPRs(client, authorQuery, startDateTime)\n\tresult.PRs = append(result.PRs, prs...)\n\n\t// Remove duplicates\n\tresult.PRs = removeDuplicates(result.PRs)\n\n\t// Save results to JSON file\n\tjsonData, err := json.MarshalIndent(result, \"\", \"  \")\n\tif err != nil {\n\t\tfmt.Printf(\"Error marshaling JSON: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\toutputFile := fmt.Sprintf(\"%s/junit5_candidates.json\", *outputDir)\n\terr = ioutil.WriteFile(outputFile, jsonData, 0644)\n\tif err != nil {\n\t\tfmt.Printf(\"Error writing JSON file: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Generate text file with URLs for easy addition to junit5_pr_urls.txt\n\tgenerateCandidateURLsFile(result.PRs, *candidateFile)\n\n\t// Compare with existing PRs in junit5_pr_urls.txt\n\tcompareWithExistingPRs(result.PRs, *existingFile)\n\n\tfmt.Printf(\"Found %d potential JUnit 5 migration PR candidates\\n\", len(result.PRs))\n\tfmt.Printf(\"Results saved to %s and %s\\n\", outputFile, *candidateFile)\n}\n\n// searchPRs performs a GitHub search and returns PRs matching the query\nfunc searchPRs(client *githubv4.Client, query string, startDate time.Time) []JUnit5PR {\n\tvar q searchQuery\n\tvariables := map[string]interface{}{\n\t\t\"query\": githubv4.String(query),\n\t\t\"first\": githubv4.Int(10), // Reduced from 25 to 10 to make queries even less complex\n\t\t\"after\": (*githubv4.String)(nil),\n\t}\n\n\tvar allPRs []JUnit5PR\n\tmaxRetries := 10 // Increased from 5 to 10\n\tinitialBackoff := 2 * time.Second\n\tmaxBackoff := 60 * time.Second\n\n\t// Log the query being executed\n\tfmt.Printf(\"Executing GitHub GraphQL query: %s\\n\", query)\n\tfmt.Printf(\"Start date: %s\\n\", startDate.Format(time.RFC3339))\n\n\tpageCount := 0\n\ttotalAttempts := 0\n\tmaxPages := 100 // Set a maximum page limit to prevent infinite loops\n\n\tfor pageCount < maxPages {\n\t\t// Add a small delay between requests to respect rate limits\n\t\ttime.Sleep(1 * time.Second)\n\n\t\t// Create a context with timeout\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n\n\t\tvar err error\n\t\tsuccess := false\n\n\t\t// Implement retry with exponential backoff\n\t\tfor attempt := 0; attempt < maxRetries && !success; attempt++ {\n\t\t\ttotalAttempts++\n\n\t\t\t// Get current rate limit information before making the request\n\t\t\tvar rateLimit struct {\n\t\t\t\tRateLimit struct {\n\t\t\t\t\tLimit     githubv4.Int\n\t\t\t\t\tRemaining githubv4.Int\n\t\t\t\t\tResetAt   githubv4.DateTime\n\t\t\t\t} `graphql:\"rateLimit\"`\n\t\t\t}\n\n\t\t\trateLimitErr := client.Query(context.Background(), &rateLimit, nil)\n\t\t\tif rateLimitErr == nil {\n\t\t\t\tfmt.Printf(\"GitHub API rate limit: %d/%d remaining, resets at %s\\n\",\n\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\trateLimit.RateLimit.Limit,\n\t\t\t\t\trateLimit.RateLimit.ResetAt.Format(time.RFC3339))\n\n\t\t\t\t// Check if we're close to hitting the rate limit\n\t\t\t\tif rateLimit.RateLimit.Remaining < 100 {\n\t\t\t\t\tresetTime := time.Until(rateLimit.RateLimit.ResetAt.Time)\n\t\t\t\t\tfmt.Printf(\"WARNING: Rate limit is low (%d remaining). Limit resets in %s\\n\",\n\t\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\t\tresetTime.Round(time.Second))\n\n\t\t\t\t\tif rateLimit.RateLimit.Remaining < 10 {\n\t\t\t\t\t\tfmt.Println(\"Rate limit critically low, waiting until reset...\")\n\t\t\t\t\t\twaitTime := time.Until(rateLimit.RateLimit.ResetAt.Time) + 10*time.Second\n\t\t\t\t\t\ttime.Sleep(waitTime)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfmt.Printf(\"Could not fetch rate limit info: %v\\n\", rateLimitErr)\n\t\t\t}\n\n\t\t\t// Execute the actual query\n\t\t\tstartTime := time.Now()\n\t\t\terr = client.Query(ctx, &q, variables)\n\t\t\tqueryDuration := time.Since(startTime)\n\n\t\t\tif err == nil {\n\t\t\t\tsuccess = true\n\t\t\t\tfmt.Printf(\"Query succeeded in %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t\t// Log the number of results received\n\t\t\t\tresultCount := len(q.Search.Nodes)\n\t\t\t\tfmt.Printf(\"Received %d results for page %d\\n\", resultCount, pageCount+1)\n\n\t\t\t\t// Process the results\n\t\t\t\tfor _, node := range q.Search.Nodes {\n\t\t\t\t\tpr := node.PullRequest\n\n\t\t\t\t\t// Extract labels\n\t\t\t\t\tvar labels []string\n\t\t\t\t\tfor _, label := range pr.Labels.Nodes {\n\t\t\t\t\t\tlabels = append(labels, string(label.Name))\n\t\t\t\t\t}\n\n\t\t\t\t\t// Create PR object\n\t\t\t\t\tnewPR := JUnit5PR{\n\t\t\t\t\t\tTitle:      string(pr.Title),\n\t\t\t\t\t\tURL:        string(pr.URL),\n\t\t\t\t\t\tRepository: string(pr.Repository.NameWithOwner),\n\t\t\t\t\t\tState:      string(pr.State),\n\t\t\t\t\t\tAuthor:     string(pr.Author.Login),\n\t\t\t\t\t\tLabels:     labels,\n\t\t\t\t\t\tBody:       string(pr.BodyText),\n\t\t\t\t\t\tCreatedAt:  pr.CreatedAt.Format(time.RFC3339),\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs created on or after the start date\n\t\t\t\t\tif pr.CreatedAt.Before(startDate) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs that are likely related to JUnit 5 migration\n\t\t\t\t\tif isJUnit5MigrationPR(newPR) {\n\t\t\t\t\t\tallPRs = append(allPRs, newPR)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Log progress\n\t\t\t\tfmt.Printf(\"Processed page %d, found %d matching PRs so far\\n\", pageCount+1, len(allPRs))\n\n\t\t\t\t// Check if there are more pages\n\t\t\t\tif !q.Search.PageInfo.HasNextPage {\n\t\t\t\t\tfmt.Printf(\"No more pages available, completed after %d pages\\n\", pageCount+1)\n\t\t\t\t\tcancel()      // Cancel the context before returning\n\t\t\t\t\treturn allPRs // Exit the function when no more pages\n\t\t\t\t}\n\n\t\t\t\t// Move to next page\n\t\t\t\tfmt.Printf(\"Moving to next page with cursor: %s\\n\", q.Search.PageInfo.EndCursor)\n\t\t\t\tvariables[\"after\"] = githubv4.NewString(q.Search.PageInfo.EndCursor)\n\n\t\t\t\t// Increment page count\n\t\t\t\tpageCount++\n\n\t\t\t\t// Add a small delay before the next page to avoid overwhelming GitHub\n\t\t\t\ttime.Sleep(1 * time.Second)\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Log detailed error information\n\t\t\tfmt.Printf(\"GitHub API error on attempt %d/%d (total %d): %v\\n\",\n\t\t\t\tattempt+1, maxRetries, totalAttempts, err)\n\t\t\tfmt.Printf(\"Query duration before error: %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t// Try to parse and log more details from the error\n\t\t\tvar errorDetails struct {\n\t\t\t\tData   interface{}              `json:\"data\"`\n\t\t\t\tErrors []map[string]interface{} `json:\"errors\"`\n\t\t\t}\n\n\t\t\tif strings.Contains(err.Error(), \"{\") {\n\t\t\t\terrorJSON := err.Error()[strings.Index(err.Error(), \"{\"):]\n\t\t\t\tif jsonErr := json.Unmarshal([]byte(errorJSON), &errorDetails); jsonErr == nil {\n\t\t\t\t\tif errorDetails.Errors != nil && len(errorDetails.Errors) > 0 {\n\t\t\t\t\t\tfmt.Println(\"Detailed error information:\")\n\t\t\t\t\t\tfor i, errDetail := range errorDetails.Errors {\n\t\t\t\t\t\t\tfmt.Printf(\"  Error %d:\\n\", i+1)\n\t\t\t\t\t\t\tfor k, v := range errDetail {\n\t\t\t\t\t\t\t\tfmt.Printf(\"    %s: %v\\n\", k, v)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Check if this is a retryable error (like 502)\n\t\t\tif strings.Contains(err.Error(), \"502\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"timeout\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"Something went wrong\") {\n\n\t\t\t\t// Calculate backoff duration with exponential increase and jitter\n\t\t\t\tbackoffTime := float64(initialBackoff) * math.Pow(2, float64(attempt))\n\t\t\t\tif backoffTime > float64(maxBackoff) {\n\t\t\t\t\tbackoffTime = float64(maxBackoff)\n\t\t\t\t}\n\n\t\t\t\t// Add jitter (±20%)\n\t\t\t\tjitter := (rand.Float64() * 0.4) - 0.2 // -20% to +20%\n\t\t\t\tbackoffTime = backoffTime * (1 + jitter)\n\n\t\t\t\tsleepDuration := time.Duration(backoffTime)\n\t\t\t\tfmt.Printf(\"Retrying in %v...\\n\", sleepDuration)\n\t\t\t\ttime.Sleep(sleepDuration)\n\t\t\t} else {\n\t\t\t\t// Non-retryable error, break out\n\t\t\t\tfmt.Println(\"Non-retryable error encountered, stopping retry attempts\")\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !success {\n\t\t\tfmt.Printf(\"Failed after %d attempts: %v\\n\", maxRetries, err)\n\t\t\tfmt.Println(\"Continuing with results collected so far...\")\n\t\t\tcancel() // Cancel the context before returning\n\t\t\treturn allPRs\n\t\t}\n\n\t\t// Cancel the context after we're done with it\n\t\tcancel()\n\t}\n\n\t// If we've reached the maximum number of pages, log a message\n\tfmt.Printf(\"Reached maximum page limit (%d). Stopping to prevent excessive API usage.\\n\", maxPages)\n\treturn allPRs\n}\n\n// isJUnit5MigrationPR checks if a PR is likely related to JUnit 5 migration\nfunc isJUnit5MigrationPR(pr JUnit5PR) bool {\n\t// Exclude dependency bumps\n\tif strings.HasPrefix(pr.Title, \"Bump\") || strings.HasPrefix(pr.Title, \"bump\") {\n\t\treturn false\n\t}\n\n\t// Exclude PRs with specific JIRA ticket prefixes that are known not to be JUnit 5 related\n\t// These are examples of tickets that were incorrectly included\n\texcludePatterns := []string{\n\t\t`(?i)JENKINS-70560`,         // Improve test coverage\n\t\t`(?i)JENKINS-75447`,         // Fix Snippetizer rendering\n\t\t`(?i)JENKINS-\\d+.*fix`,      // General fixes\n\t\t`(?i)fix`,                   // General fixes\n\t\t`(?i)improve test coverage`, // Test coverage improvements not related to JUnit 5\n\t}\n\n\tfor _, pattern := range excludePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Define more specific patterns for JUnit 5 migration PRs\n\ttitlePatterns := []string{\n\t\t`(?i)migrate tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t}\n\n\tbodyPatterns := []string{\n\t\t`(?i)migrate (all )?tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t\t`(?i)org\\.junit\\.jupiter`,\n\t\t`(?i)junit-jupiter`,\n\t}\n\n\tlabelPatterns := []string{\n\t\t`(?i)\\bjunit ?5\\b`,\n\t\t`(?i)junit-5`,\n\t\t`(?i)junit-migration`,\n\t}\n\n\tauthorPatterns := []string{\n\t\t`strangelookingnerd`,\n\t}\n\n\t// Check title with more specific matching\n\tfor _, pattern := range titlePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn true\n\t\t}\n\t}\n\n\t// For body matches, require stronger evidence\n\t// Count how many patterns match in the body\n\tbodyMatchCount := 0\n\tfor _, pattern := range bodyPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Body)\n\t\tif matched {\n\t\t\tbodyMatchCount++\n\t\t}\n\t}\n\n\t// Require at least 2 body pattern matches for a positive identification\n\t// This helps avoid false positives from PRs that mention JUnit in passing\n\tif bodyMatchCount >= 2 {\n\t\treturn true\n\t}\n\n\t// Check labels\n\tfor _, label := range pr.Labels {\n\t\tfor _, pattern := range labelPatterns {\n\t\t\tmatched, _ := regexp.MatchString(pattern, label)\n\t\t\tif matched {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check author - but only if there's at least some mention of JUnit in the body\n\t// This avoids including all PRs from certain authors\n\tfor _, pattern := range authorPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Author)\n\t\tif matched {\n\t\t\t// Check if there's at least some mention of JUnit in the body\n\t\t\tjunitmatch, _ := regexp.MatchString(`(?i)junit`, pr.Body)\n\t\t\tif junitmatch {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\treturn false\n}\n\n// removeDuplicates removes duplicate PRs from the slice\nfunc removeDuplicates(prs []JUnit5PR) []JUnit5PR {\n\tseen := make(map[string]bool)\n\tvar result []JUnit5PR\n\n\tfor _, pr := range prs {\n\t\tif !seen[pr.URL] {\n\t\t\tseen[pr.URL] = true\n\t\t\tresult = append(result, pr)\n\t\t}\n\t}\n\n\treturn result\n}\n\n// generateCandidateURLsFile creates a text file with PR URLs for easy addition to junit5_pr_urls.txt\nfunc generateCandidateURLsFile(prs []JUnit5PR, outputFile string) {\n\tfile, err := os.Create(outputFile)\n\tif err != nil {\n\t\tfmt.Printf(\"Error creating file: %v\\n\", err)\n\t\treturn\n\t}\n\tdefer file.Close()\n\n\tfile.WriteString(fmt.Sprintf(\"# JUnit 5 migration PR candidates found on %s\\n\", time.Now().Format(\"2006-01-02 15:04:05\")))\n\tfile.WriteString(\"# Add relevant URLs to junit5_pr_urls.txt after verification\\n\\n\")\n\n\tfor _, pr := range prs {\n\t\tfile.WriteString(fmt.Sprintf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State))\n\t\tfile.WriteString(fmt.Sprintf(\"%s\\n\\n\", pr.URL))\n\t}\n}\n\n// compareWithExistingPRs compares found PRs with those already in junit5_pr_urls.txt\nfunc compareWithExistingPRs(prs []JUnit5PR, existingFile string) {\n\t// Read existing PR URLs\n\texistingURLs := make(map[string]bool)\n\n\tdata, err := ioutil.ReadFile(existingFile)\n\tif err == nil {\n\t\tlines := strings.Split(string(data), \"\\n\")\n\t\tfor _, line := range lines {\n\t\t\tline = strings.TrimSpace(line)\n\t\t\tif strings.HasPrefix(line, \"https://\") {\n\t\t\t\texistingURLs[line] = true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Find new PRs\n\tvar newPRs []JUnit5PR\n\tfor _, pr := range prs {\n\t\tif !existingURLs[pr.URL] {\n\t\t\tnewPRs = append(newPRs, pr)\n\t\t}\n\t}\n\n\tfmt.Printf(\"Found %d new PR candidates not already in %s\\n\", len(newPRs), existingFile)\n\n\tif len(newPRs) > 0 {\n\t\tfmt.Println(\"New PR candidates:\")\n\t\tfor _, pr := range newPRs {\n\t\t\tfmt.Printf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State)\n\t\t\tfmt.Printf(\"%s\\n\\n\", pr.URL)\n\t\t}\n\t}\n}\n"
                },
                "codebaseEnabled": true,
                "ragFiles": [
                    {
                        "path": "cmd/find-junit5-prs/main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google_auth_oauthlib/flow.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google_auth_oauthlib\\flow.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pyparsing/__init__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pyparsing\\__init__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pyparsing/common.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pyparsing\\common.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "jenkins-pr-collector.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\jenkins-pr-collector.go",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/req/req_install.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\req\\req_install.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/packaging/licenses/_spdx.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\packaging\\licenses\\_spdx.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/models/wheel.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\models\\wheel.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/models/link.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\models\\link.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/metadata/importlib/_envs.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\metadata\\importlib\\_envs.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/locations/__init__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\locations\\__init__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/typing_extensions.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\typing_extensions.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/cli/base_command.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\cli\\base_command.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/utils/deprecation.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\utils\\deprecation.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/six.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\six.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/logging.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\logging.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/default_styles.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\default_styles.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/progress_bar.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\progress_bar.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/urllib3/packages/six.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\urllib3\\packages\\six.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/pygments/formatters/html.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\pygments\\formatters\\html.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "go.sum",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\go.sum",
                        "sources": []
                    },
                    {
                        "path": "cmd\\find-junit5-prs\\go.sum",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\go.sum",
                        "sources": []
                    },
                    {
                        "path": "cmd\\find-junit5-prs\\go.mod",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\go.mod",
                        "sources": []
                    },
                    {
                        "path": "go.mod",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\go.mod",
                        "sources": []
                    },
                    {
                        "path": "cmd\\find-junit5-prs\\main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": []
                    },
                    {
                        "path": "analyze-junit5-prs.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\analyze-junit5-prs.sh",
                        "sources": []
                    },
                    {
                        "path": "data\\consolidated\\failing_prs.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\failing_prs.json",
                        "sources": []
                    },
                    {
                        "path": "grouped_prs_filtered_prs_2025_02.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\grouped_prs_filtered_prs_2025_02.json",
                        "sources": []
                    },
                    {
                        "path": "filtered_prs_filtered_prs_2025_03.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\filtered_prs_filtered_prs_2025_03.json",
                        "sources": []
                    },
                    {
                        "path": "data\\monthly\\prs_2025_03.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\monthly\\prs_2025_03.json",
                        "sources": []
                    },
                    {
                        "path": "data\\monthly\\filtered_prs_2025_03.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\monthly\\filtered_prs_2025_03.json",
                        "sources": []
                    },
                    {
                        "path": "data\\monthly\\filtered_prs_2025_02.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\monthly\\filtered_prs_2025_02.json",
                        "sources": []
                    },
                    {
                        "path": "junit5_candidate_prs.txt",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\junit5_candidate_prs.txt",
                        "sources": []
                    },
                    {
                        "path": "process_prs.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\process_prs.sh",
                        "sources": []
                    },
                    {
                        "path": "junit5-migration-prs.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\junit5-migration-prs.sh",
                        "sources": []
                    },
                    {
                        "path": "README.md",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\README.md",
                        "sources": []
                    },
                    {
                        "path": "data/consolidated/failed_builds.csv",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\failed_builds.csv",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "data/consolidated/successful_builds.csv",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\successful_builds.csv",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "data/consolidated/test_results.csv",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\test_results.csv",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "update-daily.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\update-daily.sh",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "upload_to_sheets.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\upload_to_sheets.py",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "data/junit5/junit5_migration_prs.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\junit5\\junit5_migration_prs.json",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "cmd/find-junit5-prs/main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": [
                            "opened_tab"
                        ]
                    }
                ],
                "rerankedFiles": [
                    {
                        "path": "cmd\\find-junit5-prs\\main.go",
                        "fsPath": "cmd\\find-junit5-prs\\main.go"
                    }
                ],
                "usedFilePaths": [
                    {
                        "path": "cmd\\find-junit5-prs\\main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": [
                            "opened_tab"
                        ],
                        "content": "package main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"math\"\n\t\"math/rand\"\n\t\"os\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/shurcooL/githubv4\"\n\t\"golang.org/x/oauth2\"\n)\n\n// JUnit5PR represents a GitHub pull request related to JUnit 5 migration\ntype JUnit5PR struct {\n\tTitle      string   `json:\"title\"`\n\tURL        string   `json:\"url\"`\n\tRepository string   `json:\"repository\"`\n\tState      string   `json:\"state\"`\n\tAuthor     string   `json:\"author\"`\n\tLabels     []string `json:\"labels\"`\n\tBody       string   `json:\"body\"`\n\tCreatedAt  string   `json:\"createdAt\"`\n}\n\n// SearchResult holds the PRs found in the search\ntype SearchResult struct {\n\tPRs []JUnit5PR `json:\"prs\"`\n}\n\n// GraphQL query structure for searching pull requests\ntype searchQuery struct {\n\tSearch struct {\n\t\tPageInfo struct {\n\t\t\tHasNextPage bool\n\t\t\tEndCursor   githubv4.String\n\t\t}\n\t\tNodes []struct {\n\t\t\tPullRequest struct {\n\t\t\t\tTitle     githubv4.String\n\t\t\t\tURL       githubv4.String\n\t\t\t\tState     githubv4.String\n\t\t\t\tCreatedAt githubv4.DateTime\n\t\t\t\tAuthor    struct {\n\t\t\t\t\tLogin githubv4.String\n\t\t\t\t}\n\t\t\t\tRepository struct {\n\t\t\t\t\tNameWithOwner githubv4.String\n\t\t\t\t}\n\t\t\t\tLabels struct {\n\t\t\t\t\tNodes []struct {\n\t\t\t\t\t\tName githubv4.String\n\t\t\t\t\t}\n\t\t\t\t} `graphql:\"labels(first: 10)\"`\n\t\t\t\tBodyText githubv4.String\n\t\t\t} `graphql:\"... on PullRequest\"`\n\t\t}\n\t} `graphql:\"search(query: $query, type: ISSUE, first: $first, after: $after)\"`\n}\n\nfunc main() {\n\t// Parse command line flags\n\toutputDir := flag.String(\"output-dir\", \"data/junit5\", \"Directory to store output files\")\n\tcandidateFile := flag.String(\"candidate-file\", \"junit5_candidate_prs.txt\", \"File to store candidate PR URLs\")\n\texistingFile := flag.String(\"existing-file\", \"junit5_pr_urls.txt\", \"File containing existing PR URLs\")\n\tstartDate := flag.String(\"start-date\", \"2024-07-01\", \"Start date for PR search (YYYY-MM-DD)\")\n\tflag.Parse()\n\n\t// Get GitHub token from environment\n\ttoken := os.Getenv(\"GITHUB_TOKEN\")\n\tif token == \"\" {\n\t\tfmt.Println(\"GITHUB_TOKEN environment variable is required\")\n\t\tos.Exit(1)\n\t}\n\n\t// Parse start date\n\tstartDateTime, err := time.Parse(\"2006-01-02\", *startDate)\n\tif err != nil {\n\t\tfmt.Printf(\"Error parsing start date: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tfmt.Printf(\"Searching for PRs created on or after: %s\\n\", startDateTime.Format(\"2006-01-02\"))\n\n\t// Create output directory if it doesn't exist\n\tos.MkdirAll(*outputDir, 0755)\n\n\t// Create GitHub client\n\tsrc := oauth2.StaticTokenSource(\n\t\t&oauth2.Token{AccessToken: token},\n\t)\n\thttpClient := oauth2.NewClient(context.Background(), src)\n\tclient := githubv4.NewClient(httpClient)\n\n\t// Define search terms\n\tsearchTerms := []string{\n\t\t\"junit5\",\n\t\t\"junit 5\",\n\t\t\"migrate tests to junit\",\n\t\t\"junit jupiter\",\n\t\t\"openrewrite junit\",\n\t}\n\n\t// Initialize result\n\tresult := SearchResult{\n\t\tPRs: []JUnit5PR{},\n\t}\n\n\t// Search for each term\n\tfor _, term := range searchTerms {\n\t\tfmt.Printf(\"Searching for: %s\\n\", term)\n\n\t\t// Search in title\n\t\ttitleQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:title %s\", term)\n\t\tprs := searchPRs(client, titleQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\n\t\t// Search in body\n\t\tbodyQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:body %s\", term)\n\t\tprs = searchPRs(client, bodyQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\t}\n\n\t// Search for PRs by specific authors known for JUnit 5 migrations\n\tfmt.Println(\"Searching for PRs by known JUnit 5 migration authors...\")\n\tauthorQuery := \"org:jenkinsci is:pr author:strangelookingnerd\"\n\tprs := searchPRs(client, authorQuery, startDateTime)\n\tresult.PRs = append(result.PRs, prs...)\n\n\t// Remove duplicates\n\tresult.PRs = removeDuplicates(result.PRs)\n\n\t// Save results to JSON file\n\tjsonData, err := json.MarshalIndent(result, \"\", \"  \")\n\tif err != nil {\n\t\tfmt.Printf(\"Error marshaling JSON: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\toutputFile := fmt.Sprintf(\"%s/junit5_candidates.json\", *outputDir)\n\terr = ioutil.WriteFile(outputFile, jsonData, 0644)\n\tif err != nil {\n\t\tfmt.Printf(\"Error writing JSON file: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Generate text file with URLs for easy addition to junit5_pr_urls.txt\n\tgenerateCandidateURLsFile(result.PRs, *candidateFile)\n\n\t// Compare with existing PRs in junit5_pr_urls.txt\n\tcompareWithExistingPRs(result.PRs, *existingFile)\n\n\tfmt.Printf(\"Found %d potential JUnit 5 migration PR candidates\\n\", len(result.PRs))\n\tfmt.Printf(\"Results saved to %s and %s\\n\", outputFile, *candidateFile)\n}\n\n// searchPRs performs a GitHub search and returns PRs matching the query\nfunc searchPRs(client *githubv4.Client, query string, startDate time.Time) []JUnit5PR {\n\tvar q searchQuery\n\tvariables := map[string]interface{}{\n\t\t\"query\": githubv4.String(query),\n\t\t\"first\": githubv4.Int(10), // Reduced from 25 to 10 to make queries even less complex\n\t\t\"after\": (*githubv4.String)(nil),\n\t}\n\n\tvar allPRs []JUnit5PR\n\tmaxRetries := 10 // Increased from 5 to 10\n\tinitialBackoff := 2 * time.Second\n\tmaxBackoff := 60 * time.Second\n\n\t// Log the query being executed\n\tfmt.Printf(\"Executing GitHub GraphQL query: %s\\n\", query)\n\tfmt.Printf(\"Start date: %s\\n\", startDate.Format(time.RFC3339))\n\n\tpageCount := 0\n\ttotalAttempts := 0\n\tmaxPages := 100 // Set a maximum page limit to prevent infinite loops\n\n\tfor pageCount < maxPages {\n\t\t// Add a small delay between requests to respect rate limits\n\t\ttime.Sleep(1 * time.Second)\n\n\t\t// Create a context with timeout\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n\n\t\tvar err error\n\t\tsuccess := false\n\n\t\t// Implement retry with exponential backoff\n\t\tfor attempt := 0; attempt < maxRetries && !success; attempt++ {\n\t\t\ttotalAttempts++\n\n\t\t\t// Get current rate limit information before making the request\n\t\t\tvar rateLimit struct {\n\t\t\t\tRateLimit struct {\n\t\t\t\t\tLimit     githubv4.Int\n\t\t\t\t\tRemaining githubv4.Int\n\t\t\t\t\tResetAt   githubv4.DateTime\n\t\t\t\t} `graphql:\"rateLimit\"`\n\t\t\t}\n\n\t\t\trateLimitErr := client.Query(context.Background(), &rateLimit, nil)\n\t\t\tif rateLimitErr == nil {\n\t\t\t\tfmt.Printf(\"GitHub API rate limit: %d/%d remaining, resets at %s\\n\",\n\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\trateLimit.RateLimit.Limit,\n\t\t\t\t\trateLimit.RateLimit.ResetAt.Format(time.RFC3339))\n\n\t\t\t\t// Check if we're close to hitting the rate limit\n\t\t\t\tif rateLimit.RateLimit.Remaining < 100 {\n\t\t\t\t\tresetTime := time.Until(rateLimit.RateLimit.ResetAt.Time)\n\t\t\t\t\tfmt.Printf(\"WARNING: Rate limit is low (%d remaining). Limit resets in %s\\n\",\n\t\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\t\tresetTime.Round(time.Second))\n\n\t\t\t\t\tif rateLimit.RateLimit.Remaining < 10 {\n\t\t\t\t\t\tfmt.Println(\"Rate limit critically low, waiting until reset...\")\n\t\t\t\t\t\twaitTime := time.Until(rateLimit.RateLimit.ResetAt.Time) + 10*time.Second\n\t\t\t\t\t\ttime.Sleep(waitTime)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfmt.Printf(\"Could not fetch rate limit info: %v\\n\", rateLimitErr)\n\t\t\t}\n\n\t\t\t// Execute the actual query\n\t\t\tstartTime := time.Now()\n\t\t\terr = client.Query(ctx, &q, variables)\n\t\t\tqueryDuration := time.Since(startTime)\n\n\t\t\tif err == nil {\n\t\t\t\tsuccess = true\n\t\t\t\tfmt.Printf(\"Query succeeded in %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t\t// Log the number of results received\n\t\t\t\tresultCount := len(q.Search.Nodes)\n\t\t\t\tfmt.Printf(\"Received %d results for page %d\\n\", resultCount, pageCount+1)\n\n\t\t\t\t// Process the results\n\t\t\t\tfor _, node := range q.Search.Nodes {\n\t\t\t\t\tpr := node.PullRequest\n\n\t\t\t\t\t// Extract labels\n\t\t\t\t\tvar labels []string\n\t\t\t\t\tfor _, label := range pr.Labels.Nodes {\n\t\t\t\t\t\tlabels = append(labels, string(label.Name))\n\t\t\t\t\t}\n\n\t\t\t\t\t// Create PR object\n\t\t\t\t\tnewPR := JUnit5PR{\n\t\t\t\t\t\tTitle:      string(pr.Title),\n\t\t\t\t\t\tURL:        string(pr.URL),\n\t\t\t\t\t\tRepository: string(pr.Repository.NameWithOwner),\n\t\t\t\t\t\tState:      string(pr.State),\n\t\t\t\t\t\tAuthor:     string(pr.Author.Login),\n\t\t\t\t\t\tLabels:     labels,\n\t\t\t\t\t\tBody:       string(pr.BodyText),\n\t\t\t\t\t\tCreatedAt:  pr.CreatedAt.Format(time.RFC3339),\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs created on or after the start date\n\t\t\t\t\tif pr.CreatedAt.Before(startDate) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs that are likely related to JUnit 5 migration\n\t\t\t\t\tif isJUnit5MigrationPR(newPR) {\n\t\t\t\t\t\tallPRs = append(allPRs, newPR)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Log progress\n\t\t\t\tfmt.Printf(\"Processed page %d, found %d matching PRs so far\\n\", pageCount+1, len(allPRs))\n\n\t\t\t\t// Check if there are more pages\n\t\t\t\tif !q.Search.PageInfo.HasNextPage {\n\t\t\t\t\tfmt.Printf(\"No more pages available, completed after %d pages\\n\", pageCount+1)\n\t\t\t\t\tcancel()      // Cancel the context before returning\n\t\t\t\t\treturn allPRs // Exit the function when no more pages\n\t\t\t\t}\n\n\t\t\t\t// Move to next page\n\t\t\t\tfmt.Printf(\"Moving to next page with cursor: %s\\n\", q.Search.PageInfo.EndCursor)\n\t\t\t\tvariables[\"after\"] = githubv4.NewString(q.Search.PageInfo.EndCursor)\n\n\t\t\t\t// Increment page count\n\t\t\t\tpageCount++\n\n\t\t\t\t// Add a small delay before the next page to avoid overwhelming GitHub\n\t\t\t\ttime.Sleep(1 * time.Second)\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Log detailed error information\n\t\t\tfmt.Printf(\"GitHub API error on attempt %d/%d (total %d): %v\\n\",\n\t\t\t\tattempt+1, maxRetries, totalAttempts, err)\n\t\t\tfmt.Printf(\"Query duration before error: %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t// Try to parse and log more details from the error\n\t\t\tvar errorDetails struct {\n\t\t\t\tData   interface{}              `json:\"data\"`\n\t\t\t\tErrors []map[string]interface{} `json:\"errors\"`\n\t\t\t}\n\n\t\t\tif strings.Contains(err.Error(), \"{\") {\n\t\t\t\terrorJSON := err.Error()[strings.Index(err.Error(), \"{\"):]\n\t\t\t\tif jsonErr := json.Unmarshal([]byte(errorJSON), &errorDetails); jsonErr == nil {\n\t\t\t\t\tif errorDetails.Errors != nil && len(errorDetails.Errors) > 0 {\n\t\t\t\t\t\tfmt.Println(\"Detailed error information:\")\n\t\t\t\t\t\tfor i, errDetail := range errorDetails.Errors {\n\t\t\t\t\t\t\tfmt.Printf(\"  Error %d:\\n\", i+1)\n\t\t\t\t\t\t\tfor k, v := range errDetail {\n\t\t\t\t\t\t\t\tfmt.Printf(\"    %s: %v\\n\", k, v)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Check if this is a retryable error (like 502)\n\t\t\tif strings.Contains(err.Error(), \"502\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"timeout\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"Something went wrong\") {\n\n\t\t\t\t// Calculate backoff duration with exponential increase and jitter\n\t\t\t\tbackoffTime := float64(initialBackoff) * math.Pow(2, float64(attempt))\n\t\t\t\tif backoffTime > float64(maxBackoff) {\n\t\t\t\t\tbackoffTime = float64(maxBackoff)\n\t\t\t\t}\n\n\t\t\t\t// Add jitter (±20%)\n\t\t\t\tjitter := (rand.Float64() * 0.4) - 0.2 // -20% to +20%\n\t\t\t\tbackoffTime = backoffTime * (1 + jitter)\n\n\t\t\t\tsleepDuration := time.Duration(backoffTime)\n\t\t\t\tfmt.Printf(\"Retrying in %v...\\n\", sleepDuration)\n\t\t\t\ttime.Sleep(sleepDuration)\n\t\t\t} else {\n\t\t\t\t// Non-retryable error, break out\n\t\t\t\tfmt.Println(\"Non-retryable error encountered, stopping retry attempts\")\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !success {\n\t\t\tfmt.Printf(\"Failed after %d attempts: %v\\n\", maxRetries, err)\n\t\t\tfmt.Println(\"Continuing with results collected so far...\")\n\t\t\tcancel() // Cancel the context before returning\n\t\t\treturn allPRs\n\t\t}\n\n\t\t// Cancel the context after we're done with it\n\t\tcancel()\n\t}\n\n\t// If we've reached the maximum number of pages, log a message\n\tfmt.Printf(\"Reached maximum page limit (%d). Stopping to prevent excessive API usage.\\n\", maxPages)\n\treturn allPRs\n}\n\n// isJUnit5MigrationPR checks if a PR is likely related to JUnit 5 migration\nfunc isJUnit5MigrationPR(pr JUnit5PR) bool {\n\t// Exclude dependency bumps\n\tif strings.HasPrefix(pr.Title, \"Bump\") || strings.HasPrefix(pr.Title, \"bump\") {\n\t\treturn false\n\t}\n\n\t// Exclude PRs with specific JIRA ticket prefixes that are known not to be JUnit 5 related\n\t// These are examples of tickets that were incorrectly included\n\texcludePatterns := []string{\n\t\t`(?i)JENKINS-70560`,         // Improve test coverage\n\t\t`(?i)JENKINS-75447`,         // Fix Snippetizer rendering\n\t\t`(?i)JENKINS-\\d+.*fix`,      // General fixes\n\t\t`(?i)fix`,                   // General fixes\n\t\t`(?i)improve test coverage`, // Test coverage improvements not related to JUnit 5\n\t}\n\n\tfor _, pattern := range excludePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Define more specific patterns for JUnit 5 migration PRs\n\ttitlePatterns := []string{\n\t\t`(?i)migrate tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t}\n\n\tbodyPatterns := []string{\n\t\t`(?i)migrate (all )?tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t\t`(?i)org\\.junit\\.jupiter`,\n\t\t`(?i)junit-jupiter`,\n\t}\n\n\tlabelPatterns := []string{\n\t\t`(?i)\\bjunit ?5\\b`,\n\t\t`(?i)junit-5`,\n\t\t`(?i)junit-migration`,\n\t}\n\n\tauthorPatterns := []string{\n\t\t`strangelookingnerd`,\n\t}\n\n\t// Check title with more specific matching\n\tfor _, pattern := range titlePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn true\n\t\t}\n\t}\n\n\t// For body matches, require stronger evidence\n\t// Count how many patterns match in the body\n\tbodyMatchCount := 0\n\tfor _, pattern := range bodyPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Body)\n\t\tif matched {\n\t\t\tbodyMatchCount++\n\t\t}\n\t}\n\n\t// Require at least 2 body pattern matches for a positive identification\n\t// This helps avoid false positives from PRs that mention JUnit in passing\n\tif bodyMatchCount >= 2 {\n\t\treturn true\n\t}\n\n\t// Check labels\n\tfor _, label := range pr.Labels {\n\t\tfor _, pattern := range labelPatterns {\n\t\t\tmatched, _ := regexp.MatchString(pattern, label)\n\t\t\tif matched {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check author - but only if there's at least some mention of JUnit in the body\n\t// This avoids including all PRs from certain authors\n\tfor _, pattern := range authorPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Author)\n\t\tif matched {\n\t\t\t// Check if there's at least some mention of JUnit in the body\n\t\t\tjunitmatch, _ := regexp.MatchString(`(?i)junit`, pr.Body)\n\t\t\tif junitmatch {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\treturn false\n}\n\n// removeDuplicates removes duplicate PRs from the slice\nfunc removeDuplicates(prs []JUnit5PR) []JUnit5PR {\n\tseen := make(map[string]bool)\n\tvar result []JUnit5PR\n\n\tfor _, pr := range prs {\n\t\tif !seen[pr.URL] {\n\t\t\tseen[pr.URL] = true\n\t\t\tresult = append(result, pr)\n\t\t}\n\t}\n\n\treturn result\n}\n\n// generateCandidateURLsFile creates a text file with PR URLs for easy addition to junit5_pr_urls.txt\nfunc generateCandidateURLsFile(prs []JUnit5PR, outputFile string) {\n\tfile, err := os.Create(outputFile)\n\tif err != nil {\n\t\tfmt.Printf(\"Error creating file: %v\\n\", err)\n\t\treturn\n\t}\n\tdefer file.Close()\n\n\tfile.WriteString(fmt.Sprintf(\"# JUnit 5 migration PR candidates found on %s\\n\", time.Now().Format(\"2006-01-02 15:04:05\")))\n\tfile.WriteString(\"# Add relevant URLs to junit5_pr_urls.txt after verification\\n\\n\")\n\n\tfor _, pr := range prs {\n\t\tfile.WriteString(fmt.Sprintf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State))\n\t\tfile.WriteString(fmt.Sprintf(\"%s\\n\\n\", pr.URL))\n\t}\n}\n\n// compareWithExistingPRs compares found PRs with those already in junit5_pr_urls.txt\nfunc compareWithExistingPRs(prs []JUnit5PR, existingFile string) {\n\t// Read existing PR URLs\n\texistingURLs := make(map[string]bool)\n\n\tdata, err := ioutil.ReadFile(existingFile)\n\tif err == nil {\n\t\tlines := strings.Split(string(data), \"\\n\")\n\t\tfor _, line := range lines {\n\t\t\tline = strings.TrimSpace(line)\n\t\t\tif strings.HasPrefix(line, \"https://\") {\n\t\t\t\texistingURLs[line] = true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Find new PRs\n\tvar newPRs []JUnit5PR\n\tfor _, pr := range prs {\n\t\tif !existingURLs[pr.URL] {\n\t\t\tnewPRs = append(newPRs, pr)\n\t\t}\n\t}\n\n\tfmt.Printf(\"Found %d new PR candidates not already in %s\\n\", len(newPRs), existingFile)\n\n\tif len(newPRs) > 0 {\n\t\tfmt.Println(\"New PR candidates:\")\n\t\tfor _, pr := range newPRs {\n\t\t\tfmt.Printf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State)\n\t\t\tfmt.Printf(\"%s\\n\\n\", pr.URL)\n\t\t}\n\t}\n}\n"
                    }
                ]
            },
            "createdAt": 1745335135869,
            "isInternal": false
        }
    ],
    "isAgent": false,
    "isNameGenerated": true,
    "isCustomAgent": false,
    "isUnitTestsAgent": false,
    "autoApply": false
}
}