{
    "checksum": "65ed85ba3c7cf9486edf077ace02d2e36a3923f79784cdfa53f35fb42b70f2ba",
    "data": {
    "id": "0bda0514-c42a-4db8-b165-b3aea5a53f9b",
    "createdAt": 1744710463187,
    "updatedAt": 1744720394634,
    "title": "Go Code Syntax Errors",
    "messages": [
        {
            "id": "0c495095-f63e-44b4-8dac-f43bffcb0e01",
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "2025-04-15 11:46:56,502 - INFO - Successfully applied 1 format requests"
                },
                {
                    "type": "text",
                    "text": "2025-04-15 11:47:08,502 - INFO - Data has been uploaded to Google Sheets."
                },
                {
                    "type": "text",
                    "text": "Note: To force an update of the successful builds sheet, run with the force parameter: python3 upload_to_sheets.py \"data/consolidated/all_prs.json\" false true"
                },
                {
                    "type": "text",
                    "text": "Running JUnit 5 migration PR analysis..."
                },
                {
                    "type": "text",
                    "text": "Finding JUnit 5 migration PRs..."
                },
                {
                    "type": "text",
                    "text": "Output directory: data/junit5"
                },
                {
                    "type": "text",
                    "text": "Candidate file: junit5_candidate_prs.txt"
                },
                {
                    "type": "text",
                    "text": "Existing file: junit5_pr_urls.txt"
                },
                {
                    "type": "text",
                    "text": "Downloading dependencies..."
                },
                {
                    "type": "text",
                    "text": "Building and running the JUnit 5 PR finder..."
                },
                {
                    "type": "text",
                    "text": "# command-line-arguments"
                },
                {
                    "type": "text",
                    "text": "./main.go:313:5: syntax error: unexpected if, expected expression"
                },
                {
                    "type": "text",
                    "text": "./main.go:314:6: syntax error: unexpected if, expected expression"
                },
                {
                    "type": "text",
                    "text": "./main.go:358:2: syntax error: non-declaration statement outside function body"
                }
            ],
            "context": {
                "currentFile": {
                    "path": "cmd\\find-junit5-prs\\main.go",
                    "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                    "sources": [
                        "opened_tab"
                    ],
                    "content": "package main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"math\"\n\t\"math/rand\"\n\t\"net/http\"\n\t\"os\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/shurcooL/githubv4\"\n\t\"golang.org/x/oauth2\"\n)\n\n// JUnit5PR represents a GitHub pull request related to JUnit 5 migration\ntype JUnit5PR struct {\n\tTitle      string   `json:\"title\"`\n\tURL        string   `json:\"url\"`\n\tRepository string   `json:\"repository\"`\n\tState      string   `json:\"state\"`\n\tAuthor     string   `json:\"author\"`\n\tLabels     []string `json:\"labels\"`\n\tBody       string   `json:\"body\"`\n\tCreatedAt  string   `json:\"createdAt\"`\n}\n\n// SearchResult holds the PRs found in the search\ntype SearchResult struct {\n\tPRs []JUnit5PR `json:\"prs\"`\n}\n\n// GraphQL query structure for searching pull requests\ntype searchQuery struct {\n\tSearch struct {\n\t\tPageInfo struct {\n\t\t\tHasNextPage bool\n\t\t\tEndCursor   githubv4.String\n\t\t}\n\t\tNodes []struct {\n\t\t\tPullRequest struct {\n\t\t\t\tTitle     githubv4.String\n\t\t\t\tURL       githubv4.String\n\t\t\t\tState     githubv4.String\n\t\t\t\tCreatedAt githubv4.DateTime\n\t\t\t\tAuthor    struct {\n\t\t\t\t\tLogin githubv4.String\n\t\t\t\t}\n\t\t\t\tRepository struct {\n\t\t\t\t\tNameWithOwner githubv4.String\n\t\t\t\t}\n\t\t\t\tLabels struct {\n\t\t\t\t\tNodes []struct {\n\t\t\t\t\t\tName githubv4.String\n\t\t\t\t\t}\n\t\t\t\t} `graphql:\"labels(first: 10)\"`\n\t\t\t\tBodyText githubv4.String\n\t\t\t} `graphql:\"... on PullRequest\"`\n\t\t}\n\t} `graphql:\"search(query: $query, type: ISSUE, first: $first, after: $after)\"`\n}\n\nfunc main() {\n\t// Parse command line flags\n\toutputDir := flag.String(\"output-dir\", \"data/junit5\", \"Directory to store output files\")\n\tcandidateFile := flag.String(\"candidate-file\", \"junit5_candidate_prs.txt\", \"File to store candidate PR URLs\")\n\texistingFile := flag.String(\"existing-file\", \"junit5_pr_urls.txt\", \"File containing existing PR URLs\")\n\tstartDate := flag.String(\"start-date\", \"2024-07-01\", \"Start date for PR search (YYYY-MM-DD)\")\n\tflag.Parse()\n\n\t// Get GitHub token from environment\n\ttoken := os.Getenv(\"GITHUB_TOKEN\")\n\tif token == \"\" {\n\t\tfmt.Println(\"GITHUB_TOKEN environment variable is required\")\n\t\tos.Exit(1)\n\t}\n\n\t// Parse start date\n\tstartDateTime, err := time.Parse(\"2006-01-02\", *startDate)\n\tif err != nil {\n\t\tfmt.Printf(\"Error parsing start date: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tfmt.Printf(\"Searching for PRs created on or after: %s\\n\", startDateTime.Format(\"2006-01-02\"))\n\n\t// Create output directory if it doesn't exist\n\tos.MkdirAll(*outputDir, 0755)\n\n\t// Create GitHub client\n\tsrc := oauth2.StaticTokenSource(\n\t\t&oauth2.Token{AccessToken: token},\n\t)\n\thttpClient := oauth2.NewClient(context.Background(), src)\n\tclient := githubv4.NewClient(httpClient)\n\n\t// Define search terms\n\tsearchTerms := []string{\n\t\t\"junit5\",\n\t\t\"junit 5\",\n\t\t\"migrate tests to junit\",\n\t\t\"junit jupiter\",\n\t\t\"openrewrite junit\",\n\t}\n\n\t// Initialize result\n\tresult := SearchResult{\n\t\tPRs: []JUnit5PR{},\n\t}\n\n\t// Search for each term\n\tfor _, term := range searchTerms {\n\t\tfmt.Printf(\"Searching for: %s\\n\", term)\n\n\t\t// Search in title\n\t\ttitleQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:title %s\", term)\n\t\tprs := searchPRs(client, titleQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\n\t\t// Search in body\n\t\tbodyQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:body %s\", term)\n\t\tprs = searchPRs(client, bodyQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\t}\n\n\t// Search for PRs by specific authors known for JUnit 5 migrations\n\tfmt.Println(\"Searching for PRs by known JUnit 5 migration authors...\")\n\tauthorQuery := \"org:jenkinsci is:pr author:strangelookingnerd\"\n\tprs := searchPRs(client, authorQuery, startDateTime)\n\tresult.PRs = append(result.PRs, prs...)\n\n\t// Remove duplicates\n\tresult.PRs = removeDuplicates(result.PRs)\n\n\t// Save results to JSON file\n\tjsonData, err := json.MarshalIndent(result, \"\", \"  \")\n\tif err != nil {\n\t\tfmt.Printf(\"Error marshaling JSON: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\toutputFile := fmt.Sprintf(\"%s/junit5_candidates.json\", *outputDir)\n\terr = ioutil.WriteFile(outputFile, jsonData, 0644)\n\tif err != nil {\n\t\tfmt.Printf(\"Error writing JSON file: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Generate text file with URLs for easy addition to junit5_pr_urls.txt\n\tgenerateCandidateURLsFile(result.PRs, *candidateFile)\n\n\t// Compare with existing PRs in junit5_pr_urls.txt\n\tcompareWithExistingPRs(result.PRs, *existingFile)\n\n\tfmt.Printf(\"Found %d potential JUnit 5 migration PR candidates\\n\", len(result.PRs))\n\tfmt.Printf(\"Results saved to %s and %s\\n\", outputFile, *candidateFile)\n}\n\n// searchPRs performs a GitHub search and returns PRs matching the query\nfunc searchPRs(client *githubv4.Client, query string, startDate time.Time) []JUnit5PR {\n\tvar q searchQuery\n\tvariables := map[string]interface{}{\n\t\t\"query\": githubv4.String(query),\n\t\t\"first\": githubv4.Int(10), // Reduced from 25 to 10 to make queries even less complex\n\t\t\"after\": (*githubv4.String)(nil),\n\t}\n\n\tvar allPRs []JUnit5PR\n\tmaxRetries := 10 // Increased from 5 to 10\n\tinitialBackoff := 2 * time.Second\n\tmaxBackoff := 60 * time.Second\n\n\t// Log the query being executed\n\tfmt.Printf(\"Executing GitHub GraphQL query: %s\\n\", query)\n\tfmt.Printf(\"Start date: %s\\n\", startDate.Format(time.RFC3339))\n\n\tpageCount := 0\n\ttotalAttempts := 0\n\tfor {\n\t\t// Add a small delay between requests to respect rate limits\n\t\ttime.Sleep(1 * time.Second)\n\n\t\t// Create a context with timeout\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n\t\tdefer cancel()\n\n\t\tvar err error\n\t\tsuccess := false\n\n\t\t// Implement retry with exponential backoff\n\t\tfor attempt := 0; attempt < maxRetries && !success; attempt++ {\n\t\t\ttotalAttempts++\n\n\t\t\t// Get current rate limit information before making the request\n\t\t\tvar rateLimit struct {\n\t\t\t\tRateLimit struct {\n\t\t\t\t\tLimit     githubv4.Int\n\t\t\t\t\tRemaining githubv4.Int\n\t\t\t\t\tResetAt   githubv4.DateTime\n\t\t\t\t} `graphql:\"rateLimit\"`\n\t\t\t}\n\n\t\t\trateLimitErr := client.Query(context.Background(), &rateLimit, nil)\n\t\t\tif rateLimitErr == nil {\n\t\t\t\tfmt.Printf(\"GitHub API rate limit: %d/%d remaining, resets at %s\\n\",\n\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\trateLimit.RateLimit.Limit,\n\t\t\t\t\trateLimit.RateLimit.ResetAt.Format(time.RFC3339))\n\n\t\t\t\t// Check if we're close to hitting the rate limit\n\t\t\t\tif rateLimit.RateLimit.Remaining < 100 {\n\t\t\t\t\tresetTime := time.Until(rateLimit.RateLimit.ResetAt.Time)\n\t\t\t\t\tfmt.Printf(\"WARNING: Rate limit is low (%d remaining). Limit resets in %s\\n\",\n\t\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\t\tresetTime.Round(time.Second))\n\n\t\t\t\t\tif rateLimit.RateLimit.Remaining < 10 {\n\t\t\t\t\t\tfmt.Println(\"Rate limit critically low, waiting until reset...\")\n\t\t\t\t\t\twaitTime := time.Until(rateLimit.RateLimit.ResetAt.Time) + 10*time.Second\n\t\t\t\t\t\ttime.Sleep(waitTime)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfmt.Printf(\"Could not fetch rate limit info: %v\\n\", rateLimitErr)\n\t\t\t}\n\n\t\t\t// Execute the actual query\n\t\t\tstartTime := time.Now()\n\t\t\terr = client.Query(ctx, &q, variables)\n\t\t\tqueryDuration := time.Since(startTime)\n\n\t\t\tif err == nil {\n\t\t\t\tsuccess = true\n\t\t\t\tfmt.Printf(\"Query succeeded in %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t\t// Log the number of results received\n\t\t\t\tresultCount := len(q.Search.Nodes)\n\t\t\t\tfmt.Printf(\"Received %d results for page %d\\n\", resultCount, pageCount+1)\n\n\t\t\t\t// Process the results\n\t\t\t\tfor _, node := range q.Search.Nodes {\n\t\t\t\t\tpr := node.PullRequest\n\n\t\t\t\t\t// Extract labels\n\t\t\t\t\tvar labels []string\n\t\t\t\t\tfor _, label := range pr.Labels.Nodes {\n\t\t\t\t\t\tlabels = append(labels, string(label.Name))\n\t\t\t\t\t}\n\n\t\t\t\t\t// Create PR object\n\t\t\t\t\tnewPR := JUnit5PR{\n\t\t\t\t\t\tTitle:      string(pr.Title),\n\t\t\t\t\t\tURL:        string(pr.URL),\n\t\t\t\t\t\tRepository: string(pr.Repository.NameWithOwner),\n\t\t\t\t\t\tState:      string(pr.State),\n\t\t\t\t\t\tAuthor:     string(pr.Author.Login),\n\t\t\t\t\t\tLabels:     labels,\n\t\t\t\t\t\tBody:       string(pr.BodyText),\n\t\t\t\t\t\tCreatedAt:  pr.CreatedAt.Format(time.RFC3339),\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs created on or after the start date\n\t\t\t\t\tif pr.CreatedAt.Before(startDate) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs that are likely related to JUnit 5 migration\n\t\t\t\t\tif isJUnit5MigrationPR(newPR) {\n\t\t\t\t\t\tallPRs = append(allPRs, newPR)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Log progress\n\t\t\t\tfmt.Printf(\"Processed page %d, found %d matching PRs so far\\n\", pageCount+1, len(allPRs))\n\n\t\t\t\t// Check if there are more pages\n\t\t\t\tif !q.Search.PageInfo.HasNextPage {\n\t\t\t\t\tfmt.Printf(\"No more pages available, completed after %d pages\\n\", pageCount+1)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\n\t\t\t\t// Move to next page\n\t\t\t\tfmt.Printf(\"Moving to next page with cursor: %s\\n\", q.Search.PageInfo.EndCursor)\n\t\t\t\tvariables[\"after\"] = githubv4.NewString(q.Search.PageInfo.EndCursor)\n\n\t\t\t\t// Reset the attempt counter since we successfully processed this page\n\t\t\t\tattempt = 0\n\n\t\t\t\t// Add a small delay before the next page to avoid overwhelming GitHub\n\t\t\t\ttime.Sleep(1 * time.Second)\n\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Log detailed error information\n\t\t\tfmt.Printf(\"GitHub API error on attempt %d/%d (total %d): %v\\n\",\n\t\t\t\tattempt+1, maxRetries, totalAttempts, err)\n\t\t\tfmt.Printf(\"Query duration before error: %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t// Try to parse and log more details from the error\n\t\t\tvar errorDetails struct {\n\t\t\t\tData   interface{}            `json:\"data\"`\n\t\t\t\tErrors []map[string]interface{} `json:\"errors\"`\n\t\t\t}\n\n\t\t\tif strings.Contains(err.Error(), \"{\") {\n\t\t\t\terrorJSON := err.Error()[strings.Index(err.Error(), \"{\"): // Removed the -1\n\t\t\t\tif jsonErr := json.Unmarshal([]byte(errorJSON), &errorDetails); jsonErr == nil {\n\t\t\t\t\tif errorDetails.Errors != nil && len(errorDetails.Errors) > 0 {\n\t\t\t\t\t\tfmt.Println(\"Detailed error information:\")\n\t\t\t\t\t\tfor i, errDetail := range errorDetails.Errors {\n\t\t\t\t\t\t\tfmt.Printf(\"  Error %d:\\n\", i+1)\n\t\t\t\t\t\t\tfor k, v := range errDetail {\n\t\t\t\t\t\t\t\tfmt.Printf(\"    %s: %v\\n\", k, v)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Check if this is a retryable error (like 502)\n\t\t\tif strings.Contains(err.Error(), \"502\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"timeout\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"Something went wrong\") {\n\n\t\t\t\t// Calculate backoff duration with exponential increase and jitter\n\t\t\t\tbackoffTime := float64(initialBackoff) * math.Pow(2, float64(attempt))\n\t\t\t\tif backoffTime > float64(maxBackoff) {\n\t\t\t\t\tbackoffTime = float64(maxBackoff)\n\t\t\t\t}\n\n\t\t\t\t// Add jitter (±20%)\n\t\t\t\tjitter := (rand.Float64() * 0.4) - 0.2 // -20% to +20%\n\t\t\t\tbackoffTime = backoffTime * (1 + jitter)\n\n\t\t\t\tsleepDuration := time.Duration(backoffTime)\n\t\t\t\tfmt.Printf(\"Retrying in %v...\\n\", sleepDuration)\n\t\t\t\ttime.Sleep(sleepDuration)\n\t\t\t} else {\n\t\t\t\t// Non-retryable error, break out\n\t\t\t\tfmt.Println(\"Non-retryable error encountered, stopping retry attempts\")\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !success {\n\t\t\tfmt.Printf(\"Failed after %d attempts: %v\\n\", maxRetries, err)\n\t\t\tfmt.Println(\"Continuing with results collected so far...\")\n\t\t\treturn allPRs\n\t\t}\n\t}\n\n\tfmt.Printf(\"Search completed. Found %d matching PRs for query: %s\\n\", len(allPRs), query)\n\treturn allPRs\n}\n\n// isJUnit5MigrationPR checks if a PR is likely related to JUnit 5 migration\nfunc isJUnit5MigrationPR(pr JUnit5PR) bool {\n\t// Exclude dependency bumps\n\tif strings.HasPrefix(pr.Title, \"Bump\") || strings.HasPrefix(pr.Title, \"bump\") {\n\t\treturn false\n\t}\n\n\t// Exclude PRs with specific JIRA ticket prefixes that are known not to be JUnit 5 related\n\t// These are examples of tickets that were incorrectly included\n\texcludePatterns := []string{\n\t\t`(?i)JENKINS-70560`,         // Improve test coverage\n\t\t`(?i)JENKINS-75447`,         // Fix Snippetizer rendering\n\t\t`(?i)JENKINS-\\d+.*fix`,      // General fixes\n\t\t`(?i)fix`,                   // General fixes\n\t\t`(?i)improve test coverage`, // Test coverage improvements not related to JUnit 5\n\t}\n\n\tfor _, pattern := range excludePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Define more specific patterns for JUnit 5 migration PRs\n\ttitlePatterns := []string{\n\t\t`(?i)migrate tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t}\n\n\tbodyPatterns := []string{\n\t\t`(?i)migrate (all )?tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t\t`(?i)org\\.junit\\.jupiter`,\n\t\t`(?i)junit-jupiter`,\n\t}\n\n\tlabelPatterns := []string{\n\t\t`(?i)\\bjunit ?5\\b`,\n\t\t`(?i)junit-5`,\n\t\t`(?i)junit-migration`,\n\t}\n\n\tauthorPatterns := []string{\n\t\t`strangelookingnerd`,\n\t}\n\n\t// Check title with more specific matching\n\tfor _, pattern := range titlePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn true\n\t\t}\n\t}\n\n\t// For body matches, require stronger evidence\n\t// Count how many patterns match in the body\n\tbodyMatchCount := 0\n\tfor _, pattern := range bodyPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Body)\n\t\tif matched {\n\t\t\tbodyMatchCount++\n\t\t}\n\t}\n\n\t// Require at least 2 body pattern matches for a positive identification\n\t// This helps avoid false positives from PRs that mention JUnit in passing\n\tif bodyMatchCount >= 2 {\n\t\treturn true\n\t}\n\n\t// Check labels\n\tfor _, label := range pr.Labels {\n\t\tfor _, pattern := range labelPatterns {\n\t\t\tmatched, _ := regexp.MatchString(pattern, label)\n\t\t\tif matched {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check author - but only if there's at least some mention of JUnit in the body\n\t// This avoids including all PRs from certain authors\n\tfor _, pattern := range authorPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Author)\n\t\tif matched {\n\t\t\t// Check if there's at least some mention of JUnit in the body\n\t\t\tjunitmatch, _ := regexp.MatchString(`(?i)junit`, pr.Body)\n\t\t\tif junitmatch {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\treturn false\n}\n\n// removeDuplicates removes duplicate PRs from the slice\nfunc removeDuplicates(prs []JUnit5PR) []JUnit5PR {\n\tseen := make(map[string]bool)\n\tvar result []JUnit5PR\n\n\tfor _, pr := range prs {\n\t\tif !seen[pr.URL] {\n\t\t\tseen[pr.URL] = true\n\t\t\tresult = append(result, pr)\n\t\t}\n\t}\n\n\treturn result\n}\n\n// generateCandidateURLsFile creates a text file with PR URLs for easy addition to junit5_pr_urls.txt\nfunc generateCandidateURLsFile(prs []JUnit5PR, outputFile string) {\n\tfile, err := os.Create(outputFile)\n\tif err != nil {\n\t\tfmt.Printf(\"Error creating file: %v\\n\", err)\n\t\treturn\n\t}\n\tdefer file.Close()\n\n\tfile.WriteString(fmt.Sprintf(\"# JUnit 5 migration PR candidates found on %s\\n\", time.Now().Format(\"2006-01-02 15:04:05\")))\n\tfile.WriteString(\"# Add relevant URLs to junit5_pr_urls.txt after verification\\n\\n\")\n\n\tfor _, pr := range prs {\n\t\tfile.WriteString(fmt.Sprintf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State))\n\t\tfile.WriteString(fmt.Sprintf(\"%s\\n\\n\", pr.URL))\n\t}\n}\n\n// compareWithExistingPRs compares found PRs with those already in junit5_pr_urls.txt\nfunc compareWithExistingPRs(prs []JUnit5PR, existingFile string) {\n\t// Read existing PR URLs\n\texistingURLs := make(map[string]bool)\n\n\tdata, err := ioutil.ReadFile(existingFile)\n\tif err == nil {\n\t\tlines := strings.Split(string(data), \"\\n\")\n\t\tfor _, line := range lines {\n\t\t\tline = strings.TrimSpace(line)\n\t\t\tif strings.HasPrefix(line, \"https://\") {\n\t\t\t\texistingURLs[line] = true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Find new PRs\n\tvar newPRs []JUnit5PR\n\tfor _, pr := range prs {\n\t\tif !existingURLs[pr.URL] {\n\t\t\tnewPRs = append(newPRs, pr)\n\t\t}\n\t}\n\n\tfmt.Printf(\"Found %d new PR candidates not already in %s\\n\", len(newPRs), existingFile)\n\n\tif len(newPRs) > 0 {\n\t\tfmt.Println(\"New PR candidates:\")\n\t\tfor _, pr := range newPRs {\n\t\t\tfmt.Printf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State)\n\t\t\tfmt.Printf(\"%s\\n\\n\", pr.URL)\n\t\t}\n\t}\n}\n"
                },
                "codebaseEnabled": true,
                "ragFiles": [
                    {
                        "path": "venv/lib/python3.13/site-packages/gspread/spreadsheet.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\gspread\\spreadsheet.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "upload_to_sheets.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\upload_to_sheets.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/traceback.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\traceback.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/tree.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\tree.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/syntax.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\syntax.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/progress.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\progress.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/live.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\live.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/__main__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\__main__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/segment.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\segment.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/urllib3/contrib/appengine.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\urllib3\\contrib\\appengine.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/_credentials_base.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\_credentials_base.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/_helpers.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\_helpers.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/_credentials_async.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\_credentials_async.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/metrics.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\metrics.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/_exponential_backoff.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\_exponential_backoff.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/_refresh_worker.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\_refresh_worker.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/aio/__init__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\aio\\__init__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/crypt/base.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\crypt\\base.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/transport/_custom_tls_signer.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\transport\\_custom_tls_signer.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/transport/_mtls_helper.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\transport\\_mtls_helper.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "cmd\\find-junit5-prs\\main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": []
                    },
                    {
                        "path": "junit5-migration-prs.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\junit5-migration-prs.sh",
                        "sources": []
                    },
                    {
                        "path": "analyze-junit5-prs.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\analyze-junit5-prs.sh",
                        "sources": []
                    },
                    {
                        "path": "find-junit5-prs.go.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\find-junit5-prs.go.sh",
                        "sources": []
                    },
                    {
                        "path": "find-junit5-prs.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\find-junit5-prs.sh",
                        "sources": []
                    },
                    {
                        "path": "update-daily.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\update-daily.sh",
                        "sources": []
                    },
                    {
                        "path": "README.md",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\README.md",
                        "sources": []
                    },
                    {
                        "path": "data\\junit5\\common_patterns.txt",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\junit5\\common_patterns.txt",
                        "sources": []
                    },
                    {
                        "path": "jenkins-pr-collector-readme.md",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\jenkins-pr-collector-readme.md",
                        "sources": []
                    },
                    {
                        "path": "data\\junit5\\junit5_prs_by_repo.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\junit5\\junit5_prs_by_repo.json",
                        "sources": []
                    },
                    {
                        "path": "junit5_candidate_prs.txt",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\junit5_candidate_prs.txt",
                        "sources": []
                    },
                    {
                        "path": "data\\junit5\\detection_patterns.txt",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\junit5\\detection_patterns.txt",
                        "sources": []
                    },
                    {
                        "path": "data/consolidated/failed_builds.csv",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\failed_builds.csv",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "data/consolidated/successful_builds.csv",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\successful_builds.csv",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "data/consolidated/test_results.csv",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\test_results.csv",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "update-daily.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\update-daily.sh",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "upload_to_sheets.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\upload_to_sheets.py",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "data/junit5/junit5_migration_prs.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\junit5\\junit5_migration_prs.json",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "cmd/find-junit5-prs/main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": [
                            "opened_tab"
                        ]
                    }
                ],
                "rerankedFiles": [],
                "usedFilePaths": [
                    {
                        "path": "cmd\\find-junit5-prs\\main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": [
                            "opened_tab"
                        ],
                        "content": "package main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"math\"\n\t\"math/rand\"\n\t\"net/http\"\n\t\"os\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/shurcooL/githubv4\"\n\t\"golang.org/x/oauth2\"\n)\n\n// JUnit5PR represents a GitHub pull request related to JUnit 5 migration\ntype JUnit5PR struct {\n\tTitle      string   `json:\"title\"`\n\tURL        string   `json:\"url\"`\n\tRepository string   `json:\"repository\"`\n\tState      string   `json:\"state\"`\n\tAuthor     string   `json:\"author\"`\n\tLabels     []string `json:\"labels\"`\n\tBody       string   `json:\"body\"`\n\tCreatedAt  string   `json:\"createdAt\"`\n}\n\n// SearchResult holds the PRs found in the search\ntype SearchResult struct {\n\tPRs []JUnit5PR `json:\"prs\"`\n}\n\n// GraphQL query structure for searching pull requests\ntype searchQuery struct {\n\tSearch struct {\n\t\tPageInfo struct {\n\t\t\tHasNextPage bool\n\t\t\tEndCursor   githubv4.String\n\t\t}\n\t\tNodes []struct {\n\t\t\tPullRequest struct {\n\t\t\t\tTitle     githubv4.String\n\t\t\t\tURL       githubv4.String\n\t\t\t\tState     githubv4.String\n\t\t\t\tCreatedAt githubv4.DateTime\n\t\t\t\tAuthor    struct {\n\t\t\t\t\tLogin githubv4.String\n\t\t\t\t}\n\t\t\t\tRepository struct {\n\t\t\t\t\tNameWithOwner githubv4.String\n\t\t\t\t}\n\t\t\t\tLabels struct {\n\t\t\t\t\tNodes []struct {\n\t\t\t\t\t\tName githubv4.String\n\t\t\t\t\t}\n\t\t\t\t} `graphql:\"labels(first: 10)\"`\n\t\t\t\tBodyText githubv4.String\n\t\t\t} `graphql:\"... on PullRequest\"`\n\t\t}\n\t} `graphql:\"search(query: $query, type: ISSUE, first: $first, after: $after)\"`\n}\n\nfunc main() {\n\t// Parse command line flags\n\toutputDir := flag.String(\"output-dir\", \"data/junit5\", \"Directory to store output files\")\n\tcandidateFile := flag.String(\"candidate-file\", \"junit5_candidate_prs.txt\", \"File to store candidate PR URLs\")\n\texistingFile := flag.String(\"existing-file\", \"junit5_pr_urls.txt\", \"File containing existing PR URLs\")\n\tstartDate := flag.String(\"start-date\", \"2024-07-01\", \"Start date for PR search (YYYY-MM-DD)\")\n\tflag.Parse()\n\n\t// Get GitHub token from environment\n\ttoken := os.Getenv(\"GITHUB_TOKEN\")\n\tif token == \"\" {\n\t\tfmt.Println(\"GITHUB_TOKEN environment variable is required\")\n\t\tos.Exit(1)\n\t}\n\n\t// Parse start date\n\tstartDateTime, err := time.Parse(\"2006-01-02\", *startDate)\n\tif err != nil {\n\t\tfmt.Printf(\"Error parsing start date: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tfmt.Printf(\"Searching for PRs created on or after: %s\\n\", startDateTime.Format(\"2006-01-02\"))\n\n\t// Create output directory if it doesn't exist\n\tos.MkdirAll(*outputDir, 0755)\n\n\t// Create GitHub client\n\tsrc := oauth2.StaticTokenSource(\n\t\t&oauth2.Token{AccessToken: token},\n\t)\n\thttpClient := oauth2.NewClient(context.Background(), src)\n\tclient := githubv4.NewClient(httpClient)\n\n\t// Define search terms\n\tsearchTerms := []string{\n\t\t\"junit5\",\n\t\t\"junit 5\",\n\t\t\"migrate tests to junit\",\n\t\t\"junit jupiter\",\n\t\t\"openrewrite junit\",\n\t}\n\n\t// Initialize result\n\tresult := SearchResult{\n\t\tPRs: []JUnit5PR{},\n\t}\n\n\t// Search for each term\n\tfor _, term := range searchTerms {\n\t\tfmt.Printf(\"Searching for: %s\\n\", term)\n\n\t\t// Search in title\n\t\ttitleQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:title %s\", term)\n\t\tprs := searchPRs(client, titleQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\n\t\t// Search in body\n\t\tbodyQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:body %s\", term)\n\t\tprs = searchPRs(client, bodyQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\t}\n\n\t// Search for PRs by specific authors known for JUnit 5 migrations\n\tfmt.Println(\"Searching for PRs by known JUnit 5 migration authors...\")\n\tauthorQuery := \"org:jenkinsci is:pr author:strangelookingnerd\"\n\tprs := searchPRs(client, authorQuery, startDateTime)\n\tresult.PRs = append(result.PRs, prs...)\n\n\t// Remove duplicates\n\tresult.PRs = removeDuplicates(result.PRs)\n\n\t// Save results to JSON file\n\tjsonData, err := json.MarshalIndent(result, \"\", \"  \")\n\tif err != nil {\n\t\tfmt.Printf(\"Error marshaling JSON: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\toutputFile := fmt.Sprintf(\"%s/junit5_candidates.json\", *outputDir)\n\terr = ioutil.WriteFile(outputFile, jsonData, 0644)\n\tif err != nil {\n\t\tfmt.Printf(\"Error writing JSON file: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Generate text file with URLs for easy addition to junit5_pr_urls.txt\n\tgenerateCandidateURLsFile(result.PRs, *candidateFile)\n\n\t// Compare with existing PRs in junit5_pr_urls.txt\n\tcompareWithExistingPRs(result.PRs, *existingFile)\n\n\tfmt.Printf(\"Found %d potential JUnit 5 migration PR candidates\\n\", len(result.PRs))\n\tfmt.Printf(\"Results saved to %s and %s\\n\", outputFile, *candidateFile)\n}\n\n// searchPRs performs a GitHub search and returns PRs matching the query\nfunc searchPRs(client *githubv4.Client, query string, startDate time.Time) []JUnit5PR {\n\tvar q searchQuery\n\tvariables := map[string]interface{}{\n\t\t\"query\": githubv4.String(query),\n\t\t\"first\": githubv4.Int(10), // Reduced from 25 to 10 to make queries even less complex\n\t\t\"after\": (*githubv4.String)(nil),\n\t}\n\n\tvar allPRs []JUnit5PR\n\tmaxRetries := 10 // Increased from 5 to 10\n\tinitialBackoff := 2 * time.Second\n\tmaxBackoff := 60 * time.Second\n\n\t// Log the query being executed\n\tfmt.Printf(\"Executing GitHub GraphQL query: %s\\n\", query)\n\tfmt.Printf(\"Start date: %s\\n\", startDate.Format(time.RFC3339))\n\n\tpageCount := 0\n\ttotalAttempts := 0\n\tfor {\n\t\t// Add a small delay between requests to respect rate limits\n\t\ttime.Sleep(1 * time.Second)\n\n\t\t// Create a context with timeout\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n\t\tdefer cancel()\n\n\t\tvar err error\n\t\tsuccess := false\n\n\t\t// Implement retry with exponential backoff\n\t\tfor attempt := 0; attempt < maxRetries && !success; attempt++ {\n\t\t\ttotalAttempts++\n\n\t\t\t// Get current rate limit information before making the request\n\t\t\tvar rateLimit struct {\n\t\t\t\tRateLimit struct {\n\t\t\t\t\tLimit     githubv4.Int\n\t\t\t\t\tRemaining githubv4.Int\n\t\t\t\t\tResetAt   githubv4.DateTime\n\t\t\t\t} `graphql:\"rateLimit\"`\n\t\t\t}\n\n\t\t\trateLimitErr := client.Query(context.Background(), &rateLimit, nil)\n\t\t\tif rateLimitErr == nil {\n\t\t\t\tfmt.Printf(\"GitHub API rate limit: %d/%d remaining, resets at %s\\n\",\n\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\trateLimit.RateLimit.Limit,\n\t\t\t\t\trateLimit.RateLimit.ResetAt.Format(time.RFC3339))\n\n\t\t\t\t// Check if we're close to hitting the rate limit\n\t\t\t\tif rateLimit.RateLimit.Remaining < 100 {\n\t\t\t\t\tresetTime := time.Until(rateLimit.RateLimit.ResetAt.Time)\n\t\t\t\t\tfmt.Printf(\"WARNING: Rate limit is low (%d remaining). Limit resets in %s\\n\",\n\t\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\t\tresetTime.Round(time.Second))\n\n\t\t\t\t\tif rateLimit.RateLimit.Remaining < 10 {\n\t\t\t\t\t\tfmt.Println(\"Rate limit critically low, waiting until reset...\")\n\t\t\t\t\t\twaitTime := time.Until(rateLimit.RateLimit.ResetAt.Time) + 10*time.Second\n\t\t\t\t\t\ttime.Sleep(waitTime)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfmt.Printf(\"Could not fetch rate limit info: %v\\n\", rateLimitErr)\n\t\t\t}\n\n\t\t\t// Execute the actual query\n\t\t\tstartTime := time.Now()\n\t\t\terr = client.Query(ctx, &q, variables)\n\t\t\tqueryDuration := time.Since(startTime)\n\n\t\t\tif err == nil {\n\t\t\t\tsuccess = true\n\t\t\t\tfmt.Printf(\"Query succeeded in %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t\t// Log the number of results received\n\t\t\t\tresultCount := len(q.Search.Nodes)\n\t\t\t\tfmt.Printf(\"Received %d results for page %d\\n\", resultCount, pageCount+1)\n\n\t\t\t\t// Process the results\n\t\t\t\tfor _, node := range q.Search.Nodes {\n\t\t\t\t\tpr := node.PullRequest\n\n\t\t\t\t\t// Extract labels\n\t\t\t\t\tvar labels []string\n\t\t\t\t\tfor _, label := range pr.Labels.Nodes {\n\t\t\t\t\t\tlabels = append(labels, string(label.Name))\n\t\t\t\t\t}\n\n\t\t\t\t\t// Create PR object\n\t\t\t\t\tnewPR := JUnit5PR{\n\t\t\t\t\t\tTitle:      string(pr.Title),\n\t\t\t\t\t\tURL:        string(pr.URL),\n\t\t\t\t\t\tRepository: string(pr.Repository.NameWithOwner),\n\t\t\t\t\t\tState:      string(pr.State),\n\t\t\t\t\t\tAuthor:     string(pr.Author.Login),\n\t\t\t\t\t\tLabels:     labels,\n\t\t\t\t\t\tBody:       string(pr.BodyText),\n\t\t\t\t\t\tCreatedAt:  pr.CreatedAt.Format(time.RFC3339),\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs created on or after the start date\n\t\t\t\t\tif pr.CreatedAt.Before(startDate) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs that are likely related to JUnit 5 migration\n\t\t\t\t\tif isJUnit5MigrationPR(newPR) {\n\t\t\t\t\t\tallPRs = append(allPRs, newPR)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Log progress\n\t\t\t\tfmt.Printf(\"Processed page %d, found %d matching PRs so far\\n\", pageCount+1, len(allPRs))\n\n\t\t\t\t// Check if there are more pages\n\t\t\t\tif !q.Search.PageInfo.HasNextPage {\n\t\t\t\t\tfmt.Printf(\"No more pages available, completed after %d pages\\n\", pageCount+1)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\n\t\t\t\t// Move to next page\n\t\t\t\tfmt.Printf(\"Moving to next page with cursor: %s\\n\", q.Search.PageInfo.EndCursor)\n\t\t\t\tvariables[\"after\"] = githubv4.NewString(q.Search.PageInfo.EndCursor)\n\n\t\t\t\t// Reset the attempt counter since we successfully processed this page\n\t\t\t\tattempt = 0\n\n\t\t\t\t// Add a small delay before the next page to avoid overwhelming GitHub\n\t\t\t\ttime.Sleep(1 * time.Second)\n\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Log detailed error information\n\t\t\tfmt.Printf(\"GitHub API error on attempt %d/%d (total %d): %v\\n\",\n\t\t\t\tattempt+1, maxRetries, totalAttempts, err)\n\t\t\tfmt.Printf(\"Query duration before error: %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t// Try to parse and log more details from the error\n\t\t\tvar errorDetails struct {\n\t\t\t\tData   interface{}            `json:\"data\"`\n\t\t\t\tErrors []map[string]interface{} `json:\"errors\"`\n\t\t\t}\n\n\t\t\tif strings.Contains(err.Error(), \"{\") {\n\t\t\t\terrorJSON := err.Error()[strings.Index(err.Error(), \"{\"): // Removed the -1\n\t\t\t\tif jsonErr := json.Unmarshal([]byte(errorJSON), &errorDetails); jsonErr == nil {\n\t\t\t\t\tif errorDetails.Errors != nil && len(errorDetails.Errors) > 0 {\n\t\t\t\t\t\tfmt.Println(\"Detailed error information:\")\n\t\t\t\t\t\tfor i, errDetail := range errorDetails.Errors {\n\t\t\t\t\t\t\tfmt.Printf(\"  Error %d:\\n\", i+1)\n\t\t\t\t\t\t\tfor k, v := range errDetail {\n\t\t\t\t\t\t\t\tfmt.Printf(\"    %s: %v\\n\", k, v)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Check if this is a retryable error (like 502)\n\t\t\tif strings.Contains(err.Error(), \"502\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"timeout\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"Something went wrong\") {\n\n\t\t\t\t// Calculate backoff duration with exponential increase and jitter\n\t\t\t\tbackoffTime := float64(initialBackoff) * math.Pow(2, float64(attempt))\n\t\t\t\tif backoffTime > float64(maxBackoff) {\n\t\t\t\t\tbackoffTime = float64(maxBackoff)\n\t\t\t\t}\n\n\t\t\t\t// Add jitter (±20%)\n\t\t\t\tjitter := (rand.Float64() * 0.4) - 0.2 // -20% to +20%\n\t\t\t\tbackoffTime = backoffTime * (1 + jitter)\n\n\t\t\t\tsleepDuration := time.Duration(backoffTime)\n\t\t\t\tfmt.Printf(\"Retrying in %v...\\n\", sleepDuration)\n\t\t\t\ttime.Sleep(sleepDuration)\n\t\t\t} else {\n\t\t\t\t// Non-retryable error, break out\n\t\t\t\tfmt.Println(\"Non-retryable error encountered, stopping retry attempts\")\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !success {\n\t\t\tfmt.Printf(\"Failed after %d attempts: %v\\n\", maxRetries, err)\n\t\t\tfmt.Println(\"Continuing with results collected so far...\")\n\t\t\treturn allPRs\n\t\t}\n\t}\n\n\tfmt.Printf(\"Search completed. Found %d matching PRs for query: %s\\n\", len(allPRs), query)\n\treturn allPRs\n}\n\n// isJUnit5MigrationPR checks if a PR is likely related to JUnit 5 migration\nfunc isJUnit5MigrationPR(pr JUnit5PR) bool {\n\t// Exclude dependency bumps\n\tif strings.HasPrefix(pr.Title, \"Bump\") || strings.HasPrefix(pr.Title, \"bump\") {\n\t\treturn false\n\t}\n\n\t// Exclude PRs with specific JIRA ticket prefixes that are known not to be JUnit 5 related\n\t// These are examples of tickets that were incorrectly included\n\texcludePatterns := []string{\n\t\t`(?i)JENKINS-70560`,         // Improve test coverage\n\t\t`(?i)JENKINS-75447`,         // Fix Snippetizer rendering\n\t\t`(?i)JENKINS-\\d+.*fix`,      // General fixes\n\t\t`(?i)fix`,                   // General fixes\n\t\t`(?i)improve test coverage`, // Test coverage improvements not related to JUnit 5\n\t}\n\n\tfor _, pattern := range excludePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Define more specific patterns for JUnit 5 migration PRs\n\ttitlePatterns := []string{\n\t\t`(?i)migrate tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t}\n\n\tbodyPatterns := []string{\n\t\t`(?i)migrate (all )?tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t\t`(?i)org\\.junit\\.jupiter`,\n\t\t`(?i)junit-jupiter`,\n\t}\n\n\tlabelPatterns := []string{\n\t\t`(?i)\\bjunit ?5\\b`,\n\t\t`(?i)junit-5`,\n\t\t`(?i)junit-migration`,\n\t}\n\n\tauthorPatterns := []string{\n\t\t`strangelookingnerd`,\n\t}\n\n\t// Check title with more specific matching\n\tfor _, pattern := range titlePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn true\n\t\t}\n\t}\n\n\t// For body matches, require stronger evidence\n\t// Count how many patterns match in the body\n\tbodyMatchCount := 0\n\tfor _, pattern := range bodyPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Body)\n\t\tif matched {\n\t\t\tbodyMatchCount++\n\t\t}\n\t}\n\n\t// Require at least 2 body pattern matches for a positive identification\n\t// This helps avoid false positives from PRs that mention JUnit in passing\n\tif bodyMatchCount >= 2 {\n\t\treturn true\n\t}\n\n\t// Check labels\n\tfor _, label := range pr.Labels {\n\t\tfor _, pattern := range labelPatterns {\n\t\t\tmatched, _ := regexp.MatchString(pattern, label)\n\t\t\tif matched {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check author - but only if there's at least some mention of JUnit in the body\n\t// This avoids including all PRs from certain authors\n\tfor _, pattern := range authorPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Author)\n\t\tif matched {\n\t\t\t// Check if there's at least some mention of JUnit in the body\n\t\t\tjunitmatch, _ := regexp.MatchString(`(?i)junit`, pr.Body)\n\t\t\tif junitmatch {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\treturn false\n}\n\n// removeDuplicates removes duplicate PRs from the slice\nfunc removeDuplicates(prs []JUnit5PR) []JUnit5PR {\n\tseen := make(map[string]bool)\n\tvar result []JUnit5PR\n\n\tfor _, pr := range prs {\n\t\tif !seen[pr.URL] {\n\t\t\tseen[pr.URL] = true\n\t\t\tresult = append(result, pr)\n\t\t}\n\t}\n\n\treturn result\n}\n\n// generateCandidateURLsFile creates a text file with PR URLs for easy addition to junit5_pr_urls.txt\nfunc generateCandidateURLsFile(prs []JUnit5PR, outputFile string) {\n\tfile, err := os.Create(outputFile)\n\tif err != nil {\n\t\tfmt.Printf(\"Error creating file: %v\\n\", err)\n\t\treturn\n\t}\n\tdefer file.Close()\n\n\tfile.WriteString(fmt.Sprintf(\"# JUnit 5 migration PR candidates found on %s\\n\", time.Now().Format(\"2006-01-02 15:04:05\")))\n\tfile.WriteString(\"# Add relevant URLs to junit5_pr_urls.txt after verification\\n\\n\")\n\n\tfor _, pr := range prs {\n\t\tfile.WriteString(fmt.Sprintf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State))\n\t\tfile.WriteString(fmt.Sprintf(\"%s\\n\\n\", pr.URL))\n\t}\n}\n\n// compareWithExistingPRs compares found PRs with those already in junit5_pr_urls.txt\nfunc compareWithExistingPRs(prs []JUnit5PR, existingFile string) {\n\t// Read existing PR URLs\n\texistingURLs := make(map[string]bool)\n\n\tdata, err := ioutil.ReadFile(existingFile)\n\tif err == nil {\n\t\tlines := strings.Split(string(data), \"\\n\")\n\t\tfor _, line := range lines {\n\t\t\tline = strings.TrimSpace(line)\n\t\t\tif strings.HasPrefix(line, \"https://\") {\n\t\t\t\texistingURLs[line] = true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Find new PRs\n\tvar newPRs []JUnit5PR\n\tfor _, pr := range prs {\n\t\tif !existingURLs[pr.URL] {\n\t\t\tnewPRs = append(newPRs, pr)\n\t\t}\n\t}\n\n\tfmt.Printf(\"Found %d new PR candidates not already in %s\\n\", len(newPRs), existingFile)\n\n\tif len(newPRs) > 0 {\n\t\tfmt.Println(\"New PR candidates:\")\n\t\tfor _, pr := range newPRs {\n\t\t\tfmt.Printf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State)\n\t\t\tfmt.Printf(\"%s\\n\\n\", pr.URL)\n\t\t}\n\t}\n}\n"
                    }
                ]
            },
            "createdAt": 1744710463188,
            "isInternal": false,
            "rawContent": {
                "type": "doc",
                "content": [
                    {
                        "type": "paragraph",
                        "content": [
                            {
                                "type": "text",
                                "text": "2025-04-15 11:46:56,502 - INFO - Successfully applied 1 format requests"
                            }
                        ]
                    },
                    {
                        "type": "paragraph",
                        "content": [
                            {
                                "type": "text",
                                "text": "2025-04-15 11:47:08,502 - INFO - Data has been uploaded to Google Sheets."
                            }
                        ]
                    },
                    {
                        "type": "paragraph",
                        "content": [
                            {
                                "type": "text",
                                "text": "Note: To force an update of the successful builds sheet, run with the force parameter: python3 upload_to_sheets.py \"data/consolidated/all_prs.json\" false true"
                            }
                        ]
                    },
                    {
                        "type": "paragraph",
                        "content": [
                            {
                                "type": "text",
                                "text": "Running JUnit 5 migration PR analysis..."
                            }
                        ]
                    },
                    {
                        "type": "paragraph",
                        "content": [
                            {
                                "type": "text",
                                "text": "Finding JUnit 5 migration PRs..."
                            }
                        ]
                    },
                    {
                        "type": "paragraph",
                        "content": [
                            {
                                "type": "text",
                                "text": "Output directory: data/junit5"
                            }
                        ]
                    },
                    {
                        "type": "paragraph",
                        "content": [
                            {
                                "type": "text",
                                "text": "Candidate file: junit5_candidate_prs.txt"
                            }
                        ]
                    },
                    {
                        "type": "paragraph",
                        "content": [
                            {
                                "type": "text",
                                "text": "Existing file: junit5_pr_urls.txt"
                            }
                        ]
                    },
                    {
                        "type": "paragraph",
                        "content": [
                            {
                                "type": "text",
                                "text": "Downloading dependencies..."
                            }
                        ]
                    },
                    {
                        "type": "paragraph",
                        "content": [
                            {
                                "type": "text",
                                "text": "Building and running the JUnit 5 PR finder..."
                            }
                        ]
                    },
                    {
                        "type": "paragraph",
                        "content": [
                            {
                                "type": "text",
                                "text": "# command-line-arguments"
                            }
                        ]
                    },
                    {
                        "type": "paragraph",
                        "content": [
                            {
                                "type": "text",
                                "text": "./main.go:313:5: syntax error: unexpected if, expected expression"
                            }
                        ]
                    },
                    {
                        "type": "paragraph",
                        "content": [
                            {
                                "type": "text",
                                "text": "./main.go:314:6: syntax error: unexpected if, expected expression"
                            }
                        ]
                    },
                    {
                        "type": "paragraph",
                        "content": [
                            {
                                "type": "text",
                                "text": "./main.go:358:2: syntax error: non-declaration statement outside function body"
                            }
                        ]
                    }
                ]
            }
        },
        {
            "id": "c6c37e7f-6eeb-452a-b934-bb6ac00edc12",
            "role": "assistant",
            "content": [
                {
                    "type": "text",
                    "text": "The error messages you're encountering indicate syntax errors in your Go code. Let's address each of them:\n\n1. **Syntax Error: Unexpected `if`, Expected Expression**\n\n   The errors at lines 313 and 314 suggest that there are misplaced `if` statements or missing context around them. In Go, `if` statements must be inside a function body. Ensure that these lines are within a function and that the syntax is correct.\n\n2. **Syntax Error: Non-declaration Statement Outside Function Body**\n\n   The error at line 358 indicates that there is a statement outside of any function. In Go, all executable code must be inside a function. Check to ensure that this line is within a function.\n\nLet's look at the relevant section of your code to identify the issues:\n\n```go\n// Assuming this is the problematic section\n// Ensure all code is within a function\nfunc someFunction() {\n    // Example of a correct if statement\n    if condition {\n        // Do something\n    }\n}\n```\n\n### Steps to Fix:\n\n- **Check Line 313 and 314**: Ensure these lines are inside a function. If they are not, wrap them in a function.\n- **Check Line 358**: Ensure this line is also inside a function. If it is a standalone statement, it needs to be part of a function.\n\nIf you can provide the specific lines around 313, 314, and 358, I can give more precise guidance."
                }
            ],
            "context": {
                "currentFile": {
                    "path": "cmd\\find-junit5-prs\\main.go",
                    "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                    "sources": [
                        "opened_tab"
                    ],
                    "content": "package main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"math\"\n\t\"math/rand\"\n\t\"net/http\"\n\t\"os\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/shurcooL/githubv4\"\n\t\"golang.org/x/oauth2\"\n)\n\n// JUnit5PR represents a GitHub pull request related to JUnit 5 migration\ntype JUnit5PR struct {\n\tTitle      string   `json:\"title\"`\n\tURL        string   `json:\"url\"`\n\tRepository string   `json:\"repository\"`\n\tState      string   `json:\"state\"`\n\tAuthor     string   `json:\"author\"`\n\tLabels     []string `json:\"labels\"`\n\tBody       string   `json:\"body\"`\n\tCreatedAt  string   `json:\"createdAt\"`\n}\n\n// SearchResult holds the PRs found in the search\ntype SearchResult struct {\n\tPRs []JUnit5PR `json:\"prs\"`\n}\n\n// GraphQL query structure for searching pull requests\ntype searchQuery struct {\n\tSearch struct {\n\t\tPageInfo struct {\n\t\t\tHasNextPage bool\n\t\t\tEndCursor   githubv4.String\n\t\t}\n\t\tNodes []struct {\n\t\t\tPullRequest struct {\n\t\t\t\tTitle     githubv4.String\n\t\t\t\tURL       githubv4.String\n\t\t\t\tState     githubv4.String\n\t\t\t\tCreatedAt githubv4.DateTime\n\t\t\t\tAuthor    struct {\n\t\t\t\t\tLogin githubv4.String\n\t\t\t\t}\n\t\t\t\tRepository struct {\n\t\t\t\t\tNameWithOwner githubv4.String\n\t\t\t\t}\n\t\t\t\tLabels struct {\n\t\t\t\t\tNodes []struct {\n\t\t\t\t\t\tName githubv4.String\n\t\t\t\t\t}\n\t\t\t\t} `graphql:\"labels(first: 10)\"`\n\t\t\t\tBodyText githubv4.String\n\t\t\t} `graphql:\"... on PullRequest\"`\n\t\t}\n\t} `graphql:\"search(query: $query, type: ISSUE, first: $first, after: $after)\"`\n}\n\nfunc main() {\n\t// Parse command line flags\n\toutputDir := flag.String(\"output-dir\", \"data/junit5\", \"Directory to store output files\")\n\tcandidateFile := flag.String(\"candidate-file\", \"junit5_candidate_prs.txt\", \"File to store candidate PR URLs\")\n\texistingFile := flag.String(\"existing-file\", \"junit5_pr_urls.txt\", \"File containing existing PR URLs\")\n\tstartDate := flag.String(\"start-date\", \"2024-07-01\", \"Start date for PR search (YYYY-MM-DD)\")\n\tflag.Parse()\n\n\t// Get GitHub token from environment\n\ttoken := os.Getenv(\"GITHUB_TOKEN\")\n\tif token == \"\" {\n\t\tfmt.Println(\"GITHUB_TOKEN environment variable is required\")\n\t\tos.Exit(1)\n\t}\n\n\t// Parse start date\n\tstartDateTime, err := time.Parse(\"2006-01-02\", *startDate)\n\tif err != nil {\n\t\tfmt.Printf(\"Error parsing start date: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tfmt.Printf(\"Searching for PRs created on or after: %s\\n\", startDateTime.Format(\"2006-01-02\"))\n\n\t// Create output directory if it doesn't exist\n\tos.MkdirAll(*outputDir, 0755)\n\n\t// Create GitHub client\n\tsrc := oauth2.StaticTokenSource(\n\t\t&oauth2.Token{AccessToken: token},\n\t)\n\thttpClient := oauth2.NewClient(context.Background(), src)\n\tclient := githubv4.NewClient(httpClient)\n\n\t// Define search terms\n\tsearchTerms := []string{\n\t\t\"junit5\",\n\t\t\"junit 5\",\n\t\t\"migrate tests to junit\",\n\t\t\"junit jupiter\",\n\t\t\"openrewrite junit\",\n\t}\n\n\t// Initialize result\n\tresult := SearchResult{\n\t\tPRs: []JUnit5PR{},\n\t}\n\n\t// Search for each term\n\tfor _, term := range searchTerms {\n\t\tfmt.Printf(\"Searching for: %s\\n\", term)\n\n\t\t// Search in title\n\t\ttitleQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:title %s\", term)\n\t\tprs := searchPRs(client, titleQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\n\t\t// Search in body\n\t\tbodyQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:body %s\", term)\n\t\tprs = searchPRs(client, bodyQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\t}\n\n\t// Search for PRs by specific authors known for JUnit 5 migrations\n\tfmt.Println(\"Searching for PRs by known JUnit 5 migration authors...\")\n\tauthorQuery := \"org:jenkinsci is:pr author:strangelookingnerd\"\n\tprs := searchPRs(client, authorQuery, startDateTime)\n\tresult.PRs = append(result.PRs, prs...)\n\n\t// Remove duplicates\n\tresult.PRs = removeDuplicates(result.PRs)\n\n\t// Save results to JSON file\n\tjsonData, err := json.MarshalIndent(result, \"\", \"  \")\n\tif err != nil {\n\t\tfmt.Printf(\"Error marshaling JSON: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\toutputFile := fmt.Sprintf(\"%s/junit5_candidates.json\", *outputDir)\n\terr = ioutil.WriteFile(outputFile, jsonData, 0644)\n\tif err != nil {\n\t\tfmt.Printf(\"Error writing JSON file: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Generate text file with URLs for easy addition to junit5_pr_urls.txt\n\tgenerateCandidateURLsFile(result.PRs, *candidateFile)\n\n\t// Compare with existing PRs in junit5_pr_urls.txt\n\tcompareWithExistingPRs(result.PRs, *existingFile)\n\n\tfmt.Printf(\"Found %d potential JUnit 5 migration PR candidates\\n\", len(result.PRs))\n\tfmt.Printf(\"Results saved to %s and %s\\n\", outputFile, *candidateFile)\n}\n\n// searchPRs performs a GitHub search and returns PRs matching the query\nfunc searchPRs(client *githubv4.Client, query string, startDate time.Time) []JUnit5PR {\n\tvar q searchQuery\n\tvariables := map[string]interface{}{\n\t\t\"query\": githubv4.String(query),\n\t\t\"first\": githubv4.Int(10), // Reduced from 25 to 10 to make queries even less complex\n\t\t\"after\": (*githubv4.String)(nil),\n\t}\n\n\tvar allPRs []JUnit5PR\n\tmaxRetries := 10 // Increased from 5 to 10\n\tinitialBackoff := 2 * time.Second\n\tmaxBackoff := 60 * time.Second\n\n\t// Log the query being executed\n\tfmt.Printf(\"Executing GitHub GraphQL query: %s\\n\", query)\n\tfmt.Printf(\"Start date: %s\\n\", startDate.Format(time.RFC3339))\n\n\tpageCount := 0\n\ttotalAttempts := 0\n\tfor {\n\t\t// Add a small delay between requests to respect rate limits\n\t\ttime.Sleep(1 * time.Second)\n\n\t\t// Create a context with timeout\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n\t\tdefer cancel()\n\n\t\tvar err error\n\t\tsuccess := false\n\n\t\t// Implement retry with exponential backoff\n\t\tfor attempt := 0; attempt < maxRetries && !success; attempt++ {\n\t\t\ttotalAttempts++\n\n\t\t\t// Get current rate limit information before making the request\n\t\t\tvar rateLimit struct {\n\t\t\t\tRateLimit struct {\n\t\t\t\t\tLimit     githubv4.Int\n\t\t\t\t\tRemaining githubv4.Int\n\t\t\t\t\tResetAt   githubv4.DateTime\n\t\t\t\t} `graphql:\"rateLimit\"`\n\t\t\t}\n\n\t\t\trateLimitErr := client.Query(context.Background(), &rateLimit, nil)\n\t\t\tif rateLimitErr == nil {\n\t\t\t\tfmt.Printf(\"GitHub API rate limit: %d/%d remaining, resets at %s\\n\",\n\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\trateLimit.RateLimit.Limit,\n\t\t\t\t\trateLimit.RateLimit.ResetAt.Format(time.RFC3339))\n\n\t\t\t\t// Check if we're close to hitting the rate limit\n\t\t\t\tif rateLimit.RateLimit.Remaining < 100 {\n\t\t\t\t\tresetTime := time.Until(rateLimit.RateLimit.ResetAt.Time)\n\t\t\t\t\tfmt.Printf(\"WARNING: Rate limit is low (%d remaining). Limit resets in %s\\n\",\n\t\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\t\tresetTime.Round(time.Second))\n\n\t\t\t\t\tif rateLimit.RateLimit.Remaining < 10 {\n\t\t\t\t\t\tfmt.Println(\"Rate limit critically low, waiting until reset...\")\n\t\t\t\t\t\twaitTime := time.Until(rateLimit.RateLimit.ResetAt.Time) + 10*time.Second\n\t\t\t\t\t\ttime.Sleep(waitTime)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfmt.Printf(\"Could not fetch rate limit info: %v\\n\", rateLimitErr)\n\t\t\t}\n\n\t\t\t// Execute the actual query\n\t\t\tstartTime := time.Now()\n\t\t\terr = client.Query(ctx, &q, variables)\n\t\t\tqueryDuration := time.Since(startTime)\n\n\t\t\tif err == nil {\n\t\t\t\tsuccess = true\n\t\t\t\tfmt.Printf(\"Query succeeded in %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t\t// Log the number of results received\n\t\t\t\tresultCount := len(q.Search.Nodes)\n\t\t\t\tfmt.Printf(\"Received %d results for page %d\\n\", resultCount, pageCount+1)\n\n\t\t\t\t// Process the results\n\t\t\t\tfor _, node := range q.Search.Nodes {\n\t\t\t\t\tpr := node.PullRequest\n\n\t\t\t\t\t// Extract labels\n\t\t\t\t\tvar labels []string\n\t\t\t\t\tfor _, label := range pr.Labels.Nodes {\n\t\t\t\t\t\tlabels = append(labels, string(label.Name))\n\t\t\t\t\t}\n\n\t\t\t\t\t// Create PR object\n\t\t\t\t\tnewPR := JUnit5PR{\n\t\t\t\t\t\tTitle:      string(pr.Title),\n\t\t\t\t\t\tURL:        string(pr.URL),\n\t\t\t\t\t\tRepository: string(pr.Repository.NameWithOwner),\n\t\t\t\t\t\tState:      string(pr.State),\n\t\t\t\t\t\tAuthor:     string(pr.Author.Login),\n\t\t\t\t\t\tLabels:     labels,\n\t\t\t\t\t\tBody:       string(pr.BodyText),\n\t\t\t\t\t\tCreatedAt:  pr.CreatedAt.Format(time.RFC3339),\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs created on or after the start date\n\t\t\t\t\tif pr.CreatedAt.Before(startDate) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs that are likely related to JUnit 5 migration\n\t\t\t\t\tif isJUnit5MigrationPR(newPR) {\n\t\t\t\t\t\tallPRs = append(allPRs, newPR)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Log progress\n\t\t\t\tfmt.Printf(\"Processed page %d, found %d matching PRs so far\\n\", pageCount+1, len(allPRs))\n\n\t\t\t\t// Check if there are more pages\n\t\t\t\tif !q.Search.PageInfo.HasNextPage {\n\t\t\t\t\tfmt.Printf(\"No more pages available, completed after %d pages\\n\", pageCount+1)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\n\t\t\t\t// Move to next page\n\t\t\t\tfmt.Printf(\"Moving to next page with cursor: %s\\n\", q.Search.PageInfo.EndCursor)\n\t\t\t\tvariables[\"after\"] = githubv4.NewString(q.Search.PageInfo.EndCursor)\n\n\t\t\t\t// Reset the attempt counter since we successfully processed this page\n\t\t\t\tattempt = 0\n\n\t\t\t\t// Add a small delay before the next page to avoid overwhelming GitHub\n\t\t\t\ttime.Sleep(1 * time.Second)\n\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Log detailed error information\n\t\t\tfmt.Printf(\"GitHub API error on attempt %d/%d (total %d): %v\\n\",\n\t\t\t\tattempt+1, maxRetries, totalAttempts, err)\n\t\t\tfmt.Printf(\"Query duration before error: %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t// Try to parse and log more details from the error\n\t\t\tvar errorDetails struct {\n\t\t\t\tData   interface{}            `json:\"data\"`\n\t\t\t\tErrors []map[string]interface{} `json:\"errors\"`\n\t\t\t}\n\n\t\t\tif strings.Contains(err.Error(), \"{\") {\n\t\t\t\terrorJSON := err.Error()[strings.Index(err.Error(), \"{\"): // Removed the -1\n\t\t\t\tif jsonErr := json.Unmarshal([]byte(errorJSON), &errorDetails); jsonErr == nil {\n\t\t\t\t\tif errorDetails.Errors != nil && len(errorDetails.Errors) > 0 {\n\t\t\t\t\t\tfmt.Println(\"Detailed error information:\")\n\t\t\t\t\t\tfor i, errDetail := range errorDetails.Errors {\n\t\t\t\t\t\t\tfmt.Printf(\"  Error %d:\\n\", i+1)\n\t\t\t\t\t\t\tfor k, v := range errDetail {\n\t\t\t\t\t\t\t\tfmt.Printf(\"    %s: %v\\n\", k, v)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Check if this is a retryable error (like 502)\n\t\t\tif strings.Contains(err.Error(), \"502\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"timeout\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"Something went wrong\") {\n\n\t\t\t\t// Calculate backoff duration with exponential increase and jitter\n\t\t\t\tbackoffTime := float64(initialBackoff) * math.Pow(2, float64(attempt))\n\t\t\t\tif backoffTime > float64(maxBackoff) {\n\t\t\t\t\tbackoffTime = float64(maxBackoff)\n\t\t\t\t}\n\n\t\t\t\t// Add jitter (±20%)\n\t\t\t\tjitter := (rand.Float64() * 0.4) - 0.2 // -20% to +20%\n\t\t\t\tbackoffTime = backoffTime * (1 + jitter)\n\n\t\t\t\tsleepDuration := time.Duration(backoffTime)\n\t\t\t\tfmt.Printf(\"Retrying in %v...\\n\", sleepDuration)\n\t\t\t\ttime.Sleep(sleepDuration)\n\t\t\t} else {\n\t\t\t\t// Non-retryable error, break out\n\t\t\t\tfmt.Println(\"Non-retryable error encountered, stopping retry attempts\")\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !success {\n\t\t\tfmt.Printf(\"Failed after %d attempts: %v\\n\", maxRetries, err)\n\t\t\tfmt.Println(\"Continuing with results collected so far...\")\n\t\t\treturn allPRs\n\t\t}\n\t}\n\n\tfmt.Printf(\"Search completed. Found %d matching PRs for query: %s\\n\", len(allPRs), query)\n\treturn allPRs\n}\n\n// isJUnit5MigrationPR checks if a PR is likely related to JUnit 5 migration\nfunc isJUnit5MigrationPR(pr JUnit5PR) bool {\n\t// Exclude dependency bumps\n\tif strings.HasPrefix(pr.Title, \"Bump\") || strings.HasPrefix(pr.Title, \"bump\") {\n\t\treturn false\n\t}\n\n\t// Exclude PRs with specific JIRA ticket prefixes that are known not to be JUnit 5 related\n\t// These are examples of tickets that were incorrectly included\n\texcludePatterns := []string{\n\t\t`(?i)JENKINS-70560`,         // Improve test coverage\n\t\t`(?i)JENKINS-75447`,         // Fix Snippetizer rendering\n\t\t`(?i)JENKINS-\\d+.*fix`,      // General fixes\n\t\t`(?i)fix`,                   // General fixes\n\t\t`(?i)improve test coverage`, // Test coverage improvements not related to JUnit 5\n\t}\n\n\tfor _, pattern := range excludePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Define more specific patterns for JUnit 5 migration PRs\n\ttitlePatterns := []string{\n\t\t`(?i)migrate tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t}\n\n\tbodyPatterns := []string{\n\t\t`(?i)migrate (all )?tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t\t`(?i)org\\.junit\\.jupiter`,\n\t\t`(?i)junit-jupiter`,\n\t}\n\n\tlabelPatterns := []string{\n\t\t`(?i)\\bjunit ?5\\b`,\n\t\t`(?i)junit-5`,\n\t\t`(?i)junit-migration`,\n\t}\n\n\tauthorPatterns := []string{\n\t\t`strangelookingnerd`,\n\t}\n\n\t// Check title with more specific matching\n\tfor _, pattern := range titlePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn true\n\t\t}\n\t}\n\n\t// For body matches, require stronger evidence\n\t// Count how many patterns match in the body\n\tbodyMatchCount := 0\n\tfor _, pattern := range bodyPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Body)\n\t\tif matched {\n\t\t\tbodyMatchCount++\n\t\t}\n\t}\n\n\t// Require at least 2 body pattern matches for a positive identification\n\t// This helps avoid false positives from PRs that mention JUnit in passing\n\tif bodyMatchCount >= 2 {\n\t\treturn true\n\t}\n\n\t// Check labels\n\tfor _, label := range pr.Labels {\n\t\tfor _, pattern := range labelPatterns {\n\t\t\tmatched, _ := regexp.MatchString(pattern, label)\n\t\t\tif matched {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check author - but only if there's at least some mention of JUnit in the body\n\t// This avoids including all PRs from certain authors\n\tfor _, pattern := range authorPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Author)\n\t\tif matched {\n\t\t\t// Check if there's at least some mention of JUnit in the body\n\t\t\tjunitmatch, _ := regexp.MatchString(`(?i)junit`, pr.Body)\n\t\t\tif junitmatch {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\treturn false\n}\n\n// removeDuplicates removes duplicate PRs from the slice\nfunc removeDuplicates(prs []JUnit5PR) []JUnit5PR {\n\tseen := make(map[string]bool)\n\tvar result []JUnit5PR\n\n\tfor _, pr := range prs {\n\t\tif !seen[pr.URL] {\n\t\t\tseen[pr.URL] = true\n\t\t\tresult = append(result, pr)\n\t\t}\n\t}\n\n\treturn result\n}\n\n// generateCandidateURLsFile creates a text file with PR URLs for easy addition to junit5_pr_urls.txt\nfunc generateCandidateURLsFile(prs []JUnit5PR, outputFile string) {\n\tfile, err := os.Create(outputFile)\n\tif err != nil {\n\t\tfmt.Printf(\"Error creating file: %v\\n\", err)\n\t\treturn\n\t}\n\tdefer file.Close()\n\n\tfile.WriteString(fmt.Sprintf(\"# JUnit 5 migration PR candidates found on %s\\n\", time.Now().Format(\"2006-01-02 15:04:05\")))\n\tfile.WriteString(\"# Add relevant URLs to junit5_pr_urls.txt after verification\\n\\n\")\n\n\tfor _, pr := range prs {\n\t\tfile.WriteString(fmt.Sprintf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State))\n\t\tfile.WriteString(fmt.Sprintf(\"%s\\n\\n\", pr.URL))\n\t}\n}\n\n// compareWithExistingPRs compares found PRs with those already in junit5_pr_urls.txt\nfunc compareWithExistingPRs(prs []JUnit5PR, existingFile string) {\n\t// Read existing PR URLs\n\texistingURLs := make(map[string]bool)\n\n\tdata, err := ioutil.ReadFile(existingFile)\n\tif err == nil {\n\t\tlines := strings.Split(string(data), \"\\n\")\n\t\tfor _, line := range lines {\n\t\t\tline = strings.TrimSpace(line)\n\t\t\tif strings.HasPrefix(line, \"https://\") {\n\t\t\t\texistingURLs[line] = true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Find new PRs\n\tvar newPRs []JUnit5PR\n\tfor _, pr := range prs {\n\t\tif !existingURLs[pr.URL] {\n\t\t\tnewPRs = append(newPRs, pr)\n\t\t}\n\t}\n\n\tfmt.Printf(\"Found %d new PR candidates not already in %s\\n\", len(newPRs), existingFile)\n\n\tif len(newPRs) > 0 {\n\t\tfmt.Println(\"New PR candidates:\")\n\t\tfor _, pr := range newPRs {\n\t\t\tfmt.Printf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State)\n\t\t\tfmt.Printf(\"%s\\n\\n\", pr.URL)\n\t\t}\n\t}\n}\n"
                },
                "codebaseEnabled": true,
                "ragFiles": [
                    {
                        "path": "venv/lib/python3.13/site-packages/gspread/spreadsheet.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\gspread\\spreadsheet.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "upload_to_sheets.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\upload_to_sheets.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/traceback.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\traceback.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/tree.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\tree.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/syntax.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\syntax.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/progress.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\progress.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/live.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\live.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/__main__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\__main__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/segment.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\segment.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/urllib3/contrib/appengine.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\urllib3\\contrib\\appengine.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/_credentials_base.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\_credentials_base.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/_helpers.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\_helpers.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/_credentials_async.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\_credentials_async.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/metrics.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\metrics.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/_exponential_backoff.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\_exponential_backoff.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/_refresh_worker.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\_refresh_worker.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/aio/__init__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\aio\\__init__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/crypt/base.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\crypt\\base.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/transport/_custom_tls_signer.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\transport\\_custom_tls_signer.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/google/auth/transport/_mtls_helper.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\google\\auth\\transport\\_mtls_helper.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "cmd\\find-junit5-prs\\main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": []
                    },
                    {
                        "path": "junit5-migration-prs.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\junit5-migration-prs.sh",
                        "sources": []
                    },
                    {
                        "path": "analyze-junit5-prs.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\analyze-junit5-prs.sh",
                        "sources": []
                    },
                    {
                        "path": "find-junit5-prs.go.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\find-junit5-prs.go.sh",
                        "sources": []
                    },
                    {
                        "path": "find-junit5-prs.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\find-junit5-prs.sh",
                        "sources": []
                    },
                    {
                        "path": "update-daily.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\update-daily.sh",
                        "sources": []
                    },
                    {
                        "path": "README.md",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\README.md",
                        "sources": []
                    },
                    {
                        "path": "data\\junit5\\common_patterns.txt",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\junit5\\common_patterns.txt",
                        "sources": []
                    },
                    {
                        "path": "jenkins-pr-collector-readme.md",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\jenkins-pr-collector-readme.md",
                        "sources": []
                    },
                    {
                        "path": "data\\junit5\\junit5_prs_by_repo.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\junit5\\junit5_prs_by_repo.json",
                        "sources": []
                    },
                    {
                        "path": "junit5_candidate_prs.txt",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\junit5_candidate_prs.txt",
                        "sources": []
                    },
                    {
                        "path": "data\\junit5\\detection_patterns.txt",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\junit5\\detection_patterns.txt",
                        "sources": []
                    },
                    {
                        "path": "data/consolidated/failed_builds.csv",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\failed_builds.csv",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "data/consolidated/successful_builds.csv",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\successful_builds.csv",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "data/consolidated/test_results.csv",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\test_results.csv",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "update-daily.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\update-daily.sh",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "upload_to_sheets.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\upload_to_sheets.py",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "data/junit5/junit5_migration_prs.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\junit5\\junit5_migration_prs.json",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "cmd/find-junit5-prs/main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": [
                            "opened_tab"
                        ]
                    }
                ],
                "rerankedFiles": [],
                "usedFilePaths": [
                    {
                        "path": "cmd\\find-junit5-prs\\main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": [
                            "opened_tab"
                        ],
                        "content": "package main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"math\"\n\t\"math/rand\"\n\t\"net/http\"\n\t\"os\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/shurcooL/githubv4\"\n\t\"golang.org/x/oauth2\"\n)\n\n// JUnit5PR represents a GitHub pull request related to JUnit 5 migration\ntype JUnit5PR struct {\n\tTitle      string   `json:\"title\"`\n\tURL        string   `json:\"url\"`\n\tRepository string   `json:\"repository\"`\n\tState      string   `json:\"state\"`\n\tAuthor     string   `json:\"author\"`\n\tLabels     []string `json:\"labels\"`\n\tBody       string   `json:\"body\"`\n\tCreatedAt  string   `json:\"createdAt\"`\n}\n\n// SearchResult holds the PRs found in the search\ntype SearchResult struct {\n\tPRs []JUnit5PR `json:\"prs\"`\n}\n\n// GraphQL query structure for searching pull requests\ntype searchQuery struct {\n\tSearch struct {\n\t\tPageInfo struct {\n\t\t\tHasNextPage bool\n\t\t\tEndCursor   githubv4.String\n\t\t}\n\t\tNodes []struct {\n\t\t\tPullRequest struct {\n\t\t\t\tTitle     githubv4.String\n\t\t\t\tURL       githubv4.String\n\t\t\t\tState     githubv4.String\n\t\t\t\tCreatedAt githubv4.DateTime\n\t\t\t\tAuthor    struct {\n\t\t\t\t\tLogin githubv4.String\n\t\t\t\t}\n\t\t\t\tRepository struct {\n\t\t\t\t\tNameWithOwner githubv4.String\n\t\t\t\t}\n\t\t\t\tLabels struct {\n\t\t\t\t\tNodes []struct {\n\t\t\t\t\t\tName githubv4.String\n\t\t\t\t\t}\n\t\t\t\t} `graphql:\"labels(first: 10)\"`\n\t\t\t\tBodyText githubv4.String\n\t\t\t} `graphql:\"... on PullRequest\"`\n\t\t}\n\t} `graphql:\"search(query: $query, type: ISSUE, first: $first, after: $after)\"`\n}\n\nfunc main() {\n\t// Parse command line flags\n\toutputDir := flag.String(\"output-dir\", \"data/junit5\", \"Directory to store output files\")\n\tcandidateFile := flag.String(\"candidate-file\", \"junit5_candidate_prs.txt\", \"File to store candidate PR URLs\")\n\texistingFile := flag.String(\"existing-file\", \"junit5_pr_urls.txt\", \"File containing existing PR URLs\")\n\tstartDate := flag.String(\"start-date\", \"2024-07-01\", \"Start date for PR search (YYYY-MM-DD)\")\n\tflag.Parse()\n\n\t// Get GitHub token from environment\n\ttoken := os.Getenv(\"GITHUB_TOKEN\")\n\tif token == \"\" {\n\t\tfmt.Println(\"GITHUB_TOKEN environment variable is required\")\n\t\tos.Exit(1)\n\t}\n\n\t// Parse start date\n\tstartDateTime, err := time.Parse(\"2006-01-02\", *startDate)\n\tif err != nil {\n\t\tfmt.Printf(\"Error parsing start date: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tfmt.Printf(\"Searching for PRs created on or after: %s\\n\", startDateTime.Format(\"2006-01-02\"))\n\n\t// Create output directory if it doesn't exist\n\tos.MkdirAll(*outputDir, 0755)\n\n\t// Create GitHub client\n\tsrc := oauth2.StaticTokenSource(\n\t\t&oauth2.Token{AccessToken: token},\n\t)\n\thttpClient := oauth2.NewClient(context.Background(), src)\n\tclient := githubv4.NewClient(httpClient)\n\n\t// Define search terms\n\tsearchTerms := []string{\n\t\t\"junit5\",\n\t\t\"junit 5\",\n\t\t\"migrate tests to junit\",\n\t\t\"junit jupiter\",\n\t\t\"openrewrite junit\",\n\t}\n\n\t// Initialize result\n\tresult := SearchResult{\n\t\tPRs: []JUnit5PR{},\n\t}\n\n\t// Search for each term\n\tfor _, term := range searchTerms {\n\t\tfmt.Printf(\"Searching for: %s\\n\", term)\n\n\t\t// Search in title\n\t\ttitleQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:title %s\", term)\n\t\tprs := searchPRs(client, titleQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\n\t\t// Search in body\n\t\tbodyQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:body %s\", term)\n\t\tprs = searchPRs(client, bodyQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\t}\n\n\t// Search for PRs by specific authors known for JUnit 5 migrations\n\tfmt.Println(\"Searching for PRs by known JUnit 5 migration authors...\")\n\tauthorQuery := \"org:jenkinsci is:pr author:strangelookingnerd\"\n\tprs := searchPRs(client, authorQuery, startDateTime)\n\tresult.PRs = append(result.PRs, prs...)\n\n\t// Remove duplicates\n\tresult.PRs = removeDuplicates(result.PRs)\n\n\t// Save results to JSON file\n\tjsonData, err := json.MarshalIndent(result, \"\", \"  \")\n\tif err != nil {\n\t\tfmt.Printf(\"Error marshaling JSON: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\toutputFile := fmt.Sprintf(\"%s/junit5_candidates.json\", *outputDir)\n\terr = ioutil.WriteFile(outputFile, jsonData, 0644)\n\tif err != nil {\n\t\tfmt.Printf(\"Error writing JSON file: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Generate text file with URLs for easy addition to junit5_pr_urls.txt\n\tgenerateCandidateURLsFile(result.PRs, *candidateFile)\n\n\t// Compare with existing PRs in junit5_pr_urls.txt\n\tcompareWithExistingPRs(result.PRs, *existingFile)\n\n\tfmt.Printf(\"Found %d potential JUnit 5 migration PR candidates\\n\", len(result.PRs))\n\tfmt.Printf(\"Results saved to %s and %s\\n\", outputFile, *candidateFile)\n}\n\n// searchPRs performs a GitHub search and returns PRs matching the query\nfunc searchPRs(client *githubv4.Client, query string, startDate time.Time) []JUnit5PR {\n\tvar q searchQuery\n\tvariables := map[string]interface{}{\n\t\t\"query\": githubv4.String(query),\n\t\t\"first\": githubv4.Int(10), // Reduced from 25 to 10 to make queries even less complex\n\t\t\"after\": (*githubv4.String)(nil),\n\t}\n\n\tvar allPRs []JUnit5PR\n\tmaxRetries := 10 // Increased from 5 to 10\n\tinitialBackoff := 2 * time.Second\n\tmaxBackoff := 60 * time.Second\n\n\t// Log the query being executed\n\tfmt.Printf(\"Executing GitHub GraphQL query: %s\\n\", query)\n\tfmt.Printf(\"Start date: %s\\n\", startDate.Format(time.RFC3339))\n\n\tpageCount := 0\n\ttotalAttempts := 0\n\tfor {\n\t\t// Add a small delay between requests to respect rate limits\n\t\ttime.Sleep(1 * time.Second)\n\n\t\t// Create a context with timeout\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n\t\tdefer cancel()\n\n\t\tvar err error\n\t\tsuccess := false\n\n\t\t// Implement retry with exponential backoff\n\t\tfor attempt := 0; attempt < maxRetries && !success; attempt++ {\n\t\t\ttotalAttempts++\n\n\t\t\t// Get current rate limit information before making the request\n\t\t\tvar rateLimit struct {\n\t\t\t\tRateLimit struct {\n\t\t\t\t\tLimit     githubv4.Int\n\t\t\t\t\tRemaining githubv4.Int\n\t\t\t\t\tResetAt   githubv4.DateTime\n\t\t\t\t} `graphql:\"rateLimit\"`\n\t\t\t}\n\n\t\t\trateLimitErr := client.Query(context.Background(), &rateLimit, nil)\n\t\t\tif rateLimitErr == nil {\n\t\t\t\tfmt.Printf(\"GitHub API rate limit: %d/%d remaining, resets at %s\\n\",\n\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\trateLimit.RateLimit.Limit,\n\t\t\t\t\trateLimit.RateLimit.ResetAt.Format(time.RFC3339))\n\n\t\t\t\t// Check if we're close to hitting the rate limit\n\t\t\t\tif rateLimit.RateLimit.Remaining < 100 {\n\t\t\t\t\tresetTime := time.Until(rateLimit.RateLimit.ResetAt.Time)\n\t\t\t\t\tfmt.Printf(\"WARNING: Rate limit is low (%d remaining). Limit resets in %s\\n\",\n\t\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\t\tresetTime.Round(time.Second))\n\n\t\t\t\t\tif rateLimit.RateLimit.Remaining < 10 {\n\t\t\t\t\t\tfmt.Println(\"Rate limit critically low, waiting until reset...\")\n\t\t\t\t\t\twaitTime := time.Until(rateLimit.RateLimit.ResetAt.Time) + 10*time.Second\n\t\t\t\t\t\ttime.Sleep(waitTime)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfmt.Printf(\"Could not fetch rate limit info: %v\\n\", rateLimitErr)\n\t\t\t}\n\n\t\t\t// Execute the actual query\n\t\t\tstartTime := time.Now()\n\t\t\terr = client.Query(ctx, &q, variables)\n\t\t\tqueryDuration := time.Since(startTime)\n\n\t\t\tif err == nil {\n\t\t\t\tsuccess = true\n\t\t\t\tfmt.Printf(\"Query succeeded in %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t\t// Log the number of results received\n\t\t\t\tresultCount := len(q.Search.Nodes)\n\t\t\t\tfmt.Printf(\"Received %d results for page %d\\n\", resultCount, pageCount+1)\n\n\t\t\t\t// Process the results\n\t\t\t\tfor _, node := range q.Search.Nodes {\n\t\t\t\t\tpr := node.PullRequest\n\n\t\t\t\t\t// Extract labels\n\t\t\t\t\tvar labels []string\n\t\t\t\t\tfor _, label := range pr.Labels.Nodes {\n\t\t\t\t\t\tlabels = append(labels, string(label.Name))\n\t\t\t\t\t}\n\n\t\t\t\t\t// Create PR object\n\t\t\t\t\tnewPR := JUnit5PR{\n\t\t\t\t\t\tTitle:      string(pr.Title),\n\t\t\t\t\t\tURL:        string(pr.URL),\n\t\t\t\t\t\tRepository: string(pr.Repository.NameWithOwner),\n\t\t\t\t\t\tState:      string(pr.State),\n\t\t\t\t\t\tAuthor:     string(pr.Author.Login),\n\t\t\t\t\t\tLabels:     labels,\n\t\t\t\t\t\tBody:       string(pr.BodyText),\n\t\t\t\t\t\tCreatedAt:  pr.CreatedAt.Format(time.RFC3339),\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs created on or after the start date\n\t\t\t\t\tif pr.CreatedAt.Before(startDate) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs that are likely related to JUnit 5 migration\n\t\t\t\t\tif isJUnit5MigrationPR(newPR) {\n\t\t\t\t\t\tallPRs = append(allPRs, newPR)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Log progress\n\t\t\t\tfmt.Printf(\"Processed page %d, found %d matching PRs so far\\n\", pageCount+1, len(allPRs))\n\n\t\t\t\t// Check if there are more pages\n\t\t\t\tif !q.Search.PageInfo.HasNextPage {\n\t\t\t\t\tfmt.Printf(\"No more pages available, completed after %d pages\\n\", pageCount+1)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\n\t\t\t\t// Move to next page\n\t\t\t\tfmt.Printf(\"Moving to next page with cursor: %s\\n\", q.Search.PageInfo.EndCursor)\n\t\t\t\tvariables[\"after\"] = githubv4.NewString(q.Search.PageInfo.EndCursor)\n\n\t\t\t\t// Reset the attempt counter since we successfully processed this page\n\t\t\t\tattempt = 0\n\n\t\t\t\t// Add a small delay before the next page to avoid overwhelming GitHub\n\t\t\t\ttime.Sleep(1 * time.Second)\n\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Log detailed error information\n\t\t\tfmt.Printf(\"GitHub API error on attempt %d/%d (total %d): %v\\n\",\n\t\t\t\tattempt+1, maxRetries, totalAttempts, err)\n\t\t\tfmt.Printf(\"Query duration before error: %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t// Try to parse and log more details from the error\n\t\t\tvar errorDetails struct {\n\t\t\t\tData   interface{}            `json:\"data\"`\n\t\t\t\tErrors []map[string]interface{} `json:\"errors\"`\n\t\t\t}\n\n\t\t\tif strings.Contains(err.Error(), \"{\") {\n\t\t\t\terrorJSON := err.Error()[strings.Index(err.Error(), \"{\"): // Removed the -1\n\t\t\t\tif jsonErr := json.Unmarshal([]byte(errorJSON), &errorDetails); jsonErr == nil {\n\t\t\t\t\tif errorDetails.Errors != nil && len(errorDetails.Errors) > 0 {\n\t\t\t\t\t\tfmt.Println(\"Detailed error information:\")\n\t\t\t\t\t\tfor i, errDetail := range errorDetails.Errors {\n\t\t\t\t\t\t\tfmt.Printf(\"  Error %d:\\n\", i+1)\n\t\t\t\t\t\t\tfor k, v := range errDetail {\n\t\t\t\t\t\t\t\tfmt.Printf(\"    %s: %v\\n\", k, v)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Check if this is a retryable error (like 502)\n\t\t\tif strings.Contains(err.Error(), \"502\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"timeout\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"Something went wrong\") {\n\n\t\t\t\t// Calculate backoff duration with exponential increase and jitter\n\t\t\t\tbackoffTime := float64(initialBackoff) * math.Pow(2, float64(attempt))\n\t\t\t\tif backoffTime > float64(maxBackoff) {\n\t\t\t\t\tbackoffTime = float64(maxBackoff)\n\t\t\t\t}\n\n\t\t\t\t// Add jitter (±20%)\n\t\t\t\tjitter := (rand.Float64() * 0.4) - 0.2 // -20% to +20%\n\t\t\t\tbackoffTime = backoffTime * (1 + jitter)\n\n\t\t\t\tsleepDuration := time.Duration(backoffTime)\n\t\t\t\tfmt.Printf(\"Retrying in %v...\\n\", sleepDuration)\n\t\t\t\ttime.Sleep(sleepDuration)\n\t\t\t} else {\n\t\t\t\t// Non-retryable error, break out\n\t\t\t\tfmt.Println(\"Non-retryable error encountered, stopping retry attempts\")\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !success {\n\t\t\tfmt.Printf(\"Failed after %d attempts: %v\\n\", maxRetries, err)\n\t\t\tfmt.Println(\"Continuing with results collected so far...\")\n\t\t\treturn allPRs\n\t\t}\n\t}\n\n\tfmt.Printf(\"Search completed. Found %d matching PRs for query: %s\\n\", len(allPRs), query)\n\treturn allPRs\n}\n\n// isJUnit5MigrationPR checks if a PR is likely related to JUnit 5 migration\nfunc isJUnit5MigrationPR(pr JUnit5PR) bool {\n\t// Exclude dependency bumps\n\tif strings.HasPrefix(pr.Title, \"Bump\") || strings.HasPrefix(pr.Title, \"bump\") {\n\t\treturn false\n\t}\n\n\t// Exclude PRs with specific JIRA ticket prefixes that are known not to be JUnit 5 related\n\t// These are examples of tickets that were incorrectly included\n\texcludePatterns := []string{\n\t\t`(?i)JENKINS-70560`,         // Improve test coverage\n\t\t`(?i)JENKINS-75447`,         // Fix Snippetizer rendering\n\t\t`(?i)JENKINS-\\d+.*fix`,      // General fixes\n\t\t`(?i)fix`,                   // General fixes\n\t\t`(?i)improve test coverage`, // Test coverage improvements not related to JUnit 5\n\t}\n\n\tfor _, pattern := range excludePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Define more specific patterns for JUnit 5 migration PRs\n\ttitlePatterns := []string{\n\t\t`(?i)migrate tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t}\n\n\tbodyPatterns := []string{\n\t\t`(?i)migrate (all )?tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t\t`(?i)org\\.junit\\.jupiter`,\n\t\t`(?i)junit-jupiter`,\n\t}\n\n\tlabelPatterns := []string{\n\t\t`(?i)\\bjunit ?5\\b`,\n\t\t`(?i)junit-5`,\n\t\t`(?i)junit-migration`,\n\t}\n\n\tauthorPatterns := []string{\n\t\t`strangelookingnerd`,\n\t}\n\n\t// Check title with more specific matching\n\tfor _, pattern := range titlePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn true\n\t\t}\n\t}\n\n\t// For body matches, require stronger evidence\n\t// Count how many patterns match in the body\n\tbodyMatchCount := 0\n\tfor _, pattern := range bodyPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Body)\n\t\tif matched {\n\t\t\tbodyMatchCount++\n\t\t}\n\t}\n\n\t// Require at least 2 body pattern matches for a positive identification\n\t// This helps avoid false positives from PRs that mention JUnit in passing\n\tif bodyMatchCount >= 2 {\n\t\treturn true\n\t}\n\n\t// Check labels\n\tfor _, label := range pr.Labels {\n\t\tfor _, pattern := range labelPatterns {\n\t\t\tmatched, _ := regexp.MatchString(pattern, label)\n\t\t\tif matched {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check author - but only if there's at least some mention of JUnit in the body\n\t// This avoids including all PRs from certain authors\n\tfor _, pattern := range authorPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Author)\n\t\tif matched {\n\t\t\t// Check if there's at least some mention of JUnit in the body\n\t\t\tjunitmatch, _ := regexp.MatchString(`(?i)junit`, pr.Body)\n\t\t\tif junitmatch {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\treturn false\n}\n\n// removeDuplicates removes duplicate PRs from the slice\nfunc removeDuplicates(prs []JUnit5PR) []JUnit5PR {\n\tseen := make(map[string]bool)\n\tvar result []JUnit5PR\n\n\tfor _, pr := range prs {\n\t\tif !seen[pr.URL] {\n\t\t\tseen[pr.URL] = true\n\t\t\tresult = append(result, pr)\n\t\t}\n\t}\n\n\treturn result\n}\n\n// generateCandidateURLsFile creates a text file with PR URLs for easy addition to junit5_pr_urls.txt\nfunc generateCandidateURLsFile(prs []JUnit5PR, outputFile string) {\n\tfile, err := os.Create(outputFile)\n\tif err != nil {\n\t\tfmt.Printf(\"Error creating file: %v\\n\", err)\n\t\treturn\n\t}\n\tdefer file.Close()\n\n\tfile.WriteString(fmt.Sprintf(\"# JUnit 5 migration PR candidates found on %s\\n\", time.Now().Format(\"2006-01-02 15:04:05\")))\n\tfile.WriteString(\"# Add relevant URLs to junit5_pr_urls.txt after verification\\n\\n\")\n\n\tfor _, pr := range prs {\n\t\tfile.WriteString(fmt.Sprintf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State))\n\t\tfile.WriteString(fmt.Sprintf(\"%s\\n\\n\", pr.URL))\n\t}\n}\n\n// compareWithExistingPRs compares found PRs with those already in junit5_pr_urls.txt\nfunc compareWithExistingPRs(prs []JUnit5PR, existingFile string) {\n\t// Read existing PR URLs\n\texistingURLs := make(map[string]bool)\n\n\tdata, err := ioutil.ReadFile(existingFile)\n\tif err == nil {\n\t\tlines := strings.Split(string(data), \"\\n\")\n\t\tfor _, line := range lines {\n\t\t\tline = strings.TrimSpace(line)\n\t\t\tif strings.HasPrefix(line, \"https://\") {\n\t\t\t\texistingURLs[line] = true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Find new PRs\n\tvar newPRs []JUnit5PR\n\tfor _, pr := range prs {\n\t\tif !existingURLs[pr.URL] {\n\t\t\tnewPRs = append(newPRs, pr)\n\t\t}\n\t}\n\n\tfmt.Printf(\"Found %d new PR candidates not already in %s\\n\", len(newPRs), existingFile)\n\n\tif len(newPRs) > 0 {\n\t\tfmt.Println(\"New PR candidates:\")\n\t\tfor _, pr := range newPRs {\n\t\t\tfmt.Printf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State)\n\t\t\tfmt.Printf(\"%s\\n\\n\", pr.URL)\n\t\t}\n\t}\n}\n"
                    }
                ]
            },
            "createdAt": 1744710473909,
            "isInternal": false
        },
        {
            "id": "e7f088a9-f6c5-4003-95bb-ffd21b69c3b4",
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "[ERROR] Medium: Suppressing annotation on the method new jenkins.plugin.android.emulator.tools.AndroidSDKInstaller$AndroidSDKInstallable(AndroidSDKInstaller, DownloadFromUrlInstaller$Installable) is unnecessary [jenkins.plugin.android.emulator.tools.AndroidSDKInstaller$AndroidSDKInstallable] At AndroidSDKInstaller.java:[lines 70-72] US_USELESS_SUPPRESSION_ON_METHOD"
                }
            ],
            "context": {
                "currentFile": {
                    "path": "cmd\\find-junit5-prs\\main.go",
                    "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                    "sources": [
                        "opened_tab"
                    ],
                    "content": "package main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"math\"\n\t\"math/rand\"\n\t\"net/http\"\n\t\"os\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/shurcooL/githubv4\"\n\t\"golang.org/x/oauth2\"\n)\n\n// JUnit5PR represents a GitHub pull request related to JUnit 5 migration\ntype JUnit5PR struct {\n\tTitle      string   `json:\"title\"`\n\tURL        string   `json:\"url\"`\n\tRepository string   `json:\"repository\"`\n\tState      string   `json:\"state\"`\n\tAuthor     string   `json:\"author\"`\n\tLabels     []string `json:\"labels\"`\n\tBody       string   `json:\"body\"`\n\tCreatedAt  string   `json:\"createdAt\"`\n}\n\n// SearchResult holds the PRs found in the search\ntype SearchResult struct {\n\tPRs []JUnit5PR `json:\"prs\"`\n}\n\n// GraphQL query structure for searching pull requests\ntype searchQuery struct {\n\tSearch struct {\n\t\tPageInfo struct {\n\t\t\tHasNextPage bool\n\t\t\tEndCursor   githubv4.String\n\t\t}\n\t\tNodes []struct {\n\t\t\tPullRequest struct {\n\t\t\t\tTitle     githubv4.String\n\t\t\t\tURL       githubv4.String\n\t\t\t\tState     githubv4.String\n\t\t\t\tCreatedAt githubv4.DateTime\n\t\t\t\tAuthor    struct {\n\t\t\t\t\tLogin githubv4.String\n\t\t\t\t}\n\t\t\t\tRepository struct {\n\t\t\t\t\tNameWithOwner githubv4.String\n\t\t\t\t}\n\t\t\t\tLabels struct {\n\t\t\t\t\tNodes []struct {\n\t\t\t\t\t\tName githubv4.String\n\t\t\t\t\t}\n\t\t\t\t} `graphql:\"labels(first: 10)\"`\n\t\t\t\tBodyText githubv4.String\n\t\t\t} `graphql:\"... on PullRequest\"`\n\t\t}\n\t} `graphql:\"search(query: $query, type: ISSUE, first: $first, after: $after)\"`\n}\n\nfunc main() {\n\t// Parse command line flags\n\toutputDir := flag.String(\"output-dir\", \"data/junit5\", \"Directory to store output files\")\n\tcandidateFile := flag.String(\"candidate-file\", \"junit5_candidate_prs.txt\", \"File to store candidate PR URLs\")\n\texistingFile := flag.String(\"existing-file\", \"junit5_pr_urls.txt\", \"File containing existing PR URLs\")\n\tstartDate := flag.String(\"start-date\", \"2024-07-01\", \"Start date for PR search (YYYY-MM-DD)\")\n\tflag.Parse()\n\n\t// Get GitHub token from environment\n\ttoken := os.Getenv(\"GITHUB_TOKEN\")\n\tif token == \"\" {\n\t\tfmt.Println(\"GITHUB_TOKEN environment variable is required\")\n\t\tos.Exit(1)\n\t}\n\n\t// Parse start date\n\tstartDateTime, err := time.Parse(\"2006-01-02\", *startDate)\n\tif err != nil {\n\t\tfmt.Printf(\"Error parsing start date: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tfmt.Printf(\"Searching for PRs created on or after: %s\\n\", startDateTime.Format(\"2006-01-02\"))\n\n\t// Create output directory if it doesn't exist\n\tos.MkdirAll(*outputDir, 0755)\n\n\t// Create GitHub client\n\tsrc := oauth2.StaticTokenSource(\n\t\t&oauth2.Token{AccessToken: token},\n\t)\n\thttpClient := oauth2.NewClient(context.Background(), src)\n\tclient := githubv4.NewClient(httpClient)\n\n\t// Define search terms\n\tsearchTerms := []string{\n\t\t\"junit5\",\n\t\t\"junit 5\",\n\t\t\"migrate tests to junit\",\n\t\t\"junit jupiter\",\n\t\t\"openrewrite junit\",\n\t}\n\n\t// Initialize result\n\tresult := SearchResult{\n\t\tPRs: []JUnit5PR{},\n\t}\n\n\t// Search for each term\n\tfor _, term := range searchTerms {\n\t\tfmt.Printf(\"Searching for: %s\\n\", term)\n\n\t\t// Search in title\n\t\ttitleQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:title %s\", term)\n\t\tprs := searchPRs(client, titleQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\n\t\t// Search in body\n\t\tbodyQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:body %s\", term)\n\t\tprs = searchPRs(client, bodyQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\t}\n\n\t// Search for PRs by specific authors known for JUnit 5 migrations\n\tfmt.Println(\"Searching for PRs by known JUnit 5 migration authors...\")\n\tauthorQuery := \"org:jenkinsci is:pr author:strangelookingnerd\"\n\tprs := searchPRs(client, authorQuery, startDateTime)\n\tresult.PRs = append(result.PRs, prs...)\n\n\t// Remove duplicates\n\tresult.PRs = removeDuplicates(result.PRs)\n\n\t// Save results to JSON file\n\tjsonData, err := json.MarshalIndent(result, \"\", \"  \")\n\tif err != nil {\n\t\tfmt.Printf(\"Error marshaling JSON: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\toutputFile := fmt.Sprintf(\"%s/junit5_candidates.json\", *outputDir)\n\terr = ioutil.WriteFile(outputFile, jsonData, 0644)\n\tif err != nil {\n\t\tfmt.Printf(\"Error writing JSON file: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Generate text file with URLs for easy addition to junit5_pr_urls.txt\n\tgenerateCandidateURLsFile(result.PRs, *candidateFile)\n\n\t// Compare with existing PRs in junit5_pr_urls.txt\n\tcompareWithExistingPRs(result.PRs, *existingFile)\n\n\tfmt.Printf(\"Found %d potential JUnit 5 migration PR candidates\\n\", len(result.PRs))\n\tfmt.Printf(\"Results saved to %s and %s\\n\", outputFile, *candidateFile)\n}\n\n// searchPRs performs a GitHub search and returns PRs matching the query\nfunc searchPRs(client *githubv4.Client, query string, startDate time.Time) []JUnit5PR {\n\tvar q searchQuery\n\tvariables := map[string]interface{}{\n\t\t\"query\": githubv4.String(query),\n\t\t\"first\": githubv4.Int(10), // Reduced from 25 to 10 to make queries even less complex\n\t\t\"after\": (*githubv4.String)(nil),\n\t}\n\n\tvar allPRs []JUnit5PR\n\tmaxRetries := 10 // Increased from 5 to 10\n\tinitialBackoff := 2 * time.Second\n\tmaxBackoff := 60 * time.Second\n\n\t// Log the query being executed\n\tfmt.Printf(\"Executing GitHub GraphQL query: %s\\n\", query)\n\tfmt.Printf(\"Start date: %s\\n\", startDate.Format(time.RFC3339))\n\n\tpageCount := 0\n\ttotalAttempts := 0\n\tfor {\n\t\t// Add a small delay between requests to respect rate limits\n\t\ttime.Sleep(1 * time.Second)\n\n\t\t// Create a context with timeout\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n\t\tdefer cancel()\n\n\t\tvar err error\n\t\tsuccess := false\n\n\t\t// Implement retry with exponential backoff\n\t\tfor attempt := 0; attempt < maxRetries && !success; attempt++ {\n\t\t\ttotalAttempts++\n\n\t\t\t// Get current rate limit information before making the request\n\t\t\tvar rateLimit struct {\n\t\t\t\tRateLimit struct {\n\t\t\t\t\tLimit     githubv4.Int\n\t\t\t\t\tRemaining githubv4.Int\n\t\t\t\t\tResetAt   githubv4.DateTime\n\t\t\t\t} `graphql:\"rateLimit\"`\n\t\t\t}\n\n\t\t\trateLimitErr := client.Query(context.Background(), &rateLimit, nil)\n\t\t\tif rateLimitErr == nil {\n\t\t\t\tfmt.Printf(\"GitHub API rate limit: %d/%d remaining, resets at %s\\n\",\n\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\trateLimit.RateLimit.Limit,\n\t\t\t\t\trateLimit.RateLimit.ResetAt.Format(time.RFC3339))\n\n\t\t\t\t// Check if we're close to hitting the rate limit\n\t\t\t\tif rateLimit.RateLimit.Remaining < 100 {\n\t\t\t\t\tresetTime := time.Until(rateLimit.RateLimit.ResetAt.Time)\n\t\t\t\t\tfmt.Printf(\"WARNING: Rate limit is low (%d remaining). Limit resets in %s\\n\",\n\t\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\t\tresetTime.Round(time.Second))\n\n\t\t\t\t\tif rateLimit.RateLimit.Remaining < 10 {\n\t\t\t\t\t\tfmt.Println(\"Rate limit critically low, waiting until reset...\")\n\t\t\t\t\t\twaitTime := time.Until(rateLimit.RateLimit.ResetAt.Time) + 10*time.Second\n\t\t\t\t\t\ttime.Sleep(waitTime)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfmt.Printf(\"Could not fetch rate limit info: %v\\n\", rateLimitErr)\n\t\t\t}\n\n\t\t\t// Execute the actual query\n\t\t\tstartTime := time.Now()\n\t\t\terr = client.Query(ctx, &q, variables)\n\t\t\tqueryDuration := time.Since(startTime)\n\n\t\t\tif err == nil {\n\t\t\t\tsuccess = true\n\t\t\t\tfmt.Printf(\"Query succeeded in %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t\t// Log the number of results received\n\t\t\t\tresultCount := len(q.Search.Nodes)\n\t\t\t\tfmt.Printf(\"Received %d results for page %d\\n\", resultCount, pageCount+1)\n\n\t\t\t\t// Process the results\n\t\t\t\tfor _, node := range q.Search.Nodes {\n\t\t\t\t\tpr := node.PullRequest\n\n\t\t\t\t\t// Extract labels\n\t\t\t\t\tvar labels []string\n\t\t\t\t\tfor _, label := range pr.Labels.Nodes {\n\t\t\t\t\t\tlabels = append(labels, string(label.Name))\n\t\t\t\t\t}\n\n\t\t\t\t\t// Create PR object\n\t\t\t\t\tnewPR := JUnit5PR{\n\t\t\t\t\t\tTitle:      string(pr.Title),\n\t\t\t\t\t\tURL:        string(pr.URL),\n\t\t\t\t\t\tRepository: string(pr.Repository.NameWithOwner),\n\t\t\t\t\t\tState:      string(pr.State),\n\t\t\t\t\t\tAuthor:     string(pr.Author.Login),\n\t\t\t\t\t\tLabels:     labels,\n\t\t\t\t\t\tBody:       string(pr.BodyText),\n\t\t\t\t\t\tCreatedAt:  pr.CreatedAt.Format(time.RFC3339),\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs created on or after the start date\n\t\t\t\t\tif pr.CreatedAt.Before(startDate) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs that are likely related to JUnit 5 migration\n\t\t\t\t\tif isJUnit5MigrationPR(newPR) {\n\t\t\t\t\t\tallPRs = append(allPRs, newPR)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Log progress\n\t\t\t\tfmt.Printf(\"Processed page %d, found %d matching PRs so far\\n\", pageCount+1, len(allPRs))\n\n\t\t\t\t// Check if there are more pages\n\t\t\t\tif !q.Search.PageInfo.HasNextPage {\n\t\t\t\t\tfmt.Printf(\"No more pages available, completed after %d pages\\n\", pageCount+1)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\n\t\t\t\t// Move to next page\n\t\t\t\tfmt.Printf(\"Moving to next page with cursor: %s\\n\", q.Search.PageInfo.EndCursor)\n\t\t\t\tvariables[\"after\"] = githubv4.NewString(q.Search.PageInfo.EndCursor)\n\n\t\t\t\t// Reset the attempt counter since we successfully processed this page\n\t\t\t\tattempt = 0\n\n\t\t\t\t// Add a small delay before the next page to avoid overwhelming GitHub\n\t\t\t\ttime.Sleep(1 * time.Second)\n\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Log detailed error information\n\t\t\tfmt.Printf(\"GitHub API error on attempt %d/%d (total %d): %v\\n\",\n\t\t\t\tattempt+1, maxRetries, totalAttempts, err)\n\t\t\tfmt.Printf(\"Query duration before error: %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t// Try to parse and log more details from the error\n\t\t\tvar errorDetails struct {\n\t\t\t\tData   interface{}            `json:\"data\"`\n\t\t\t\tErrors []map[string]interface{} `json:\"errors\"`\n\t\t\t}\n\n\t\t\tif strings.Contains(err.Error(), \"{\") {\n\t\t\t\terrorJSON := err.Error()[strings.Index(err.Error(), \"{\"): // Removed the -1\n\t\t\t\tif jsonErr := json.Unmarshal([]byte(errorJSON), &errorDetails); jsonErr == nil {\n\t\t\t\t\tif errorDetails.Errors != nil && len(errorDetails.Errors) > 0 {\n\t\t\t\t\t\tfmt.Println(\"Detailed error information:\")\n\t\t\t\t\t\tfor i, errDetail := range errorDetails.Errors {\n\t\t\t\t\t\t\tfmt.Printf(\"  Error %d:\\n\", i+1)\n\t\t\t\t\t\t\tfor k, v := range errDetail {\n\t\t\t\t\t\t\t\tfmt.Printf(\"    %s: %v\\n\", k, v)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Check if this is a retryable error (like 502)\n\t\t\tif strings.Contains(err.Error(), \"502\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"timeout\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"Something went wrong\") {\n\n\t\t\t\t// Calculate backoff duration with exponential increase and jitter\n\t\t\t\tbackoffTime := float64(initialBackoff) * math.Pow(2, float64(attempt))\n\t\t\t\tif backoffTime > float64(maxBackoff) {\n\t\t\t\t\tbackoffTime = float64(maxBackoff)\n\t\t\t\t}\n\n\t\t\t\t// Add jitter (±20%)\n\t\t\t\tjitter := (rand.Float64() * 0.4) - 0.2 // -20% to +20%\n\t\t\t\tbackoffTime = backoffTime * (1 + jitter)\n\n\t\t\t\tsleepDuration := time.Duration(backoffTime)\n\t\t\t\tfmt.Printf(\"Retrying in %v...\\n\", sleepDuration)\n\t\t\t\ttime.Sleep(sleepDuration)\n\t\t\t} else {\n\t\t\t\t// Non-retryable error, break out\n\t\t\t\tfmt.Println(\"Non-retryable error encountered, stopping retry attempts\")\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !success {\n\t\t\tfmt.Printf(\"Failed after %d attempts: %v\\n\", maxRetries, err)\n\t\t\tfmt.Println(\"Continuing with results collected so far...\")\n\t\t\treturn allPRs\n\t\t}\n\t}\n\n\tfmt.Printf(\"Search completed. Found %d matching PRs for query: %s\\n\", len(allPRs), query)\n\treturn allPRs\n}\n\n// isJUnit5MigrationPR checks if a PR is likely related to JUnit 5 migration\nfunc isJUnit5MigrationPR(pr JUnit5PR) bool {\n\t// Exclude dependency bumps\n\tif strings.HasPrefix(pr.Title, \"Bump\") || strings.HasPrefix(pr.Title, \"bump\") {\n\t\treturn false\n\t}\n\n\t// Exclude PRs with specific JIRA ticket prefixes that are known not to be JUnit 5 related\n\t// These are examples of tickets that were incorrectly included\n\texcludePatterns := []string{\n\t\t`(?i)JENKINS-70560`,         // Improve test coverage\n\t\t`(?i)JENKINS-75447`,         // Fix Snippetizer rendering\n\t\t`(?i)JENKINS-\\d+.*fix`,      // General fixes\n\t\t`(?i)fix`,                   // General fixes\n\t\t`(?i)improve test coverage`, // Test coverage improvements not related to JUnit 5\n\t}\n\n\tfor _, pattern := range excludePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Define more specific patterns for JUnit 5 migration PRs\n\ttitlePatterns := []string{\n\t\t`(?i)migrate tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t}\n\n\tbodyPatterns := []string{\n\t\t`(?i)migrate (all )?tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t\t`(?i)org\\.junit\\.jupiter`,\n\t\t`(?i)junit-jupiter`,\n\t}\n\n\tlabelPatterns := []string{\n\t\t`(?i)\\bjunit ?5\\b`,\n\t\t`(?i)junit-5`,\n\t\t`(?i)junit-migration`,\n\t}\n\n\tauthorPatterns := []string{\n\t\t`strangelookingnerd`,\n\t}\n\n\t// Check title with more specific matching\n\tfor _, pattern := range titlePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn true\n\t\t}\n\t}\n\n\t// For body matches, require stronger evidence\n\t// Count how many patterns match in the body\n\tbodyMatchCount := 0\n\tfor _, pattern := range bodyPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Body)\n\t\tif matched {\n\t\t\tbodyMatchCount++\n\t\t}\n\t}\n\n\t// Require at least 2 body pattern matches for a positive identification\n\t// This helps avoid false positives from PRs that mention JUnit in passing\n\tif bodyMatchCount >= 2 {\n\t\treturn true\n\t}\n\n\t// Check labels\n\tfor _, label := range pr.Labels {\n\t\tfor _, pattern := range labelPatterns {\n\t\t\tmatched, _ := regexp.MatchString(pattern, label)\n\t\t\tif matched {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check author - but only if there's at least some mention of JUnit in the body\n\t// This avoids including all PRs from certain authors\n\tfor _, pattern := range authorPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Author)\n\t\tif matched {\n\t\t\t// Check if there's at least some mention of JUnit in the body\n\t\t\tjunitmatch, _ := regexp.MatchString(`(?i)junit`, pr.Body)\n\t\t\tif junitmatch {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\treturn false\n}\n\n// removeDuplicates removes duplicate PRs from the slice\nfunc removeDuplicates(prs []JUnit5PR) []JUnit5PR {\n\tseen := make(map[string]bool)\n\tvar result []JUnit5PR\n\n\tfor _, pr := range prs {\n\t\tif !seen[pr.URL] {\n\t\t\tseen[pr.URL] = true\n\t\t\tresult = append(result, pr)\n\t\t}\n\t}\n\n\treturn result\n}\n\n// generateCandidateURLsFile creates a text file with PR URLs for easy addition to junit5_pr_urls.txt\nfunc generateCandidateURLsFile(prs []JUnit5PR, outputFile string) {\n\tfile, err := os.Create(outputFile)\n\tif err != nil {\n\t\tfmt.Printf(\"Error creating file: %v\\n\", err)\n\t\treturn\n\t}\n\tdefer file.Close()\n\n\tfile.WriteString(fmt.Sprintf(\"# JUnit 5 migration PR candidates found on %s\\n\", time.Now().Format(\"2006-01-02 15:04:05\")))\n\tfile.WriteString(\"# Add relevant URLs to junit5_pr_urls.txt after verification\\n\\n\")\n\n\tfor _, pr := range prs {\n\t\tfile.WriteString(fmt.Sprintf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State))\n\t\tfile.WriteString(fmt.Sprintf(\"%s\\n\\n\", pr.URL))\n\t}\n}\n\n// compareWithExistingPRs compares found PRs with those already in junit5_pr_urls.txt\nfunc compareWithExistingPRs(prs []JUnit5PR, existingFile string) {\n\t// Read existing PR URLs\n\texistingURLs := make(map[string]bool)\n\n\tdata, err := ioutil.ReadFile(existingFile)\n\tif err == nil {\n\t\tlines := strings.Split(string(data), \"\\n\")\n\t\tfor _, line := range lines {\n\t\t\tline = strings.TrimSpace(line)\n\t\t\tif strings.HasPrefix(line, \"https://\") {\n\t\t\t\texistingURLs[line] = true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Find new PRs\n\tvar newPRs []JUnit5PR\n\tfor _, pr := range prs {\n\t\tif !existingURLs[pr.URL] {\n\t\t\tnewPRs = append(newPRs, pr)\n\t\t}\n\t}\n\n\tfmt.Printf(\"Found %d new PR candidates not already in %s\\n\", len(newPRs), existingFile)\n\n\tif len(newPRs) > 0 {\n\t\tfmt.Println(\"New PR candidates:\")\n\t\tfor _, pr := range newPRs {\n\t\t\tfmt.Printf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State)\n\t\t\tfmt.Printf(\"%s\\n\\n\", pr.URL)\n\t\t}\n\t}\n}\n"
                },
                "codebaseEnabled": true,
                "ragFiles": [
                    {
                        "path": "Dockerfile",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\Dockerfile",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/tqdm/utils.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\tqdm\\utils.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "upload_to_sheets.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\upload_to_sheets.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "jenkins-pr-collector.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\jenkins-pr-collector.go",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/pygments/lexers/__init__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\pygments\\lexers\\__init__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/pygments/styles/__init__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\pygments\\styles\\__init__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/pygments/filters/__init__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\pygments\\filters\\__init__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/pygments/formatters/__init__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\pygments\\formatters\\__init__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/logging.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\logging.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/exceptions.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\exceptions.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/metadata/__init__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\metadata\\__init__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/factory.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/resolver.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pyparsing/util.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pyparsing\\util.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pyparsing/helpers.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pyparsing\\helpers.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pyparsing/diagram/__init__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pyparsing\\diagram\\__init__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/operations/check.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\operations\\check.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pyparsing/core.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pyparsing\\core.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/ansi.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\ansi.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/console.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\console.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "analyze-junit5-prs.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\analyze-junit5-prs.sh",
                        "sources": []
                    },
                    {
                        "path": "test-pr-builds.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\test-pr-builds.sh",
                        "sources": []
                    },
                    {
                        "path": "junit5-migration-prs.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\junit5-migration-prs.sh",
                        "sources": []
                    },
                    {
                        "path": "cmd\\find-junit5-prs\\main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": []
                    },
                    {
                        "path": "find-junit5-prs.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\find-junit5-prs.sh",
                        "sources": []
                    },
                    {
                        "path": "cmd\\find-junit5-prs\\go.mod",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\go.mod",
                        "sources": []
                    },
                    {
                        "path": "data\\consolidated\\failing_prs.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\failing_prs.json",
                        "sources": []
                    },
                    {
                        "path": "data\\monthly\\filtered_prs_2025_03.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\monthly\\filtered_prs_2025_03.json",
                        "sources": []
                    },
                    {
                        "path": "data\\monthly\\prs_2025_03.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\monthly\\prs_2025_03.json",
                        "sources": []
                    },
                    {
                        "path": "filtered_prs_filtered_prs_2025_02.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\filtered_prs_filtered_prs_2025_02.json",
                        "sources": []
                    },
                    {
                        "path": "data\\monthly\\prs_2025_02.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\monthly\\prs_2025_02.json",
                        "sources": []
                    },
                    {
                        "path": "data\\monthly\\filtered_prs_2025_02.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\monthly\\filtered_prs_2025_02.json",
                        "sources": []
                    },
                    {
                        "path": "data/consolidated/failed_builds.csv",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\failed_builds.csv",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "data/consolidated/successful_builds.csv",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\successful_builds.csv",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "data/consolidated/test_results.csv",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\test_results.csv",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "update-daily.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\update-daily.sh",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "upload_to_sheets.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\upload_to_sheets.py",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "data/junit5/junit5_migration_prs.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\junit5\\junit5_migration_prs.json",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "cmd/find-junit5-prs/main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": [
                            "opened_tab"
                        ]
                    }
                ],
                "rerankedFiles": [],
                "usedFilePaths": [
                    {
                        "path": "cmd\\find-junit5-prs\\main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": [
                            "opened_tab"
                        ],
                        "content": "package main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"math\"\n\t\"math/rand\"\n\t\"net/http\"\n\t\"os\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/shurcooL/githubv4\"\n\t\"golang.org/x/oauth2\"\n)\n\n// JUnit5PR represents a GitHub pull request related to JUnit 5 migration\ntype JUnit5PR struct {\n\tTitle      string   `json:\"title\"`\n\tURL        string   `json:\"url\"`\n\tRepository string   `json:\"repository\"`\n\tState      string   `json:\"state\"`\n\tAuthor     string   `json:\"author\"`\n\tLabels     []string `json:\"labels\"`\n\tBody       string   `json:\"body\"`\n\tCreatedAt  string   `json:\"createdAt\"`\n}\n\n// SearchResult holds the PRs found in the search\ntype SearchResult struct {\n\tPRs []JUnit5PR `json:\"prs\"`\n}\n\n// GraphQL query structure for searching pull requests\ntype searchQuery struct {\n\tSearch struct {\n\t\tPageInfo struct {\n\t\t\tHasNextPage bool\n\t\t\tEndCursor   githubv4.String\n\t\t}\n\t\tNodes []struct {\n\t\t\tPullRequest struct {\n\t\t\t\tTitle     githubv4.String\n\t\t\t\tURL       githubv4.String\n\t\t\t\tState     githubv4.String\n\t\t\t\tCreatedAt githubv4.DateTime\n\t\t\t\tAuthor    struct {\n\t\t\t\t\tLogin githubv4.String\n\t\t\t\t}\n\t\t\t\tRepository struct {\n\t\t\t\t\tNameWithOwner githubv4.String\n\t\t\t\t}\n\t\t\t\tLabels struct {\n\t\t\t\t\tNodes []struct {\n\t\t\t\t\t\tName githubv4.String\n\t\t\t\t\t}\n\t\t\t\t} `graphql:\"labels(first: 10)\"`\n\t\t\t\tBodyText githubv4.String\n\t\t\t} `graphql:\"... on PullRequest\"`\n\t\t}\n\t} `graphql:\"search(query: $query, type: ISSUE, first: $first, after: $after)\"`\n}\n\nfunc main() {\n\t// Parse command line flags\n\toutputDir := flag.String(\"output-dir\", \"data/junit5\", \"Directory to store output files\")\n\tcandidateFile := flag.String(\"candidate-file\", \"junit5_candidate_prs.txt\", \"File to store candidate PR URLs\")\n\texistingFile := flag.String(\"existing-file\", \"junit5_pr_urls.txt\", \"File containing existing PR URLs\")\n\tstartDate := flag.String(\"start-date\", \"2024-07-01\", \"Start date for PR search (YYYY-MM-DD)\")\n\tflag.Parse()\n\n\t// Get GitHub token from environment\n\ttoken := os.Getenv(\"GITHUB_TOKEN\")\n\tif token == \"\" {\n\t\tfmt.Println(\"GITHUB_TOKEN environment variable is required\")\n\t\tos.Exit(1)\n\t}\n\n\t// Parse start date\n\tstartDateTime, err := time.Parse(\"2006-01-02\", *startDate)\n\tif err != nil {\n\t\tfmt.Printf(\"Error parsing start date: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tfmt.Printf(\"Searching for PRs created on or after: %s\\n\", startDateTime.Format(\"2006-01-02\"))\n\n\t// Create output directory if it doesn't exist\n\tos.MkdirAll(*outputDir, 0755)\n\n\t// Create GitHub client\n\tsrc := oauth2.StaticTokenSource(\n\t\t&oauth2.Token{AccessToken: token},\n\t)\n\thttpClient := oauth2.NewClient(context.Background(), src)\n\tclient := githubv4.NewClient(httpClient)\n\n\t// Define search terms\n\tsearchTerms := []string{\n\t\t\"junit5\",\n\t\t\"junit 5\",\n\t\t\"migrate tests to junit\",\n\t\t\"junit jupiter\",\n\t\t\"openrewrite junit\",\n\t}\n\n\t// Initialize result\n\tresult := SearchResult{\n\t\tPRs: []JUnit5PR{},\n\t}\n\n\t// Search for each term\n\tfor _, term := range searchTerms {\n\t\tfmt.Printf(\"Searching for: %s\\n\", term)\n\n\t\t// Search in title\n\t\ttitleQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:title %s\", term)\n\t\tprs := searchPRs(client, titleQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\n\t\t// Search in body\n\t\tbodyQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:body %s\", term)\n\t\tprs = searchPRs(client, bodyQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\t}\n\n\t// Search for PRs by specific authors known for JUnit 5 migrations\n\tfmt.Println(\"Searching for PRs by known JUnit 5 migration authors...\")\n\tauthorQuery := \"org:jenkinsci is:pr author:strangelookingnerd\"\n\tprs := searchPRs(client, authorQuery, startDateTime)\n\tresult.PRs = append(result.PRs, prs...)\n\n\t// Remove duplicates\n\tresult.PRs = removeDuplicates(result.PRs)\n\n\t// Save results to JSON file\n\tjsonData, err := json.MarshalIndent(result, \"\", \"  \")\n\tif err != nil {\n\t\tfmt.Printf(\"Error marshaling JSON: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\toutputFile := fmt.Sprintf(\"%s/junit5_candidates.json\", *outputDir)\n\terr = ioutil.WriteFile(outputFile, jsonData, 0644)\n\tif err != nil {\n\t\tfmt.Printf(\"Error writing JSON file: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Generate text file with URLs for easy addition to junit5_pr_urls.txt\n\tgenerateCandidateURLsFile(result.PRs, *candidateFile)\n\n\t// Compare with existing PRs in junit5_pr_urls.txt\n\tcompareWithExistingPRs(result.PRs, *existingFile)\n\n\tfmt.Printf(\"Found %d potential JUnit 5 migration PR candidates\\n\", len(result.PRs))\n\tfmt.Printf(\"Results saved to %s and %s\\n\", outputFile, *candidateFile)\n}\n\n// searchPRs performs a GitHub search and returns PRs matching the query\nfunc searchPRs(client *githubv4.Client, query string, startDate time.Time) []JUnit5PR {\n\tvar q searchQuery\n\tvariables := map[string]interface{}{\n\t\t\"query\": githubv4.String(query),\n\t\t\"first\": githubv4.Int(10), // Reduced from 25 to 10 to make queries even less complex\n\t\t\"after\": (*githubv4.String)(nil),\n\t}\n\n\tvar allPRs []JUnit5PR\n\tmaxRetries := 10 // Increased from 5 to 10\n\tinitialBackoff := 2 * time.Second\n\tmaxBackoff := 60 * time.Second\n\n\t// Log the query being executed\n\tfmt.Printf(\"Executing GitHub GraphQL query: %s\\n\", query)\n\tfmt.Printf(\"Start date: %s\\n\", startDate.Format(time.RFC3339))\n\n\tpageCount := 0\n\ttotalAttempts := 0\n\tfor {\n\t\t// Add a small delay between requests to respect rate limits\n\t\ttime.Sleep(1 * time.Second)\n\n\t\t// Create a context with timeout\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n\t\tdefer cancel()\n\n\t\tvar err error\n\t\tsuccess := false\n\n\t\t// Implement retry with exponential backoff\n\t\tfor attempt := 0; attempt < maxRetries && !success; attempt++ {\n\t\t\ttotalAttempts++\n\n\t\t\t// Get current rate limit information before making the request\n\t\t\tvar rateLimit struct {\n\t\t\t\tRateLimit struct {\n\t\t\t\t\tLimit     githubv4.Int\n\t\t\t\t\tRemaining githubv4.Int\n\t\t\t\t\tResetAt   githubv4.DateTime\n\t\t\t\t} `graphql:\"rateLimit\"`\n\t\t\t}\n\n\t\t\trateLimitErr := client.Query(context.Background(), &rateLimit, nil)\n\t\t\tif rateLimitErr == nil {\n\t\t\t\tfmt.Printf(\"GitHub API rate limit: %d/%d remaining, resets at %s\\n\",\n\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\trateLimit.RateLimit.Limit,\n\t\t\t\t\trateLimit.RateLimit.ResetAt.Format(time.RFC3339))\n\n\t\t\t\t// Check if we're close to hitting the rate limit\n\t\t\t\tif rateLimit.RateLimit.Remaining < 100 {\n\t\t\t\t\tresetTime := time.Until(rateLimit.RateLimit.ResetAt.Time)\n\t\t\t\t\tfmt.Printf(\"WARNING: Rate limit is low (%d remaining). Limit resets in %s\\n\",\n\t\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\t\tresetTime.Round(time.Second))\n\n\t\t\t\t\tif rateLimit.RateLimit.Remaining < 10 {\n\t\t\t\t\t\tfmt.Println(\"Rate limit critically low, waiting until reset...\")\n\t\t\t\t\t\twaitTime := time.Until(rateLimit.RateLimit.ResetAt.Time) + 10*time.Second\n\t\t\t\t\t\ttime.Sleep(waitTime)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfmt.Printf(\"Could not fetch rate limit info: %v\\n\", rateLimitErr)\n\t\t\t}\n\n\t\t\t// Execute the actual query\n\t\t\tstartTime := time.Now()\n\t\t\terr = client.Query(ctx, &q, variables)\n\t\t\tqueryDuration := time.Since(startTime)\n\n\t\t\tif err == nil {\n\t\t\t\tsuccess = true\n\t\t\t\tfmt.Printf(\"Query succeeded in %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t\t// Log the number of results received\n\t\t\t\tresultCount := len(q.Search.Nodes)\n\t\t\t\tfmt.Printf(\"Received %d results for page %d\\n\", resultCount, pageCount+1)\n\n\t\t\t\t// Process the results\n\t\t\t\tfor _, node := range q.Search.Nodes {\n\t\t\t\t\tpr := node.PullRequest\n\n\t\t\t\t\t// Extract labels\n\t\t\t\t\tvar labels []string\n\t\t\t\t\tfor _, label := range pr.Labels.Nodes {\n\t\t\t\t\t\tlabels = append(labels, string(label.Name))\n\t\t\t\t\t}\n\n\t\t\t\t\t// Create PR object\n\t\t\t\t\tnewPR := JUnit5PR{\n\t\t\t\t\t\tTitle:      string(pr.Title),\n\t\t\t\t\t\tURL:        string(pr.URL),\n\t\t\t\t\t\tRepository: string(pr.Repository.NameWithOwner),\n\t\t\t\t\t\tState:      string(pr.State),\n\t\t\t\t\t\tAuthor:     string(pr.Author.Login),\n\t\t\t\t\t\tLabels:     labels,\n\t\t\t\t\t\tBody:       string(pr.BodyText),\n\t\t\t\t\t\tCreatedAt:  pr.CreatedAt.Format(time.RFC3339),\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs created on or after the start date\n\t\t\t\t\tif pr.CreatedAt.Before(startDate) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs that are likely related to JUnit 5 migration\n\t\t\t\t\tif isJUnit5MigrationPR(newPR) {\n\t\t\t\t\t\tallPRs = append(allPRs, newPR)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Log progress\n\t\t\t\tfmt.Printf(\"Processed page %d, found %d matching PRs so far\\n\", pageCount+1, len(allPRs))\n\n\t\t\t\t// Check if there are more pages\n\t\t\t\tif !q.Search.PageInfo.HasNextPage {\n\t\t\t\t\tfmt.Printf(\"No more pages available, completed after %d pages\\n\", pageCount+1)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\n\t\t\t\t// Move to next page\n\t\t\t\tfmt.Printf(\"Moving to next page with cursor: %s\\n\", q.Search.PageInfo.EndCursor)\n\t\t\t\tvariables[\"after\"] = githubv4.NewString(q.Search.PageInfo.EndCursor)\n\n\t\t\t\t// Reset the attempt counter since we successfully processed this page\n\t\t\t\tattempt = 0\n\n\t\t\t\t// Add a small delay before the next page to avoid overwhelming GitHub\n\t\t\t\ttime.Sleep(1 * time.Second)\n\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Log detailed error information\n\t\t\tfmt.Printf(\"GitHub API error on attempt %d/%d (total %d): %v\\n\",\n\t\t\t\tattempt+1, maxRetries, totalAttempts, err)\n\t\t\tfmt.Printf(\"Query duration before error: %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t// Try to parse and log more details from the error\n\t\t\tvar errorDetails struct {\n\t\t\t\tData   interface{}            `json:\"data\"`\n\t\t\t\tErrors []map[string]interface{} `json:\"errors\"`\n\t\t\t}\n\n\t\t\tif strings.Contains(err.Error(), \"{\") {\n\t\t\t\terrorJSON := err.Error()[strings.Index(err.Error(), \"{\"): // Removed the -1\n\t\t\t\tif jsonErr := json.Unmarshal([]byte(errorJSON), &errorDetails); jsonErr == nil {\n\t\t\t\t\tif errorDetails.Errors != nil && len(errorDetails.Errors) > 0 {\n\t\t\t\t\t\tfmt.Println(\"Detailed error information:\")\n\t\t\t\t\t\tfor i, errDetail := range errorDetails.Errors {\n\t\t\t\t\t\t\tfmt.Printf(\"  Error %d:\\n\", i+1)\n\t\t\t\t\t\t\tfor k, v := range errDetail {\n\t\t\t\t\t\t\t\tfmt.Printf(\"    %s: %v\\n\", k, v)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Check if this is a retryable error (like 502)\n\t\t\tif strings.Contains(err.Error(), \"502\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"timeout\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"Something went wrong\") {\n\n\t\t\t\t// Calculate backoff duration with exponential increase and jitter\n\t\t\t\tbackoffTime := float64(initialBackoff) * math.Pow(2, float64(attempt))\n\t\t\t\tif backoffTime > float64(maxBackoff) {\n\t\t\t\t\tbackoffTime = float64(maxBackoff)\n\t\t\t\t}\n\n\t\t\t\t// Add jitter (±20%)\n\t\t\t\tjitter := (rand.Float64() * 0.4) - 0.2 // -20% to +20%\n\t\t\t\tbackoffTime = backoffTime * (1 + jitter)\n\n\t\t\t\tsleepDuration := time.Duration(backoffTime)\n\t\t\t\tfmt.Printf(\"Retrying in %v...\\n\", sleepDuration)\n\t\t\t\ttime.Sleep(sleepDuration)\n\t\t\t} else {\n\t\t\t\t// Non-retryable error, break out\n\t\t\t\tfmt.Println(\"Non-retryable error encountered, stopping retry attempts\")\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !success {\n\t\t\tfmt.Printf(\"Failed after %d attempts: %v\\n\", maxRetries, err)\n\t\t\tfmt.Println(\"Continuing with results collected so far...\")\n\t\t\treturn allPRs\n\t\t}\n\t}\n\n\tfmt.Printf(\"Search completed. Found %d matching PRs for query: %s\\n\", len(allPRs), query)\n\treturn allPRs\n}\n\n// isJUnit5MigrationPR checks if a PR is likely related to JUnit 5 migration\nfunc isJUnit5MigrationPR(pr JUnit5PR) bool {\n\t// Exclude dependency bumps\n\tif strings.HasPrefix(pr.Title, \"Bump\") || strings.HasPrefix(pr.Title, \"bump\") {\n\t\treturn false\n\t}\n\n\t// Exclude PRs with specific JIRA ticket prefixes that are known not to be JUnit 5 related\n\t// These are examples of tickets that were incorrectly included\n\texcludePatterns := []string{\n\t\t`(?i)JENKINS-70560`,         // Improve test coverage\n\t\t`(?i)JENKINS-75447`,         // Fix Snippetizer rendering\n\t\t`(?i)JENKINS-\\d+.*fix`,      // General fixes\n\t\t`(?i)fix`,                   // General fixes\n\t\t`(?i)improve test coverage`, // Test coverage improvements not related to JUnit 5\n\t}\n\n\tfor _, pattern := range excludePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Define more specific patterns for JUnit 5 migration PRs\n\ttitlePatterns := []string{\n\t\t`(?i)migrate tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t}\n\n\tbodyPatterns := []string{\n\t\t`(?i)migrate (all )?tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t\t`(?i)org\\.junit\\.jupiter`,\n\t\t`(?i)junit-jupiter`,\n\t}\n\n\tlabelPatterns := []string{\n\t\t`(?i)\\bjunit ?5\\b`,\n\t\t`(?i)junit-5`,\n\t\t`(?i)junit-migration`,\n\t}\n\n\tauthorPatterns := []string{\n\t\t`strangelookingnerd`,\n\t}\n\n\t// Check title with more specific matching\n\tfor _, pattern := range titlePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn true\n\t\t}\n\t}\n\n\t// For body matches, require stronger evidence\n\t// Count how many patterns match in the body\n\tbodyMatchCount := 0\n\tfor _, pattern := range bodyPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Body)\n\t\tif matched {\n\t\t\tbodyMatchCount++\n\t\t}\n\t}\n\n\t// Require at least 2 body pattern matches for a positive identification\n\t// This helps avoid false positives from PRs that mention JUnit in passing\n\tif bodyMatchCount >= 2 {\n\t\treturn true\n\t}\n\n\t// Check labels\n\tfor _, label := range pr.Labels {\n\t\tfor _, pattern := range labelPatterns {\n\t\t\tmatched, _ := regexp.MatchString(pattern, label)\n\t\t\tif matched {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check author - but only if there's at least some mention of JUnit in the body\n\t// This avoids including all PRs from certain authors\n\tfor _, pattern := range authorPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Author)\n\t\tif matched {\n\t\t\t// Check if there's at least some mention of JUnit in the body\n\t\t\tjunitmatch, _ := regexp.MatchString(`(?i)junit`, pr.Body)\n\t\t\tif junitmatch {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\treturn false\n}\n\n// removeDuplicates removes duplicate PRs from the slice\nfunc removeDuplicates(prs []JUnit5PR) []JUnit5PR {\n\tseen := make(map[string]bool)\n\tvar result []JUnit5PR\n\n\tfor _, pr := range prs {\n\t\tif !seen[pr.URL] {\n\t\t\tseen[pr.URL] = true\n\t\t\tresult = append(result, pr)\n\t\t}\n\t}\n\n\treturn result\n}\n\n// generateCandidateURLsFile creates a text file with PR URLs for easy addition to junit5_pr_urls.txt\nfunc generateCandidateURLsFile(prs []JUnit5PR, outputFile string) {\n\tfile, err := os.Create(outputFile)\n\tif err != nil {\n\t\tfmt.Printf(\"Error creating file: %v\\n\", err)\n\t\treturn\n\t}\n\tdefer file.Close()\n\n\tfile.WriteString(fmt.Sprintf(\"# JUnit 5 migration PR candidates found on %s\\n\", time.Now().Format(\"2006-01-02 15:04:05\")))\n\tfile.WriteString(\"# Add relevant URLs to junit5_pr_urls.txt after verification\\n\\n\")\n\n\tfor _, pr := range prs {\n\t\tfile.WriteString(fmt.Sprintf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State))\n\t\tfile.WriteString(fmt.Sprintf(\"%s\\n\\n\", pr.URL))\n\t}\n}\n\n// compareWithExistingPRs compares found PRs with those already in junit5_pr_urls.txt\nfunc compareWithExistingPRs(prs []JUnit5PR, existingFile string) {\n\t// Read existing PR URLs\n\texistingURLs := make(map[string]bool)\n\n\tdata, err := ioutil.ReadFile(existingFile)\n\tif err == nil {\n\t\tlines := strings.Split(string(data), \"\\n\")\n\t\tfor _, line := range lines {\n\t\t\tline = strings.TrimSpace(line)\n\t\t\tif strings.HasPrefix(line, \"https://\") {\n\t\t\t\texistingURLs[line] = true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Find new PRs\n\tvar newPRs []JUnit5PR\n\tfor _, pr := range prs {\n\t\tif !existingURLs[pr.URL] {\n\t\t\tnewPRs = append(newPRs, pr)\n\t\t}\n\t}\n\n\tfmt.Printf(\"Found %d new PR candidates not already in %s\\n\", len(newPRs), existingFile)\n\n\tif len(newPRs) > 0 {\n\t\tfmt.Println(\"New PR candidates:\")\n\t\tfor _, pr := range newPRs {\n\t\t\tfmt.Printf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State)\n\t\t\tfmt.Printf(\"%s\\n\\n\", pr.URL)\n\t\t}\n\t}\n}\n"
                    }
                ]
            },
            "createdAt": 1744720379291,
            "isInternal": false,
            "rawContent": {
                "type": "doc",
                "content": [
                    {
                        "type": "paragraph",
                        "content": [
                            {
                                "type": "text",
                                "text": "[ERROR] Medium: Suppressing annotation on the method new jenkins.plugin.android.emulator.tools.AndroidSDKInstaller$AndroidSDKInstallable(AndroidSDKInstaller, DownloadFromUrlInstaller$Installable) is unnecessary [jenkins.plugin.android.emulator.tools.AndroidSDKInstaller$AndroidSDKInstallable] At AndroidSDKInstaller.java:[lines 70-72] US_USELESS_SUPPRESSION_ON_METHOD"
                            }
                        ]
                    }
                ]
            }
        },
        {
            "id": "a252b047-f46a-42fc-8e80-960dfb8638e3",
            "role": "assistant",
            "content": [
                {
                    "type": "text",
                    "text": "The errors you are encountering in your Go code are due to syntax issues. Let's address them based on the content of your `main.go` file:\n\n1. **Syntax Error: Unexpected `if`, Expected Expression**\n\n   This error typically occurs when an `if` statement is placed outside of a function or is incorrectly formatted. In Go, all executable code, including `if` statements, must be inside a function. Ensure that any `if` statements are correctly placed within a function body.\n\n2. **Syntax Error: Non-declaration Statement Outside Function Body**\n\n   This error indicates that there is a statement outside of any function. In Go, all executable code must be inside a function. Check to ensure that all your code is within a function.\n\n### Steps to Fix:\n\n- **Ensure All Code is Within Functions**: Review lines 313, 314, and 358 to ensure they are within a function. If they are not, wrap them in a function.\n\n- **Check for Misplaced Code**: Sometimes, a misplaced bracket or missing function declaration can cause these errors. Ensure that all your functions are properly declared and that there are no stray brackets.\n\nHere's a general structure to follow:\n\n```go\nfunc someFunction() {\n    // Example of a correct if statement\n    if condition {\n        // Do something\n    }\n}\n```\n\n### Example Fix:\n\nIf you have specific lines that are causing issues, ensure they are structured like this:\n\n```go\nfunc exampleFunction() {\n    if someCondition {\n        // Your code here\n    }\n}\n```\n\nIf you can provide the specific lines around 313, 314, and 358, I can give more precise guidance. Additionally, ensure that all your functions are properly closed with a `}` and that there are no stray `if` statements outside of functions."
                }
            ],
            "context": {
                "currentFile": {
                    "path": "cmd\\find-junit5-prs\\main.go",
                    "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                    "sources": [
                        "opened_tab"
                    ],
                    "content": "package main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"math\"\n\t\"math/rand\"\n\t\"net/http\"\n\t\"os\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/shurcooL/githubv4\"\n\t\"golang.org/x/oauth2\"\n)\n\n// JUnit5PR represents a GitHub pull request related to JUnit 5 migration\ntype JUnit5PR struct {\n\tTitle      string   `json:\"title\"`\n\tURL        string   `json:\"url\"`\n\tRepository string   `json:\"repository\"`\n\tState      string   `json:\"state\"`\n\tAuthor     string   `json:\"author\"`\n\tLabels     []string `json:\"labels\"`\n\tBody       string   `json:\"body\"`\n\tCreatedAt  string   `json:\"createdAt\"`\n}\n\n// SearchResult holds the PRs found in the search\ntype SearchResult struct {\n\tPRs []JUnit5PR `json:\"prs\"`\n}\n\n// GraphQL query structure for searching pull requests\ntype searchQuery struct {\n\tSearch struct {\n\t\tPageInfo struct {\n\t\t\tHasNextPage bool\n\t\t\tEndCursor   githubv4.String\n\t\t}\n\t\tNodes []struct {\n\t\t\tPullRequest struct {\n\t\t\t\tTitle     githubv4.String\n\t\t\t\tURL       githubv4.String\n\t\t\t\tState     githubv4.String\n\t\t\t\tCreatedAt githubv4.DateTime\n\t\t\t\tAuthor    struct {\n\t\t\t\t\tLogin githubv4.String\n\t\t\t\t}\n\t\t\t\tRepository struct {\n\t\t\t\t\tNameWithOwner githubv4.String\n\t\t\t\t}\n\t\t\t\tLabels struct {\n\t\t\t\t\tNodes []struct {\n\t\t\t\t\t\tName githubv4.String\n\t\t\t\t\t}\n\t\t\t\t} `graphql:\"labels(first: 10)\"`\n\t\t\t\tBodyText githubv4.String\n\t\t\t} `graphql:\"... on PullRequest\"`\n\t\t}\n\t} `graphql:\"search(query: $query, type: ISSUE, first: $first, after: $after)\"`\n}\n\nfunc main() {\n\t// Parse command line flags\n\toutputDir := flag.String(\"output-dir\", \"data/junit5\", \"Directory to store output files\")\n\tcandidateFile := flag.String(\"candidate-file\", \"junit5_candidate_prs.txt\", \"File to store candidate PR URLs\")\n\texistingFile := flag.String(\"existing-file\", \"junit5_pr_urls.txt\", \"File containing existing PR URLs\")\n\tstartDate := flag.String(\"start-date\", \"2024-07-01\", \"Start date for PR search (YYYY-MM-DD)\")\n\tflag.Parse()\n\n\t// Get GitHub token from environment\n\ttoken := os.Getenv(\"GITHUB_TOKEN\")\n\tif token == \"\" {\n\t\tfmt.Println(\"GITHUB_TOKEN environment variable is required\")\n\t\tos.Exit(1)\n\t}\n\n\t// Parse start date\n\tstartDateTime, err := time.Parse(\"2006-01-02\", *startDate)\n\tif err != nil {\n\t\tfmt.Printf(\"Error parsing start date: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tfmt.Printf(\"Searching for PRs created on or after: %s\\n\", startDateTime.Format(\"2006-01-02\"))\n\n\t// Create output directory if it doesn't exist\n\tos.MkdirAll(*outputDir, 0755)\n\n\t// Create GitHub client\n\tsrc := oauth2.StaticTokenSource(\n\t\t&oauth2.Token{AccessToken: token},\n\t)\n\thttpClient := oauth2.NewClient(context.Background(), src)\n\tclient := githubv4.NewClient(httpClient)\n\n\t// Define search terms\n\tsearchTerms := []string{\n\t\t\"junit5\",\n\t\t\"junit 5\",\n\t\t\"migrate tests to junit\",\n\t\t\"junit jupiter\",\n\t\t\"openrewrite junit\",\n\t}\n\n\t// Initialize result\n\tresult := SearchResult{\n\t\tPRs: []JUnit5PR{},\n\t}\n\n\t// Search for each term\n\tfor _, term := range searchTerms {\n\t\tfmt.Printf(\"Searching for: %s\\n\", term)\n\n\t\t// Search in title\n\t\ttitleQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:title %s\", term)\n\t\tprs := searchPRs(client, titleQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\n\t\t// Search in body\n\t\tbodyQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:body %s\", term)\n\t\tprs = searchPRs(client, bodyQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\t}\n\n\t// Search for PRs by specific authors known for JUnit 5 migrations\n\tfmt.Println(\"Searching for PRs by known JUnit 5 migration authors...\")\n\tauthorQuery := \"org:jenkinsci is:pr author:strangelookingnerd\"\n\tprs := searchPRs(client, authorQuery, startDateTime)\n\tresult.PRs = append(result.PRs, prs...)\n\n\t// Remove duplicates\n\tresult.PRs = removeDuplicates(result.PRs)\n\n\t// Save results to JSON file\n\tjsonData, err := json.MarshalIndent(result, \"\", \"  \")\n\tif err != nil {\n\t\tfmt.Printf(\"Error marshaling JSON: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\toutputFile := fmt.Sprintf(\"%s/junit5_candidates.json\", *outputDir)\n\terr = ioutil.WriteFile(outputFile, jsonData, 0644)\n\tif err != nil {\n\t\tfmt.Printf(\"Error writing JSON file: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Generate text file with URLs for easy addition to junit5_pr_urls.txt\n\tgenerateCandidateURLsFile(result.PRs, *candidateFile)\n\n\t// Compare with existing PRs in junit5_pr_urls.txt\n\tcompareWithExistingPRs(result.PRs, *existingFile)\n\n\tfmt.Printf(\"Found %d potential JUnit 5 migration PR candidates\\n\", len(result.PRs))\n\tfmt.Printf(\"Results saved to %s and %s\\n\", outputFile, *candidateFile)\n}\n\n// searchPRs performs a GitHub search and returns PRs matching the query\nfunc searchPRs(client *githubv4.Client, query string, startDate time.Time) []JUnit5PR {\n\tvar q searchQuery\n\tvariables := map[string]interface{}{\n\t\t\"query\": githubv4.String(query),\n\t\t\"first\": githubv4.Int(10), // Reduced from 25 to 10 to make queries even less complex\n\t\t\"after\": (*githubv4.String)(nil),\n\t}\n\n\tvar allPRs []JUnit5PR\n\tmaxRetries := 10 // Increased from 5 to 10\n\tinitialBackoff := 2 * time.Second\n\tmaxBackoff := 60 * time.Second\n\n\t// Log the query being executed\n\tfmt.Printf(\"Executing GitHub GraphQL query: %s\\n\", query)\n\tfmt.Printf(\"Start date: %s\\n\", startDate.Format(time.RFC3339))\n\n\tpageCount := 0\n\ttotalAttempts := 0\n\tfor {\n\t\t// Add a small delay between requests to respect rate limits\n\t\ttime.Sleep(1 * time.Second)\n\n\t\t// Create a context with timeout\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n\t\tdefer cancel()\n\n\t\tvar err error\n\t\tsuccess := false\n\n\t\t// Implement retry with exponential backoff\n\t\tfor attempt := 0; attempt < maxRetries && !success; attempt++ {\n\t\t\ttotalAttempts++\n\n\t\t\t// Get current rate limit information before making the request\n\t\t\tvar rateLimit struct {\n\t\t\t\tRateLimit struct {\n\t\t\t\t\tLimit     githubv4.Int\n\t\t\t\t\tRemaining githubv4.Int\n\t\t\t\t\tResetAt   githubv4.DateTime\n\t\t\t\t} `graphql:\"rateLimit\"`\n\t\t\t}\n\n\t\t\trateLimitErr := client.Query(context.Background(), &rateLimit, nil)\n\t\t\tif rateLimitErr == nil {\n\t\t\t\tfmt.Printf(\"GitHub API rate limit: %d/%d remaining, resets at %s\\n\",\n\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\trateLimit.RateLimit.Limit,\n\t\t\t\t\trateLimit.RateLimit.ResetAt.Format(time.RFC3339))\n\n\t\t\t\t// Check if we're close to hitting the rate limit\n\t\t\t\tif rateLimit.RateLimit.Remaining < 100 {\n\t\t\t\t\tresetTime := time.Until(rateLimit.RateLimit.ResetAt.Time)\n\t\t\t\t\tfmt.Printf(\"WARNING: Rate limit is low (%d remaining). Limit resets in %s\\n\",\n\t\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\t\tresetTime.Round(time.Second))\n\n\t\t\t\t\tif rateLimit.RateLimit.Remaining < 10 {\n\t\t\t\t\t\tfmt.Println(\"Rate limit critically low, waiting until reset...\")\n\t\t\t\t\t\twaitTime := time.Until(rateLimit.RateLimit.ResetAt.Time) + 10*time.Second\n\t\t\t\t\t\ttime.Sleep(waitTime)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfmt.Printf(\"Could not fetch rate limit info: %v\\n\", rateLimitErr)\n\t\t\t}\n\n\t\t\t// Execute the actual query\n\t\t\tstartTime := time.Now()\n\t\t\terr = client.Query(ctx, &q, variables)\n\t\t\tqueryDuration := time.Since(startTime)\n\n\t\t\tif err == nil {\n\t\t\t\tsuccess = true\n\t\t\t\tfmt.Printf(\"Query succeeded in %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t\t// Log the number of results received\n\t\t\t\tresultCount := len(q.Search.Nodes)\n\t\t\t\tfmt.Printf(\"Received %d results for page %d\\n\", resultCount, pageCount+1)\n\n\t\t\t\t// Process the results\n\t\t\t\tfor _, node := range q.Search.Nodes {\n\t\t\t\t\tpr := node.PullRequest\n\n\t\t\t\t\t// Extract labels\n\t\t\t\t\tvar labels []string\n\t\t\t\t\tfor _, label := range pr.Labels.Nodes {\n\t\t\t\t\t\tlabels = append(labels, string(label.Name))\n\t\t\t\t\t}\n\n\t\t\t\t\t// Create PR object\n\t\t\t\t\tnewPR := JUnit5PR{\n\t\t\t\t\t\tTitle:      string(pr.Title),\n\t\t\t\t\t\tURL:        string(pr.URL),\n\t\t\t\t\t\tRepository: string(pr.Repository.NameWithOwner),\n\t\t\t\t\t\tState:      string(pr.State),\n\t\t\t\t\t\tAuthor:     string(pr.Author.Login),\n\t\t\t\t\t\tLabels:     labels,\n\t\t\t\t\t\tBody:       string(pr.BodyText),\n\t\t\t\t\t\tCreatedAt:  pr.CreatedAt.Format(time.RFC3339),\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs created on or after the start date\n\t\t\t\t\tif pr.CreatedAt.Before(startDate) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs that are likely related to JUnit 5 migration\n\t\t\t\t\tif isJUnit5MigrationPR(newPR) {\n\t\t\t\t\t\tallPRs = append(allPRs, newPR)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Log progress\n\t\t\t\tfmt.Printf(\"Processed page %d, found %d matching PRs so far\\n\", pageCount+1, len(allPRs))\n\n\t\t\t\t// Check if there are more pages\n\t\t\t\tif !q.Search.PageInfo.HasNextPage {\n\t\t\t\t\tfmt.Printf(\"No more pages available, completed after %d pages\\n\", pageCount+1)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\n\t\t\t\t// Move to next page\n\t\t\t\tfmt.Printf(\"Moving to next page with cursor: %s\\n\", q.Search.PageInfo.EndCursor)\n\t\t\t\tvariables[\"after\"] = githubv4.NewString(q.Search.PageInfo.EndCursor)\n\n\t\t\t\t// Reset the attempt counter since we successfully processed this page\n\t\t\t\tattempt = 0\n\n\t\t\t\t// Add a small delay before the next page to avoid overwhelming GitHub\n\t\t\t\ttime.Sleep(1 * time.Second)\n\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Log detailed error information\n\t\t\tfmt.Printf(\"GitHub API error on attempt %d/%d (total %d): %v\\n\",\n\t\t\t\tattempt+1, maxRetries, totalAttempts, err)\n\t\t\tfmt.Printf(\"Query duration before error: %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t// Try to parse and log more details from the error\n\t\t\tvar errorDetails struct {\n\t\t\t\tData   interface{}            `json:\"data\"`\n\t\t\t\tErrors []map[string]interface{} `json:\"errors\"`\n\t\t\t}\n\n\t\t\tif strings.Contains(err.Error(), \"{\") {\n\t\t\t\terrorJSON := err.Error()[strings.Index(err.Error(), \"{\"): // Removed the -1\n\t\t\t\tif jsonErr := json.Unmarshal([]byte(errorJSON), &errorDetails); jsonErr == nil {\n\t\t\t\t\tif errorDetails.Errors != nil && len(errorDetails.Errors) > 0 {\n\t\t\t\t\t\tfmt.Println(\"Detailed error information:\")\n\t\t\t\t\t\tfor i, errDetail := range errorDetails.Errors {\n\t\t\t\t\t\t\tfmt.Printf(\"  Error %d:\\n\", i+1)\n\t\t\t\t\t\t\tfor k, v := range errDetail {\n\t\t\t\t\t\t\t\tfmt.Printf(\"    %s: %v\\n\", k, v)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Check if this is a retryable error (like 502)\n\t\t\tif strings.Contains(err.Error(), \"502\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"timeout\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"Something went wrong\") {\n\n\t\t\t\t// Calculate backoff duration with exponential increase and jitter\n\t\t\t\tbackoffTime := float64(initialBackoff) * math.Pow(2, float64(attempt))\n\t\t\t\tif backoffTime > float64(maxBackoff) {\n\t\t\t\t\tbackoffTime = float64(maxBackoff)\n\t\t\t\t}\n\n\t\t\t\t// Add jitter (±20%)\n\t\t\t\tjitter := (rand.Float64() * 0.4) - 0.2 // -20% to +20%\n\t\t\t\tbackoffTime = backoffTime * (1 + jitter)\n\n\t\t\t\tsleepDuration := time.Duration(backoffTime)\n\t\t\t\tfmt.Printf(\"Retrying in %v...\\n\", sleepDuration)\n\t\t\t\ttime.Sleep(sleepDuration)\n\t\t\t} else {\n\t\t\t\t// Non-retryable error, break out\n\t\t\t\tfmt.Println(\"Non-retryable error encountered, stopping retry attempts\")\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !success {\n\t\t\tfmt.Printf(\"Failed after %d attempts: %v\\n\", maxRetries, err)\n\t\t\tfmt.Println(\"Continuing with results collected so far...\")\n\t\t\treturn allPRs\n\t\t}\n\t}\n\n\tfmt.Printf(\"Search completed. Found %d matching PRs for query: %s\\n\", len(allPRs), query)\n\treturn allPRs\n}\n\n// isJUnit5MigrationPR checks if a PR is likely related to JUnit 5 migration\nfunc isJUnit5MigrationPR(pr JUnit5PR) bool {\n\t// Exclude dependency bumps\n\tif strings.HasPrefix(pr.Title, \"Bump\") || strings.HasPrefix(pr.Title, \"bump\") {\n\t\treturn false\n\t}\n\n\t// Exclude PRs with specific JIRA ticket prefixes that are known not to be JUnit 5 related\n\t// These are examples of tickets that were incorrectly included\n\texcludePatterns := []string{\n\t\t`(?i)JENKINS-70560`,         // Improve test coverage\n\t\t`(?i)JENKINS-75447`,         // Fix Snippetizer rendering\n\t\t`(?i)JENKINS-\\d+.*fix`,      // General fixes\n\t\t`(?i)fix`,                   // General fixes\n\t\t`(?i)improve test coverage`, // Test coverage improvements not related to JUnit 5\n\t}\n\n\tfor _, pattern := range excludePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Define more specific patterns for JUnit 5 migration PRs\n\ttitlePatterns := []string{\n\t\t`(?i)migrate tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t}\n\n\tbodyPatterns := []string{\n\t\t`(?i)migrate (all )?tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t\t`(?i)org\\.junit\\.jupiter`,\n\t\t`(?i)junit-jupiter`,\n\t}\n\n\tlabelPatterns := []string{\n\t\t`(?i)\\bjunit ?5\\b`,\n\t\t`(?i)junit-5`,\n\t\t`(?i)junit-migration`,\n\t}\n\n\tauthorPatterns := []string{\n\t\t`strangelookingnerd`,\n\t}\n\n\t// Check title with more specific matching\n\tfor _, pattern := range titlePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn true\n\t\t}\n\t}\n\n\t// For body matches, require stronger evidence\n\t// Count how many patterns match in the body\n\tbodyMatchCount := 0\n\tfor _, pattern := range bodyPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Body)\n\t\tif matched {\n\t\t\tbodyMatchCount++\n\t\t}\n\t}\n\n\t// Require at least 2 body pattern matches for a positive identification\n\t// This helps avoid false positives from PRs that mention JUnit in passing\n\tif bodyMatchCount >= 2 {\n\t\treturn true\n\t}\n\n\t// Check labels\n\tfor _, label := range pr.Labels {\n\t\tfor _, pattern := range labelPatterns {\n\t\t\tmatched, _ := regexp.MatchString(pattern, label)\n\t\t\tif matched {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check author - but only if there's at least some mention of JUnit in the body\n\t// This avoids including all PRs from certain authors\n\tfor _, pattern := range authorPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Author)\n\t\tif matched {\n\t\t\t// Check if there's at least some mention of JUnit in the body\n\t\t\tjunitmatch, _ := regexp.MatchString(`(?i)junit`, pr.Body)\n\t\t\tif junitmatch {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\treturn false\n}\n\n// removeDuplicates removes duplicate PRs from the slice\nfunc removeDuplicates(prs []JUnit5PR) []JUnit5PR {\n\tseen := make(map[string]bool)\n\tvar result []JUnit5PR\n\n\tfor _, pr := range prs {\n\t\tif !seen[pr.URL] {\n\t\t\tseen[pr.URL] = true\n\t\t\tresult = append(result, pr)\n\t\t}\n\t}\n\n\treturn result\n}\n\n// generateCandidateURLsFile creates a text file with PR URLs for easy addition to junit5_pr_urls.txt\nfunc generateCandidateURLsFile(prs []JUnit5PR, outputFile string) {\n\tfile, err := os.Create(outputFile)\n\tif err != nil {\n\t\tfmt.Printf(\"Error creating file: %v\\n\", err)\n\t\treturn\n\t}\n\tdefer file.Close()\n\n\tfile.WriteString(fmt.Sprintf(\"# JUnit 5 migration PR candidates found on %s\\n\", time.Now().Format(\"2006-01-02 15:04:05\")))\n\tfile.WriteString(\"# Add relevant URLs to junit5_pr_urls.txt after verification\\n\\n\")\n\n\tfor _, pr := range prs {\n\t\tfile.WriteString(fmt.Sprintf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State))\n\t\tfile.WriteString(fmt.Sprintf(\"%s\\n\\n\", pr.URL))\n\t}\n}\n\n// compareWithExistingPRs compares found PRs with those already in junit5_pr_urls.txt\nfunc compareWithExistingPRs(prs []JUnit5PR, existingFile string) {\n\t// Read existing PR URLs\n\texistingURLs := make(map[string]bool)\n\n\tdata, err := ioutil.ReadFile(existingFile)\n\tif err == nil {\n\t\tlines := strings.Split(string(data), \"\\n\")\n\t\tfor _, line := range lines {\n\t\t\tline = strings.TrimSpace(line)\n\t\t\tif strings.HasPrefix(line, \"https://\") {\n\t\t\t\texistingURLs[line] = true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Find new PRs\n\tvar newPRs []JUnit5PR\n\tfor _, pr := range prs {\n\t\tif !existingURLs[pr.URL] {\n\t\t\tnewPRs = append(newPRs, pr)\n\t\t}\n\t}\n\n\tfmt.Printf(\"Found %d new PR candidates not already in %s\\n\", len(newPRs), existingFile)\n\n\tif len(newPRs) > 0 {\n\t\tfmt.Println(\"New PR candidates:\")\n\t\tfor _, pr := range newPRs {\n\t\t\tfmt.Printf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State)\n\t\t\tfmt.Printf(\"%s\\n\\n\", pr.URL)\n\t\t}\n\t}\n}\n"
                },
                "codebaseEnabled": true,
                "ragFiles": [
                    {
                        "path": "Dockerfile",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\Dockerfile",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/tqdm/utils.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\tqdm\\utils.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "upload_to_sheets.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\upload_to_sheets.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "jenkins-pr-collector.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\jenkins-pr-collector.go",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/pygments/lexers/__init__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\pygments\\lexers\\__init__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/pygments/styles/__init__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\pygments\\styles\\__init__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/pygments/filters/__init__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\pygments\\filters\\__init__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/pygments/formatters/__init__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\pygments\\formatters\\__init__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/logging.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\logging.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/exceptions.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\exceptions.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/metadata/__init__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\metadata\\__init__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/factory.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/resolver.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pyparsing/util.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pyparsing\\util.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pyparsing/helpers.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pyparsing\\helpers.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pyparsing/diagram/__init__.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pyparsing\\diagram\\__init__.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_internal/operations/check.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_internal\\operations\\check.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pyparsing/core.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pyparsing\\core.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/ansi.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\ansi.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "venv/lib/python3.13/site-packages/pip/_vendor/rich/console.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\venv\\lib\\python3.13\\site-packages\\pip\\_vendor\\rich\\console.py",
                        "sources": [
                            "keyword_search"
                        ]
                    },
                    {
                        "path": "analyze-junit5-prs.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\analyze-junit5-prs.sh",
                        "sources": []
                    },
                    {
                        "path": "test-pr-builds.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\test-pr-builds.sh",
                        "sources": []
                    },
                    {
                        "path": "junit5-migration-prs.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\junit5-migration-prs.sh",
                        "sources": []
                    },
                    {
                        "path": "cmd\\find-junit5-prs\\main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": []
                    },
                    {
                        "path": "find-junit5-prs.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\find-junit5-prs.sh",
                        "sources": []
                    },
                    {
                        "path": "cmd\\find-junit5-prs\\go.mod",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\go.mod",
                        "sources": []
                    },
                    {
                        "path": "data\\consolidated\\failing_prs.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\failing_prs.json",
                        "sources": []
                    },
                    {
                        "path": "data\\monthly\\filtered_prs_2025_03.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\monthly\\filtered_prs_2025_03.json",
                        "sources": []
                    },
                    {
                        "path": "data\\monthly\\prs_2025_03.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\monthly\\prs_2025_03.json",
                        "sources": []
                    },
                    {
                        "path": "filtered_prs_filtered_prs_2025_02.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\filtered_prs_filtered_prs_2025_02.json",
                        "sources": []
                    },
                    {
                        "path": "data\\monthly\\prs_2025_02.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\monthly\\prs_2025_02.json",
                        "sources": []
                    },
                    {
                        "path": "data\\monthly\\filtered_prs_2025_02.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\monthly\\filtered_prs_2025_02.json",
                        "sources": []
                    },
                    {
                        "path": "data/consolidated/failed_builds.csv",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\failed_builds.csv",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "data/consolidated/successful_builds.csv",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\successful_builds.csv",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "data/consolidated/test_results.csv",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\consolidated\\test_results.csv",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "update-daily.sh",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\update-daily.sh",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "upload_to_sheets.py",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\upload_to_sheets.py",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "data/junit5/junit5_migration_prs.json",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\data\\junit5\\junit5_migration_prs.json",
                        "sources": [
                            "opened_tab"
                        ]
                    },
                    {
                        "path": "cmd/find-junit5-prs/main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": [
                            "opened_tab"
                        ]
                    }
                ],
                "rerankedFiles": [],
                "usedFilePaths": [
                    {
                        "path": "cmd\\find-junit5-prs\\main.go",
                        "fsPath": "C:\\support\\users\\dev\\jenkins\\alpha-omega\\alpha-omega-stats\\cmd\\find-junit5-prs\\main.go",
                        "sources": [
                            "opened_tab"
                        ],
                        "content": "package main\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"math\"\n\t\"math/rand\"\n\t\"net/http\"\n\t\"os\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/shurcooL/githubv4\"\n\t\"golang.org/x/oauth2\"\n)\n\n// JUnit5PR represents a GitHub pull request related to JUnit 5 migration\ntype JUnit5PR struct {\n\tTitle      string   `json:\"title\"`\n\tURL        string   `json:\"url\"`\n\tRepository string   `json:\"repository\"`\n\tState      string   `json:\"state\"`\n\tAuthor     string   `json:\"author\"`\n\tLabels     []string `json:\"labels\"`\n\tBody       string   `json:\"body\"`\n\tCreatedAt  string   `json:\"createdAt\"`\n}\n\n// SearchResult holds the PRs found in the search\ntype SearchResult struct {\n\tPRs []JUnit5PR `json:\"prs\"`\n}\n\n// GraphQL query structure for searching pull requests\ntype searchQuery struct {\n\tSearch struct {\n\t\tPageInfo struct {\n\t\t\tHasNextPage bool\n\t\t\tEndCursor   githubv4.String\n\t\t}\n\t\tNodes []struct {\n\t\t\tPullRequest struct {\n\t\t\t\tTitle     githubv4.String\n\t\t\t\tURL       githubv4.String\n\t\t\t\tState     githubv4.String\n\t\t\t\tCreatedAt githubv4.DateTime\n\t\t\t\tAuthor    struct {\n\t\t\t\t\tLogin githubv4.String\n\t\t\t\t}\n\t\t\t\tRepository struct {\n\t\t\t\t\tNameWithOwner githubv4.String\n\t\t\t\t}\n\t\t\t\tLabels struct {\n\t\t\t\t\tNodes []struct {\n\t\t\t\t\t\tName githubv4.String\n\t\t\t\t\t}\n\t\t\t\t} `graphql:\"labels(first: 10)\"`\n\t\t\t\tBodyText githubv4.String\n\t\t\t} `graphql:\"... on PullRequest\"`\n\t\t}\n\t} `graphql:\"search(query: $query, type: ISSUE, first: $first, after: $after)\"`\n}\n\nfunc main() {\n\t// Parse command line flags\n\toutputDir := flag.String(\"output-dir\", \"data/junit5\", \"Directory to store output files\")\n\tcandidateFile := flag.String(\"candidate-file\", \"junit5_candidate_prs.txt\", \"File to store candidate PR URLs\")\n\texistingFile := flag.String(\"existing-file\", \"junit5_pr_urls.txt\", \"File containing existing PR URLs\")\n\tstartDate := flag.String(\"start-date\", \"2024-07-01\", \"Start date for PR search (YYYY-MM-DD)\")\n\tflag.Parse()\n\n\t// Get GitHub token from environment\n\ttoken := os.Getenv(\"GITHUB_TOKEN\")\n\tif token == \"\" {\n\t\tfmt.Println(\"GITHUB_TOKEN environment variable is required\")\n\t\tos.Exit(1)\n\t}\n\n\t// Parse start date\n\tstartDateTime, err := time.Parse(\"2006-01-02\", *startDate)\n\tif err != nil {\n\t\tfmt.Printf(\"Error parsing start date: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tfmt.Printf(\"Searching for PRs created on or after: %s\\n\", startDateTime.Format(\"2006-01-02\"))\n\n\t// Create output directory if it doesn't exist\n\tos.MkdirAll(*outputDir, 0755)\n\n\t// Create GitHub client\n\tsrc := oauth2.StaticTokenSource(\n\t\t&oauth2.Token{AccessToken: token},\n\t)\n\thttpClient := oauth2.NewClient(context.Background(), src)\n\tclient := githubv4.NewClient(httpClient)\n\n\t// Define search terms\n\tsearchTerms := []string{\n\t\t\"junit5\",\n\t\t\"junit 5\",\n\t\t\"migrate tests to junit\",\n\t\t\"junit jupiter\",\n\t\t\"openrewrite junit\",\n\t}\n\n\t// Initialize result\n\tresult := SearchResult{\n\t\tPRs: []JUnit5PR{},\n\t}\n\n\t// Search for each term\n\tfor _, term := range searchTerms {\n\t\tfmt.Printf(\"Searching for: %s\\n\", term)\n\n\t\t// Search in title\n\t\ttitleQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:title %s\", term)\n\t\tprs := searchPRs(client, titleQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\n\t\t// Search in body\n\t\tbodyQuery := fmt.Sprintf(\"org:jenkinsci is:pr in:body %s\", term)\n\t\tprs = searchPRs(client, bodyQuery, startDateTime)\n\t\tresult.PRs = append(result.PRs, prs...)\n\t}\n\n\t// Search for PRs by specific authors known for JUnit 5 migrations\n\tfmt.Println(\"Searching for PRs by known JUnit 5 migration authors...\")\n\tauthorQuery := \"org:jenkinsci is:pr author:strangelookingnerd\"\n\tprs := searchPRs(client, authorQuery, startDateTime)\n\tresult.PRs = append(result.PRs, prs...)\n\n\t// Remove duplicates\n\tresult.PRs = removeDuplicates(result.PRs)\n\n\t// Save results to JSON file\n\tjsonData, err := json.MarshalIndent(result, \"\", \"  \")\n\tif err != nil {\n\t\tfmt.Printf(\"Error marshaling JSON: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\toutputFile := fmt.Sprintf(\"%s/junit5_candidates.json\", *outputDir)\n\terr = ioutil.WriteFile(outputFile, jsonData, 0644)\n\tif err != nil {\n\t\tfmt.Printf(\"Error writing JSON file: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\n\t// Generate text file with URLs for easy addition to junit5_pr_urls.txt\n\tgenerateCandidateURLsFile(result.PRs, *candidateFile)\n\n\t// Compare with existing PRs in junit5_pr_urls.txt\n\tcompareWithExistingPRs(result.PRs, *existingFile)\n\n\tfmt.Printf(\"Found %d potential JUnit 5 migration PR candidates\\n\", len(result.PRs))\n\tfmt.Printf(\"Results saved to %s and %s\\n\", outputFile, *candidateFile)\n}\n\n// searchPRs performs a GitHub search and returns PRs matching the query\nfunc searchPRs(client *githubv4.Client, query string, startDate time.Time) []JUnit5PR {\n\tvar q searchQuery\n\tvariables := map[string]interface{}{\n\t\t\"query\": githubv4.String(query),\n\t\t\"first\": githubv4.Int(10), // Reduced from 25 to 10 to make queries even less complex\n\t\t\"after\": (*githubv4.String)(nil),\n\t}\n\n\tvar allPRs []JUnit5PR\n\tmaxRetries := 10 // Increased from 5 to 10\n\tinitialBackoff := 2 * time.Second\n\tmaxBackoff := 60 * time.Second\n\n\t// Log the query being executed\n\tfmt.Printf(\"Executing GitHub GraphQL query: %s\\n\", query)\n\tfmt.Printf(\"Start date: %s\\n\", startDate.Format(time.RFC3339))\n\n\tpageCount := 0\n\ttotalAttempts := 0\n\tfor {\n\t\t// Add a small delay between requests to respect rate limits\n\t\ttime.Sleep(1 * time.Second)\n\n\t\t// Create a context with timeout\n\t\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\n\t\tdefer cancel()\n\n\t\tvar err error\n\t\tsuccess := false\n\n\t\t// Implement retry with exponential backoff\n\t\tfor attempt := 0; attempt < maxRetries && !success; attempt++ {\n\t\t\ttotalAttempts++\n\n\t\t\t// Get current rate limit information before making the request\n\t\t\tvar rateLimit struct {\n\t\t\t\tRateLimit struct {\n\t\t\t\t\tLimit     githubv4.Int\n\t\t\t\t\tRemaining githubv4.Int\n\t\t\t\t\tResetAt   githubv4.DateTime\n\t\t\t\t} `graphql:\"rateLimit\"`\n\t\t\t}\n\n\t\t\trateLimitErr := client.Query(context.Background(), &rateLimit, nil)\n\t\t\tif rateLimitErr == nil {\n\t\t\t\tfmt.Printf(\"GitHub API rate limit: %d/%d remaining, resets at %s\\n\",\n\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\trateLimit.RateLimit.Limit,\n\t\t\t\t\trateLimit.RateLimit.ResetAt.Format(time.RFC3339))\n\n\t\t\t\t// Check if we're close to hitting the rate limit\n\t\t\t\tif rateLimit.RateLimit.Remaining < 100 {\n\t\t\t\t\tresetTime := time.Until(rateLimit.RateLimit.ResetAt.Time)\n\t\t\t\t\tfmt.Printf(\"WARNING: Rate limit is low (%d remaining). Limit resets in %s\\n\",\n\t\t\t\t\t\trateLimit.RateLimit.Remaining,\n\t\t\t\t\t\tresetTime.Round(time.Second))\n\n\t\t\t\t\tif rateLimit.RateLimit.Remaining < 10 {\n\t\t\t\t\t\tfmt.Println(\"Rate limit critically low, waiting until reset...\")\n\t\t\t\t\t\twaitTime := time.Until(rateLimit.RateLimit.ResetAt.Time) + 10*time.Second\n\t\t\t\t\t\ttime.Sleep(waitTime)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tfmt.Printf(\"Could not fetch rate limit info: %v\\n\", rateLimitErr)\n\t\t\t}\n\n\t\t\t// Execute the actual query\n\t\t\tstartTime := time.Now()\n\t\t\terr = client.Query(ctx, &q, variables)\n\t\t\tqueryDuration := time.Since(startTime)\n\n\t\t\tif err == nil {\n\t\t\t\tsuccess = true\n\t\t\t\tfmt.Printf(\"Query succeeded in %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t\t// Log the number of results received\n\t\t\t\tresultCount := len(q.Search.Nodes)\n\t\t\t\tfmt.Printf(\"Received %d results for page %d\\n\", resultCount, pageCount+1)\n\n\t\t\t\t// Process the results\n\t\t\t\tfor _, node := range q.Search.Nodes {\n\t\t\t\t\tpr := node.PullRequest\n\n\t\t\t\t\t// Extract labels\n\t\t\t\t\tvar labels []string\n\t\t\t\t\tfor _, label := range pr.Labels.Nodes {\n\t\t\t\t\t\tlabels = append(labels, string(label.Name))\n\t\t\t\t\t}\n\n\t\t\t\t\t// Create PR object\n\t\t\t\t\tnewPR := JUnit5PR{\n\t\t\t\t\t\tTitle:      string(pr.Title),\n\t\t\t\t\t\tURL:        string(pr.URL),\n\t\t\t\t\t\tRepository: string(pr.Repository.NameWithOwner),\n\t\t\t\t\t\tState:      string(pr.State),\n\t\t\t\t\t\tAuthor:     string(pr.Author.Login),\n\t\t\t\t\t\tLabels:     labels,\n\t\t\t\t\t\tBody:       string(pr.BodyText),\n\t\t\t\t\t\tCreatedAt:  pr.CreatedAt.Format(time.RFC3339),\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs created on or after the start date\n\t\t\t\t\tif pr.CreatedAt.Before(startDate) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\t// Only include PRs that are likely related to JUnit 5 migration\n\t\t\t\t\tif isJUnit5MigrationPR(newPR) {\n\t\t\t\t\t\tallPRs = append(allPRs, newPR)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Log progress\n\t\t\t\tfmt.Printf(\"Processed page %d, found %d matching PRs so far\\n\", pageCount+1, len(allPRs))\n\n\t\t\t\t// Check if there are more pages\n\t\t\t\tif !q.Search.PageInfo.HasNextPage {\n\t\t\t\t\tfmt.Printf(\"No more pages available, completed after %d pages\\n\", pageCount+1)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\n\t\t\t\t// Move to next page\n\t\t\t\tfmt.Printf(\"Moving to next page with cursor: %s\\n\", q.Search.PageInfo.EndCursor)\n\t\t\t\tvariables[\"after\"] = githubv4.NewString(q.Search.PageInfo.EndCursor)\n\n\t\t\t\t// Reset the attempt counter since we successfully processed this page\n\t\t\t\tattempt = 0\n\n\t\t\t\t// Add a small delay before the next page to avoid overwhelming GitHub\n\t\t\t\ttime.Sleep(1 * time.Second)\n\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// Log detailed error information\n\t\t\tfmt.Printf(\"GitHub API error on attempt %d/%d (total %d): %v\\n\",\n\t\t\t\tattempt+1, maxRetries, totalAttempts, err)\n\t\t\tfmt.Printf(\"Query duration before error: %s\\n\", queryDuration.Round(time.Millisecond))\n\n\t\t\t// Try to parse and log more details from the error\n\t\t\tvar errorDetails struct {\n\t\t\t\tData   interface{}            `json:\"data\"`\n\t\t\t\tErrors []map[string]interface{} `json:\"errors\"`\n\t\t\t}\n\n\t\t\tif strings.Contains(err.Error(), \"{\") {\n\t\t\t\terrorJSON := err.Error()[strings.Index(err.Error(), \"{\"): // Removed the -1\n\t\t\t\tif jsonErr := json.Unmarshal([]byte(errorJSON), &errorDetails); jsonErr == nil {\n\t\t\t\t\tif errorDetails.Errors != nil && len(errorDetails.Errors) > 0 {\n\t\t\t\t\t\tfmt.Println(\"Detailed error information:\")\n\t\t\t\t\t\tfor i, errDetail := range errorDetails.Errors {\n\t\t\t\t\t\t\tfmt.Printf(\"  Error %d:\\n\", i+1)\n\t\t\t\t\t\t\tfor k, v := range errDetail {\n\t\t\t\t\t\t\t\tfmt.Printf(\"    %s: %v\\n\", k, v)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Check if this is a retryable error (like 502)\n\t\t\tif strings.Contains(err.Error(), \"502\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"timeout\") ||\n\t\t\t\tstrings.Contains(err.Error(), \"Something went wrong\") {\n\n\t\t\t\t// Calculate backoff duration with exponential increase and jitter\n\t\t\t\tbackoffTime := float64(initialBackoff) * math.Pow(2, float64(attempt))\n\t\t\t\tif backoffTime > float64(maxBackoff) {\n\t\t\t\t\tbackoffTime = float64(maxBackoff)\n\t\t\t\t}\n\n\t\t\t\t// Add jitter (±20%)\n\t\t\t\tjitter := (rand.Float64() * 0.4) - 0.2 // -20% to +20%\n\t\t\t\tbackoffTime = backoffTime * (1 + jitter)\n\n\t\t\t\tsleepDuration := time.Duration(backoffTime)\n\t\t\t\tfmt.Printf(\"Retrying in %v...\\n\", sleepDuration)\n\t\t\t\ttime.Sleep(sleepDuration)\n\t\t\t} else {\n\t\t\t\t// Non-retryable error, break out\n\t\t\t\tfmt.Println(\"Non-retryable error encountered, stopping retry attempts\")\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tif !success {\n\t\t\tfmt.Printf(\"Failed after %d attempts: %v\\n\", maxRetries, err)\n\t\t\tfmt.Println(\"Continuing with results collected so far...\")\n\t\t\treturn allPRs\n\t\t}\n\t}\n\n\tfmt.Printf(\"Search completed. Found %d matching PRs for query: %s\\n\", len(allPRs), query)\n\treturn allPRs\n}\n\n// isJUnit5MigrationPR checks if a PR is likely related to JUnit 5 migration\nfunc isJUnit5MigrationPR(pr JUnit5PR) bool {\n\t// Exclude dependency bumps\n\tif strings.HasPrefix(pr.Title, \"Bump\") || strings.HasPrefix(pr.Title, \"bump\") {\n\t\treturn false\n\t}\n\n\t// Exclude PRs with specific JIRA ticket prefixes that are known not to be JUnit 5 related\n\t// These are examples of tickets that were incorrectly included\n\texcludePatterns := []string{\n\t\t`(?i)JENKINS-70560`,         // Improve test coverage\n\t\t`(?i)JENKINS-75447`,         // Fix Snippetizer rendering\n\t\t`(?i)JENKINS-\\d+.*fix`,      // General fixes\n\t\t`(?i)fix`,                   // General fixes\n\t\t`(?i)improve test coverage`, // Test coverage improvements not related to JUnit 5\n\t}\n\n\tfor _, pattern := range excludePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn false\n\t\t}\n\t}\n\n\t// Define more specific patterns for JUnit 5 migration PRs\n\ttitlePatterns := []string{\n\t\t`(?i)migrate tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t}\n\n\tbodyPatterns := []string{\n\t\t`(?i)migrate (all )?tests? to junit ?5`,\n\t\t`(?i)\\bjunit ?5\\b`, // Word boundary to ensure \"junit5\" is a standalone term\n\t\t`(?i)migrate to junit ?5`,\n\t\t`(?i)junit.*(4|four).*(5|five)`,\n\t\t`(?i)junit ?5.*(migration|upgrade)`,\n\t\t`(?i)openrewrite.*junit ?5`,\n\t\t`(?i)org\\.junit\\.jupiter`,\n\t\t`(?i)junit-jupiter`,\n\t}\n\n\tlabelPatterns := []string{\n\t\t`(?i)\\bjunit ?5\\b`,\n\t\t`(?i)junit-5`,\n\t\t`(?i)junit-migration`,\n\t}\n\n\tauthorPatterns := []string{\n\t\t`strangelookingnerd`,\n\t}\n\n\t// Check title with more specific matching\n\tfor _, pattern := range titlePatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Title)\n\t\tif matched {\n\t\t\treturn true\n\t\t}\n\t}\n\n\t// For body matches, require stronger evidence\n\t// Count how many patterns match in the body\n\tbodyMatchCount := 0\n\tfor _, pattern := range bodyPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Body)\n\t\tif matched {\n\t\t\tbodyMatchCount++\n\t\t}\n\t}\n\n\t// Require at least 2 body pattern matches for a positive identification\n\t// This helps avoid false positives from PRs that mention JUnit in passing\n\tif bodyMatchCount >= 2 {\n\t\treturn true\n\t}\n\n\t// Check labels\n\tfor _, label := range pr.Labels {\n\t\tfor _, pattern := range labelPatterns {\n\t\t\tmatched, _ := regexp.MatchString(pattern, label)\n\t\t\tif matched {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check author - but only if there's at least some mention of JUnit in the body\n\t// This avoids including all PRs from certain authors\n\tfor _, pattern := range authorPatterns {\n\t\tmatched, _ := regexp.MatchString(pattern, pr.Author)\n\t\tif matched {\n\t\t\t// Check if there's at least some mention of JUnit in the body\n\t\t\tjunitmatch, _ := regexp.MatchString(`(?i)junit`, pr.Body)\n\t\t\tif junitmatch {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\treturn false\n}\n\n// removeDuplicates removes duplicate PRs from the slice\nfunc removeDuplicates(prs []JUnit5PR) []JUnit5PR {\n\tseen := make(map[string]bool)\n\tvar result []JUnit5PR\n\n\tfor _, pr := range prs {\n\t\tif !seen[pr.URL] {\n\t\t\tseen[pr.URL] = true\n\t\t\tresult = append(result, pr)\n\t\t}\n\t}\n\n\treturn result\n}\n\n// generateCandidateURLsFile creates a text file with PR URLs for easy addition to junit5_pr_urls.txt\nfunc generateCandidateURLsFile(prs []JUnit5PR, outputFile string) {\n\tfile, err := os.Create(outputFile)\n\tif err != nil {\n\t\tfmt.Printf(\"Error creating file: %v\\n\", err)\n\t\treturn\n\t}\n\tdefer file.Close()\n\n\tfile.WriteString(fmt.Sprintf(\"# JUnit 5 migration PR candidates found on %s\\n\", time.Now().Format(\"2006-01-02 15:04:05\")))\n\tfile.WriteString(\"# Add relevant URLs to junit5_pr_urls.txt after verification\\n\\n\")\n\n\tfor _, pr := range prs {\n\t\tfile.WriteString(fmt.Sprintf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State))\n\t\tfile.WriteString(fmt.Sprintf(\"%s\\n\\n\", pr.URL))\n\t}\n}\n\n// compareWithExistingPRs compares found PRs with those already in junit5_pr_urls.txt\nfunc compareWithExistingPRs(prs []JUnit5PR, existingFile string) {\n\t// Read existing PR URLs\n\texistingURLs := make(map[string]bool)\n\n\tdata, err := ioutil.ReadFile(existingFile)\n\tif err == nil {\n\t\tlines := strings.Split(string(data), \"\\n\")\n\t\tfor _, line := range lines {\n\t\t\tline = strings.TrimSpace(line)\n\t\t\tif strings.HasPrefix(line, \"https://\") {\n\t\t\t\texistingURLs[line] = true\n\t\t\t}\n\t\t}\n\t}\n\n\t// Find new PRs\n\tvar newPRs []JUnit5PR\n\tfor _, pr := range prs {\n\t\tif !existingURLs[pr.URL] {\n\t\t\tnewPRs = append(newPRs, pr)\n\t\t}\n\t}\n\n\tfmt.Printf(\"Found %d new PR candidates not already in %s\\n\", len(newPRs), existingFile)\n\n\tif len(newPRs) > 0 {\n\t\tfmt.Println(\"New PR candidates:\")\n\t\tfor _, pr := range newPRs {\n\t\t\tfmt.Printf(\"# %s - %s (%s)\\n\", pr.Repository, pr.Title, pr.State)\n\t\t\tfmt.Printf(\"%s\\n\\n\", pr.URL)\n\t\t}\n\t}\n}\n"
                    }
                ]
            },
            "createdAt": 1744720394634,
            "isInternal": false
        }
    ],
    "isAgent": false,
    "isNameGenerated": true,
    "isCustomAgent": false,
    "isUnitTestsAgent": false,
    "autoApply": false
}
}