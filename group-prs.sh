#!/bin/bash

# group-prs.sh <input-json-file> <plugins-json-file>
# Replace <input-json-file> with the path to the JSON file generated by compute-stats.sh.
# Replace <plugins-json-file> with the path to the plugins.json file.

# Input JSON file (passed as a parameter)
INPUT_JSON="$1"
PLUGINS_JSON="$2"

# Validate that the input JSON file exists and is readable
if [ ! -r "$INPUT_JSON" ]; then
  echo "Error: Input file '$INPUT_JSON' does not exist or is not readable" >&2
  exit 1
fi

# Check if the plugins JSON file exists and is less than one day old
if [ ! -f "$PLUGINS_JSON" ] || [ $(find "$PLUGINS_JSON" -mtime +1 -print) ]; then
  echo "Downloading plugins.json..."
  curl -L https://updates.jenkins.io/current/update-center.actual.json -o "$PLUGINS_JSON"
fi

# Validate that the plugins JSON file exists and is readable
if [ ! -r "$PLUGINS_JSON" ]; then
  echo "Error: Plugins file '$PLUGINS_JSON' does not exist or is not readable" >&2
  exit 1
fi

# Filter PRs related to Jenkins plugins
./filter-prs.sh "$INPUT_JSON" "$PLUGINS_JSON"

# Use the filtered PRs JSON file for grouping
FILTERED_JSON="filtered_prs_$(basename "$INPUT_JSON")"

# Group PRs by title and status
GROUPED_PRS=$(jq '
  group_by(.title) |
  map({
    title: .[0].title,
    merged: map(select(.state == "MERGED")) | length,
    open: map(select(.state == "OPEN")) | length,
    closed: map(select(.state == "CLOSED")) | length,
    prs: .
  })' "$FILTERED_JSON")

# Output the grouped PRs to a new JSON file
OUTPUT_JSON="grouped_prs_$(basename "$INPUT_JSON")"
echo "$GROUPED_PRS" > "$OUTPUT_JSON"

echo "Grouped PRs have been saved to $OUTPUT_JSON"

# Extract failing PRs from the filtered JSON
echo "Extracting failing PRs from filtered data..."

# Debug: Show the first few PRs from filtered JSON to check their structure
echo "Debug: First few PRs from filtered JSON:"
jq '.[0:3]' "$FILTERED_JSON"

# Debug: Count PRs by state
echo "Debug: PRs by state:"
jq -r 'group_by(.state) | map({state: .[0].state, count: length})' "$FILTERED_JSON"

# Debug: Count PRs by checkStatus
echo "Debug: PRs by checkStatus:"
jq -r 'group_by(.checkStatus) | map({checkStatus: .[0].checkStatus, count: length})' "$FILTERED_JSON"

# Debug: Show PRs that are OPEN
echo "Debug: First few OPEN PRs:"
jq '[.[] | select(.state == "OPEN")][0:3]' "$FILTERED_JSON"

# Debug: Show PRs that have FAILURE checkStatus
echo "Debug: First few PRs with FAILURE checkStatus:"
jq '[.[] | select(.checkStatus == "FAILURE")][0:3]' "$FILTERED_JSON"

# Now try to extract failing PRs
FAILING_PRS=$(jq '
  [.[] | select(.state == "OPEN" and .checkStatus == "FAILURE") |
  {
    title: .title,
    url: "https://github.com/\(.repository)/pull/\(.number)",
    status: .checkStatus
  }]' "$FILTERED_JSON")

# Debug: Show what we found
echo "Debug: Number of failing PRs found:"
echo "$FAILING_PRS" | jq length

# Save failing PRs to a JSON file, ensuring it's a valid array even if empty
if [ -z "$FAILING_PRS" ]; then
    echo "[]" > "all_results.json"
else
    echo "$FAILING_PRS" > "all_results.json"
fi

FAILING_PRS_ERROR=false

# Activate the virtual environment (if it exists)
if [ -d "venv" ]; then
  source venv/bin/activate
else
  echo "Virtual environment not found. Please create it first."
  exit 1
fi

# Run the Python script to upload data to Google Sheets, passing the grouped PRs JSON file and failing PRs error state
python3 upload_to_sheets.py "$OUTPUT_JSON" "$FAILING_PRS_ERROR"

# Deactivate the virtual environment (optional)
deactivate
